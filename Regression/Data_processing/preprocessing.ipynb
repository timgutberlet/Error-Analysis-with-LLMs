{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "DATA_PATH = \"../../Datasets/Vehice dataset/Car details v3.csv.xls\"\n",
    "TEST_PATH = \"../../Datasets/Vehice dataset/Downsampled/Test/test.csv\"\n",
    "TRAIN_PATH = \"../../Datasets/Vehice dataset/Downsampled/Train/train.csv\"\n",
    "VALID_PATH = \"../../Datasets/Vehice dataset/Downsampled/Valid/valid.csv\"\n",
    "TEST_SAMPLED_PATH = \"../../Datasets/Vehice dataset/Downsampled/Test/test_sampled.csv\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total set Shape: (8128, 13)\n",
      "Train set shape: (5201, 13)\n",
      "Valid set shape: (1301, 13)\n",
      "Test set shape: (1626, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "# Split the dataframe into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the train_df into train and valid sets\n",
    "train_df, valid_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting dataframes\n",
    "print(\"Total set Shape:\", df.shape)\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Valid set shape:\", valid_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 15)\n",
      "                                    name  year  selling_price  km_driven  \\\n",
      "0     Ford Figo Aspire 1.5 TDCi Titanium  2017         670000      70000   \n",
      "1  Mahindra Scorpio VLX 2WD AIRBAG BSIII  2012         525000     120000   \n",
      "2                 Maruti Swift Dzire VDI  2014         438999      81000   \n",
      "3              Ford Figo Diesel Titanium  2010         144000      50000   \n",
      "4                 Hyundai i10 Magna 1.1L  2008         185000     110000   \n",
      "\n",
      "     fuel seller_type transmission                 owner     mileage   engine  \\\n",
      "0  Diesel  Individual       Manual           First Owner  25.83 kmpl  1498 CC   \n",
      "1  Diesel  Individual       Manual           First Owner  12.05 kmpl  2179 CC   \n",
      "2  Diesel      Dealer       Manual           First Owner   23.4 kmpl  1248 CC   \n",
      "3  Diesel  Individual       Manual          Second Owner   20.0 kmpl  1399 CC   \n",
      "4  Petrol  Individual       Manual  Fourth & Above Owner  19.81 kmpl  1086 CC   \n",
      "\n",
      "   max_power               torque  seats prediction prompt  \n",
      "0     99 bhp  215Nm@ 1750-3000rpm    5.0       None   None  \n",
      "1    120 bhp  290Nm@ 1800-2800rpm    8.0       None   None  \n",
      "2     74 bhp       190Nm@ 2000rpm    5.0       None   None  \n",
      "3     68 bhp       160Nm@ 2000rpm    5.0       None   None  \n",
      "4  68.05 bhp     99.04Nm@ 4500rpm    5.0       None   None  \n"
     ]
    }
   ],
   "source": [
    "#Get Ramdon Sample of Dataframe\n",
    "df_samples = test_df.sample(n=400)\n",
    "\n",
    "#Update Index\n",
    "df_samples.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "df_samples['prediction'] = 'None'\n",
    "df_samples['prompt'] = 'None'\n",
    "\n",
    "print(df_samples.shape)\n",
    "print(df_samples.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples.to_csv(TEST_SAMPLED_PATH, index=False)\n",
    "test_df.to_csv(TEST_PATH, index=False)\n",
    "train_df.to_csv(TRAIN_PATH, index=False)\n",
    "valid_df.to_csv(VALID_PATH, index=False)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
