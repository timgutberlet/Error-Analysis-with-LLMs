{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import error_prompts as p\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = os.environ.get(\"LANGFUSE_PUBLIC_KEY\")\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = os.environ.get(\"LANGFUSE_SECRET_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "handler = CallbackHandler()\n",
    "handler.auth_check()\n",
    "\n",
    "\n",
    "prompt_name_structured = 'structured_analysis'\n",
    "prompt_structured = p.structured_analysis\n",
    "prompt_name_unstructured = 'unstructured_analysis'\n",
    "prompt_unstructured = p.unstructured_analysis\n",
    "\n",
    "file = \"zero_shot_multi_table_gpt-3.5-turbo\"\n",
    "\n",
    "DATA_PATH = f'../../Datasets/Evaluations/Schema Matching/{file}.csv'\n",
    "OUTPUT_PATH = f\"../../Datasets/Evaluations/Schema Matching/Error_Analysis/structured_unstructured_{file}.csv\"\n",
    "\n",
    "MODEL = \"gpt-4-turbo-preview\"\n",
    "TEMP = 0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  table_index                      table_name  column_index_left  \\\n",
      "0           0            0  29021592_3_2299138476894681059                  0   \n",
      "1           1            1  29021592_3_2299138476894681059                  3   \n",
      "2           2            2  29021592_3_2299138476894681059                  4   \n",
      "3           3            3  29021592_3_2299138476894681059                  2   \n",
      "4           4            4  29021592_3_2299138476894681059                  0   \n",
      "\n",
      "   column_index_right  y_true  y_pred            prompt_name  \\\n",
      "0                   0    True    True  zero_shot_multi_table   \n",
      "1                   0   False   False  zero_shot_multi_table   \n",
      "2                   0   False   False  zero_shot_multi_table   \n",
      "3                   0   False   False  zero_shot_multi_table   \n",
      "4                   3   False   False  zero_shot_multi_table   \n",
      "\n",
      "                                              prompt  \\\n",
      "0  System: Description: Please identify the match...   \n",
      "1  System: Description: Please identify the match...   \n",
      "2  System: Description: Please identify the match...   \n",
      "3  System: Description: Please identify the match...   \n",
      "4  System: Description: Please identify the match...   \n",
      "\n",
      "                                      column_table_A  \\\n",
      "0        Domitian | Hadrian | Nerva | Titus | Trajan   \n",
      "1  Titus Flavius Domitianus | Publius Aelius Hadr...   \n",
      "2              81-96 | 117-8 | 96-8 | 79-81 | 98-117   \n",
      "3                        nan | nan | nan | nan | nan   \n",
      "4        Domitian | Hadrian | Nerva | Titus | Trajan   \n",
      "\n",
      "                                      column_table_B  \\\n",
      "0  Marcus Silius Messala | Titus | Hadrian | Vesp...   \n",
      "1  Marcus Silius Messala | Titus | Hadrian | Vesp...   \n",
      "2  Marcus Silius Messala | Titus | Hadrian | Vesp...   \n",
      "3  Marcus Silius Messala | Titus | Hadrian | Vesp...   \n",
      "4  nan | Imperator Titus Caesar Vespasianus Augus...   \n",
      "\n",
      "                                             table_A  \\\n",
      "0  | Column A-0   | Column A-1        |   Column ...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             table_B  \\\n",
      "0  | Column B-0            |   Column B-1 | Colum...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                           ai_answer  \n",
      "0  {\"column_mappings\": [[\"Column A-0\", \"Column B-...  \n",
      "1  {\"column_mappings\": [[\"Column A-0\", \"Column B-...  \n",
      "2  {\"column_mappings\": [[\"Column A-0\", \"Column B-...  \n",
      "3  {\"column_mappings\": [[\"Column A-0\", \"Column B-...  \n",
      "4  {\"column_mappings\": [[\"Column A-0\", \"Column B-...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "correct    379\n",
      "error       71\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['error'] = None\n",
    "df['error'] = ['correct' if y_true == y_pred else 'error' for y_true, y_pred in zip(df['y_true'], df['y_pred'])]\n",
    "\n",
    "print(df['error'].value_counts())\n",
    "\n",
    "df_correct = df[df['error'] == 'correct']\n",
    "df_error = df[df['error'] == 'error']\n",
    "\n",
    "\n",
    "\n",
    "df_error_sample = df_error.sample(n=20)\n",
    "df_correct_sample = df_correct.sample(n=5)\n",
    "df = pd.concat([df_error_sample, df_correct_sample])\n",
    "df['structured_analysis'] = None\n",
    "df['unstructured_analysis'] = None\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 17)\n",
      "   Unnamed: 0  table_index                      table_name  column_index_left  \\\n",
      "0         183          183  36039980_4_4283009829602711082                  1   \n",
      "1         137          137  86747932_0_7532457067740920052                  3   \n",
      "2         215          215  86297395_0_6919201319699354263                  2   \n",
      "3         294          294  39173938_0_7916056990138658530                  4   \n",
      "4         438          438  90593344_0_8311455501234425088                  2   \n",
      "\n",
      "   column_index_right  y_true  y_pred            prompt_name  \\\n",
      "0                   4    True   False  zero_shot_multi_table   \n",
      "1                   0    True   False  zero_shot_multi_table   \n",
      "2                   2    True   False  zero_shot_multi_table   \n",
      "3                   0    True   False  zero_shot_multi_table   \n",
      "4                   2    True   False  zero_shot_multi_table   \n",
      "\n",
      "                                              prompt  \\\n",
      "0  System: Description: Please identify the match...   \n",
      "1  System: Description: Please identify the match...   \n",
      "2  System: Description: Please identify the match...   \n",
      "3  System: Description: Please identify the match...   \n",
      "4  System: Description: Please identify the match...   \n",
      "\n",
      "                                      column_table_A  \\\n",
      "0                     TI/I | GR/TI | GR/TI | TI | TI   \n",
      "1  Air Italy | Aeroflot Russian Airlines | Qantas...   \n",
      "2  republic | presidential/parliamentary democrac...   \n",
      "3  Playtime | The Sting | A Fish Called Wanda | M...   \n",
      "4  NY 21467 26740 | NY 26679 27785 | NY 29622 329...   \n",
      "\n",
      "                                      column_table_B  \\\n",
      "0  Vaud, Switzerland | Lombardy, Ticino, Italy, S...   \n",
      "1  British Airways World Cargo | Airworld | Malay...   \n",
      "2  Unitary parliamentary republic | Unitary state...   \n",
      "3  Bark! | Sau Crore | Cairo (1942 film) | A Brid...   \n",
      "4  NY785375 | SJ994737 | NY151034 | SD959552 | NY...   \n",
      "\n",
      "                                             table_A  \\\n",
      "0                                                NaN   \n",
      "1  | Column A-0   | Column A-1   | Column A-2   |...   \n",
      "2                                                NaN   \n",
      "3  |   Column A-0 | Column A-1         |   Column...   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             table_B  \\\n",
      "0                                                NaN   \n",
      "1  | Column B-0           | Column B-1   | Column...   \n",
      "2                                                NaN   \n",
      "3  | Column B-0          | Column B-1            ...   \n",
      "4                                                NaN   \n",
      "\n",
      "                                           ai_answer  error  \\\n",
      "0  {\"column_mappings\": [[\"Column A-0\", \"None\"], [...  error   \n",
      "1  {\"column_mappings\": [[\"Column A-0\", \"None\"], [...  error   \n",
      "2  {\"column_mappings\": [[\"Column A-0\", \"None\"], [...  error   \n",
      "3  {\"column_mappings\": [[\"Column A-0\", \"None\"], [...  error   \n",
      "4  {\"column_mappings\": [[\"Column A-0\", \"None\"], [...  error   \n",
      "\n",
      "  structured_analysis unstructured_analysis  \n",
      "0                None                  None  \n",
      "1                None                  None  \n",
      "2                None                  None  \n",
      "3                None                  None  \n",
      "4                None                  None  \n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "System: You are a helpful AI.\n",
      "Human: System: Description: Please identify the matching columns between Table A and Table B. \n",
      "     For each column in Table A, specify the corresponding column in Table B. \n",
      "     If a column in A has no corresponding column in Table B, you can map it to 'None'. \n",
      "     Represent each column mapping using a pair of column headers in a list, i.e., [Table A Column, Table B column or None]. \n",
      "     Provide the mapping for each column in Table A and return all mappings in a list. Return the final result as JSON in the format {\"column_mappings\": \"<a list of column pairs>\"}.\n",
      "Human: Question:\n",
      "Table A:\n",
      "|   Column A-0 | Column A-1   | Column A-2   |   Column A-3 | Column A-4           |\n",
      "|-------------:|:-------------|:-------------|-------------:|:---------------------|\n",
      "|        189   | GR           | 19.03 km     |         2578 | Forcel               |\n",
      "|        190.1 | GR/TI        | 15.44 km     |         2739 | Motton               |\n",
      "|        191.8 | GR/TI        | 15.59 km     |         2899 | Piz da Termin        |\n",
      "|        184.7 | TI/I         | 41.09 km     |         2116 | Gazzirola            |\n",
      "|        184   | TI/I         | 41.94 km     |         2076 | Prato della Bascióta |\n",
      "\n",
      "Table B:\n",
      "| Column B-0     |   Column B-1 |   Column B-2 | Column B-3                            | Column B-4                    |\n",
      "|:---------------|-------------:|-------------:|:--------------------------------------|:------------------------------|\n",
      "| Schilt         |           58 |         2299 | Glarus Alps                           | Canton of Glarus, Switzerland |\n",
      "| Scheuchzerhorn |          116 |         3456 | Bernese Alps                          | Canton of Bern, Switzerland   |\n",
      "| Punta Baretti  |          nan |         4013 | Mont Blanc massif                     | Italy, Val d'Aosta            |\n",
      "| Rocher du Midi |          240 |         2097 | Bernese Alps                          | Vaud, Switzerland             |\n",
      "| Rossbodenstock |          nan |         2836 | Saint-Gotthard Massif, Lepontine Alps | Canton of Uri, Graubünden     |\n",
      "\n",
      "Return the final result as JSON in the format {\"column_mappings\": \"<a list of column pairs>\"}. ONLY return the JSON and nothing else.\n",
      "Answer:\n",
      "AI: {\"column_mappings\": [[\"Column A-0\", \"None\"], [\"Column A-1\", \"None\"], [\"Column A-2\", \"None\"], [\"Column A-3\", \"Column B-2\"], [\"Column A-4\", \"None\"]]}\n",
      "Human: Now explain concisely how and why you made your decision to not match the pair Column A-1 and Column B-4 and explicitly mention the values that had a high influence on your decision.\n",
      "\n",
      "\n",
      "The decision to not match \"Column A-1\" from Table A with \"Column B-4\" from Table B was based on the content and context of the values within these columns. \n",
      "\n",
      "- \"Column A-1\" contains values like \"GR\", \"GR/TI\", and \"TI/I\", which appear to represent codes or abbreviations, possibly for geographic regions or administrative divisions.\n",
      "- \"Column B-4\" contains values like \"Canton of Glarus, Switzerland\", \"Canton of Bern, Switzerland\", \"Italy, Val d'Aosta\", \"Vaud, Switzerland\", and \"Canton of Uri, Graubünden\". These are explicit geographic locations, including countries, cantons, and regions.\n",
      "\n",
      "The key influence on the decision was the nature of the data: \"Column A-1\" seems to represent a coded or abbreviated form of geographic or administrative identifiers, while \"Column B-4\" provides full, descriptive geographic names. There is no direct correlation or a clear way to map the abbreviations to the specific locations without additional context or a key to decode the abbreviations in \"Column A-1\". Therefore, without a direct match or a clear relationship between the two sets of values, the columns were not matched.\n",
      "\n",
      "\n",
      "0 of  25\n",
      "1\n",
      "System: You are a helpful AI.\n",
      "Human: System: Description: Please identify the matching columns between Table A and Table B. \n",
      "     For each column in Table A, specify the corresponding column in Table B. \n",
      "     If a column in A has no corresponding column in Table B, you can map it to 'None'. \n",
      "     Represent each column mapping using a pair of column headers in a list, i.e., [Table A Column, Table B column or None]. \n",
      "     Provide the mapping for each column in Table A and return all mappings in a list. Return the final result as JSON in the format {\"column_mappings\": \"<a list of column pairs>\"}.\n",
      "Human: Question:\n",
      "Table A:\n",
      "| Column A-0   | Column A-1   | Column A-2   | Column A-3            |\n",
      "|:-------------|:-------------|:-------------|:----------------------|\n",
      "| EY           | Reisegepäck  | WebCheckIn   | Etihad Airways        |\n",
      "| DL           | Reisegepäck  | WebCheckIn   | Delta Air Lines       |\n",
      "| DY           | Reisegepäck  | WebCheckIn   | Norwegian Air Shuttle |\n",
      "| FL           | Reisegepäck  | WebCheckIn   | AirTran Airways       |\n",
      "| VX           | Reisegepäck  | WebCheckIn   | Virgin America        |\n",
      "\n",
      "Table B:\n",
      "| Column B-0           | Column B-1   | Column B-2                                                                                          | Column B-3   | Column B-4                                                                   |\n",
      "|:---------------------|:-------------|:----------------------------------------------------------------------------------------------------|:-------------|:-----------------------------------------------------------------------------|\n",
      "| Trans World Airlines | TWA          | Mount Kisco, New York, Fort Worth, Texas, Kansas City, Missouri, New York City, St. Louis, Missouri | TW           | nan                                                                          |\n",
      "| East African Air     | nan          | United Kingdom, London                                                                              | 5H           | Mwanza, Kilimanjaro, Mtwara, Nairobi, Johannesburg, Dubai and London Gatwick |\n",
      "| JetSmart Perú        | JAP          | Peru, Lima                                                                                          | JZ           | 10                                                                           |\n",
      "| Qantas Freight       | QFA          | Sydney                                                                                              | QF           | 130                                                                          |\n",
      "| Aviolet              | ASL          | Belgrade, Serbia                                                                                    | JU           | 26                                                                           |\n",
      "\n",
      "Return the final result as JSON in the format {\"column_mappings\": \"<a list of column pairs>\"}. ONLY return the JSON and nothing else.\n",
      "Answer:\n",
      "AI: {\"column_mappings\": [[\"Column A-0\", \"None\"], [\"Column A-1\", \"Column B-1\"], [\"Column A-2\", \"None\"], [\"Column A-3\", \"None\"]]}\n",
      "Human: Now explain concisely how and why you made your decision to not match the pair Column A-3 and Column B-0 and explicitly mention the values that had a high influence on your decision.\n",
      "\n",
      "\n",
      "The decision to not match \"Column A-3\" from Table A with \"Column B-0\" from Table B was based on the nature of the data contained within these columns. \"Column A-3\" lists airline names (e.g., \"Etihad Airways\", \"Delta Air Lines\", \"Norwegian Air Shuttle\", \"AirTran Airways\", \"Virgin America\"), while \"Column B-0\" lists either airline names or locations associated with airlines, but none of the names in \"Column B-0\" match any of the airline names listed in \"Column A-3\". The values in \"Column B-0\" such as \"Trans World Airlines\", \"East African Air\", \"JetSmart Perú\", \"Qantas Freight\", and \"Aviolet\" do not correspond to any of the specific airline names listed in \"Column A-3\". This lack of direct correspondence or matching names between the two columns influenced the decision to not map \"Column A-3\" to \"Column B-0\".\n",
      "\n",
      "\n",
      "2\n",
      "System: You are a helpful AI.\n",
      "Human: System: Description: Please identify the matching columns between Table A and Table B. \n",
      "     For each column in Table A, specify the corresponding column in Table B. \n",
      "     If a column in A has no corresponding column in Table B, you can map it to 'None'. \n",
      "     Represent each column mapping using a pair of column headers in a list, i.e., [Table A Column, Table B column or None]. \n",
      "     Provide the mapping for each column in Table A and return all mappings in a list. Return the final result as JSON in the format {\"column_mappings\": \"<a list of column pairs>\"}.\n",
      "Human: Question:\n",
      "Table A:\n",
      "| Column A-0             | Column A-1   | Column A-2                                                              | Column A-3   | Column A-4   | Column A-5         | Column A-6   |\n",
      "|:-----------------------|:-------------|:------------------------------------------------------------------------|:-------------|:-------------|:-------------------|:-------------|\n",
      "| Romania                | 22,276,056   | democracy                                                               | $256,900     | $10,661      | No (ended in 2007) | 238,392      |\n",
      "| Luxembourg             | 480,222      | constitutional monarchy                                                 | $34,530      | $71,904.24   | No                 | 2,586        |\n",
      "| Albania                | 3,600,523    | emerging democracy                                                      | $9,306       | $2,584.63    | Yes                | 27,398       |\n",
      "| Macedonia, Republic of | 2,055,915    | parliamentary democracy                                                 | $6,225       | $3,027.85    | No                 | 24,856       |\n",
      "| Switzerland            | 7,508,700    | formally a confederation but similar in structure to a federal republic | $386,100     | $51,107.52   | Yes                | 41,285       |\n",
      "\n",
      "Table B:\n",
      "| Column B-0           | Column B-1                  | Column B-2                      |       Column B-3 |   Column B-4 |   Column B-5 | Column B-6                    |   Column B-7 |   Column B-8 | Column B-9                                                                                |\n",
      "|:---------------------|:----------------------------|:--------------------------------|-----------------:|-------------:|-------------:|:------------------------------|-------------:|-------------:|:------------------------------------------------------------------------------------------|\n",
      "| United States        | United States dollar        | Federalism in the United States |      3.31894e+08 |         46.9 |  2.5035e+13  | 9833516.638013326             |  2.5035e+13  |        75180 | John Roberts, Nancy Pelosi, Joe Biden, Kamala Harris                                      |\n",
      "| Saint Lucia          | East Caribbean dollar       | Unitary state                   | 184961           |         51.2 |  2.48e+09    | 617.0, 617.0128675253453      |  1.77e+09    |         9780 | Errol Charles, Charles III, Philip J. Pierre                                              |\n",
      "| Sudan                | Sudanese pound              | Federalism                      |      4.79589e+07 |         34.2 |  2.0304e+11  | 1886068.0, 1886068.1917683303 |  3.0808e+10  |          674 | Mohamed Hamdan Dagalo, Abdel Fattah al-Burhan, Osman Hussein                              |\n",
      "| Equatorial Guinea    | Central African CFA franc   | Unitary state                   |      1.67917e+06 |        nan   |  2.7959e+10  | 28049.57123493888, 28050.0    |  1.6012e+10  |         8462 | Francisco Pascual Obama Asue, Teodoro Nguema Obiang Mangue, Teodoro Obiang Nguema Mbasogo |\n",
      "| United Arab Emirates | United Arab Emirates dirham | Federal monarchy                |      9.28241e+06 |         26   |  7.79234e+11 | 83599.63622542542, 83600.0    |  5.01354e+11 |        50349 | Mohamed bin Zayed Al Nahyan, Mohammed bin Rashid Al Maktoum                               |\n",
      "\n",
      "Return the final result as JSON in the format {\"column_mappings\": \"<a list of column pairs>\"}. ONLY return the JSON and nothing else.\n",
      "Answer:\n",
      "AI: {\"column_mappings\": [[\"Column A-0\", \"None\"], [\"Column A-1\", \"None\"], [\"Column A-2\", \"None\"], [\"Column A-3\", \"Column B-3\"], [\"Column A-4\", \"None\"], [\"Column A-5\", \"None\"], [\"Column A-6\", \"None\"]]}\n",
      "Human: Now explain concisely how and why you made your decision to not match the pair Column A-2 and Column B-2 and explicitly mention the values that had a high influence on your decision.\n",
      "\n",
      "\n",
      "The decision to not match \"Column A-2\" from Table A with \"Column B-2\" from Table B was based on the nature of the content within these columns. \n",
      "\n",
      "- \"Column A-2\" in Table A describes the type of government or political system in various countries (e.g., \"democracy,\" \"constitutional monarchy,\" \"emerging democracy,\" \"parliamentary democracy,\" \"formally a confederation but similar in structure to a federal republic\"). \n",
      "- \"Column B-2\" in Table B, on the other hand, describes more specific governmental structures or principles for different countries (e.g., \"Federalism in the United States,\" \"Unitary state,\" \"Federalism,\" \"Unitary state,\" \"Federal monarchy\").\n",
      "\n",
      "The key influence on the decision was the level of specificity and the nature of the descriptions. While both columns discuss governmental structures, \"Column A-2\" focuses on broad categories of governance systems, whereas \"Column B-2\" includes specific governmental principles or structures that do not directly correspond to the broad categories listed in \"Column A-2.\" For example, \"democracy\" is a broad category that can encompass various forms of governance, including federalism, unitary states, or federal monarchies, but it does not directly equate to any of these specific terms. Therefore, due to the lack of direct correspondence in the nature of the content, these columns were not matched.\n",
      "\n",
      "\n",
      "3\n",
      "System: You are a helpful AI.\n",
      "Human: System: Description: Please identify the matching columns between Table A and Table B. \n",
      "     For each column in Table A, specify the corresponding column in Table B. \n",
      "     If a column in A has no corresponding column in Table B, you can map it to 'None'. \n",
      "     Represent each column mapping using a pair of column headers in a list, i.e., [Table A Column, Table B column or None]. \n",
      "     Provide the mapping for each column in Table A and return all mappings in a list. Return the final result as JSON in the format {\"column_mappings\": \"<a list of column pairs>\"}.\n",
      "Human: Question:\n",
      "Table A:\n",
      "|   Column A-0 | Column A-1         |   Column A-2 |   Column A-3 | Column A-4                   |\n",
      "|-------------:|:-------------------|-------------:|-------------:|:-----------------------------|\n",
      "|           43 | Ernst Lubitsch     |          229 |         1939 | Ninotchka                    |\n",
      "|           95 | Amy Heckerling     |          424 |         1982 | Fast Times at Ridgemont High |\n",
      "|           38 | Giuseppe Tornatore |          192 |         1988 | Cinema Paradiso              |\n",
      "|            7 | Howard Hawks       |           52 |         1938 | Bringing Up Baby             |\n",
      "|           80 | Charles Chaplin    |          369 |         1940 | The Great Dictator           |\n",
      "\n",
      "Table B:\n",
      "| Column B-0          | Column B-1             | Column B-2           | Column B-3      |\n",
      "|:--------------------|:-----------------------|:---------------------|:----------------|\n",
      "| Sands of the Desert | 1960-09-08             | John Paddy Carstairs | nan             |\n",
      "| El Sur (film)       | 1983-05-19, 1988-01-15 | Víctor Erice         | Elías Querejeta |\n",
      "| In the Last Stride  | 1915-11-22, 1916-05-01 | Martyn Keith         | nan             |\n",
      "| Meendum Vazhven     | 1971-04-23             | T. N. Balu           | nan             |\n",
      "| Prey (2009 film)    | 2009-05-05             | George T. Miller     | nan             |\n",
      "\n",
      "Return the final result as JSON in the format {\"column_mappings\": \"<a list of column pairs>\"}. ONLY return the JSON and nothing else.\n",
      "Answer:\n",
      "AI: {\"column_mappings\": [[\"Column A-0\", \"None\"], [\"Column A-1\", \"None\"], [\"Column A-2\", \"None\"], [\"Column A-3\", \"None\"], [\"Column A-4\", \"None\"]]}\n",
      "Human: Now explain concisely how and why you made your decision to not match the pair Column A-4 and Column B-0 and explicitly mention the values that had a high influence on your decision.\n",
      "\n",
      "\n",
      "The decision to not match \"Column A-4\" from Table A with \"Column B-0\" from Table B was based on the content and context of the values within these columns. \"Column A-4\" contains titles of well-known movies (e.g., \"Ninotchka,\" \"Fast Times at Ridgemont High,\" \"Cinema Paradiso,\" \"Bringing Up Baby,\" \"The Great Dictator\"), which are specific and identifiable film titles. In contrast, \"Column B-0\" also lists titles (e.g., \"Sands of the Desert,\" \"El Sur (film),\" \"In the Last Stride,\" \"Meendum Vazhven,\" \"Prey (2009 film)\"), but there is no direct match or correlation between the movie titles in both columns. The titles in \"Column A-4\" are distinct and do not appear in \"Column B-0,\" indicating that these columns represent different sets of movies. Therefore, without any overlapping titles or direct correlation, it was concluded that \"Column A-4\" does not have a corresponding match in \"Column B-0.\"\n",
      "\n",
      "\n",
      "4\n",
      "System: You are a helpful AI.\n",
      "Human: System: Description: Please identify the matching columns between Table A and Table B. \n",
      "     For each column in Table A, specify the corresponding column in Table B. \n",
      "     If a column in A has no corresponding column in Table B, you can map it to 'None'. \n",
      "     Represent each column mapping using a pair of column headers in a list, i.e., [Table A Column, Table B column or None]. \n",
      "     Provide the mapping for each column in Table A and return all mappings in a list. Return the final result as JSON in the format {\"column_mappings\": \"<a list of column pairs>\"}.\n",
      "Human: Question:\n",
      "Table A:\n",
      "|   Column A-0 |   Column A-1 | Column A-2     |   Column A-3 |   Column A-4 |   Column A-5 |   Column A-6 |   Column A-7 |   Column A-8 | Column A-9       |   Column A-10 |\n",
      "|-------------:|-------------:|:---------------|-------------:|-------------:|-------------:|-------------:|-------------:|-------------:|:-----------------|--------------:|\n",
      "|          208 |          535 | NY 15135 03447 |         1755 |          nan |          nan |          nan |          nan |          nan | Whin Rigg        |           nan |\n",
      "|           87 |          736 | NY 28180 07393 |         2415 |          nan |          nan |          nan |          nan |          nan | Harrison Stickle |           nan |\n",
      "|          156 |          792 | NY 44332 12861 |         2598 |          nan |          nan |          nan |          nan |          nan | Rampsgill Head   |           nan |\n",
      "|           46 |          753 | NY 22301 15324 |         2470 |          nan |          nan |          nan |          nan |          nan | Dale Head        |           nan |\n",
      "|          204 |          487 | NY 40370 05267 |         1598 |          nan |          nan |          nan |          nan |          nan | Wansfell         |           nan |\n",
      "\n",
      "Table B:\n",
      "| Column B-0               |   Column B-1 | Column B-2   |\n",
      "|:-------------------------|-------------:|:-------------|\n",
      "| Watch Hill (Cockermouth) |          254 | NY159318     |\n",
      "| Cold Pike                |          701 | NY262035     |\n",
      "| Gregory Chapel           |          695 | NY802003     |\n",
      "| Cringle Moor             |          434 | NZ537029     |\n",
      "| Gun (Staffordshire)      |          385 | SJ970615     |\n",
      "\n",
      "Return the final result as JSON in the format {\"column_mappings\": \"<a list of column pairs>\"}. ONLY return the JSON and nothing else.\n",
      "Answer:\n",
      "AI: {\"column_mappings\": [[\"Column A-0\", \"None\"], [\"Column A-1\", \"None\"], [\"Column A-2\", \"None\"], [\"Column A-3\", \"None\"], [\"Column A-4\", \"None\"], [\"Column A-5\", \"None\"], [\"Column A-6\", \"None\"], [\"Column A-7\", \"None\"], [\"Column A-8\", \"None\"], [\"Column A-9\", \"None\"], [\"Column A-10\", \"None\"]]}\n",
      "Human: Now explain concisely how and why you made your decision to not match the pair Column A-2 and Column B-2 and explicitly mention the values that had a high influence on your decision.\n",
      "\n",
      "\n",
      "The decision to not match \"Column A-2\" from Table A with \"Column B-2\" from Table B was based on the format and structure of the values within these columns. \n",
      "\n",
      "- **Column A-2** contains values that are in a format resembling \"NY 15135 03447\", which suggests a specific pattern of an alphabetical prefix followed by two numerical groups separated by a space.\n",
      "- **Column B-2**, on the other hand, contains values like \"NY159318\", which are also prefixed with letters (e.g., \"NY\") but followed by a single group of numbers without any spaces.\n",
      "\n",
      "The key differences influencing the decision are:\n",
      "1. **Presence of a space within the numerical part**: Column A-2 includes a space separating two groups of numbers, whereas Column B-2 does not.\n",
      "2. **Number of numerical groups**: Column A-2 consistently shows two separate numerical groups after the prefix, while Column B-2 presents a single continuous string of numbers.\n",
      "\n",
      "These structural and format discrepancies indicate that despite both columns containing alphanumeric codes with a similar prefix (e.g., \"NY\"), the manner in which these codes are presented significantly differs, leading to the conclusion that they do not match.\n",
      "\n",
      "\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "#unstructured Analysis\n",
    "def execute(df, prompt, start = 0):\n",
    "    if(MODEL == \"gpt-3.5-turbo-instruct\"):\n",
    "        llm = OpenAI(model_name = MODEL, temperature = TEMP, timeout=100)\n",
    "    else:\n",
    "        llm = ChatOpenAI(model_name = MODEL, temperature = TEMP, timeout=100)\n",
    "    for i in range(len(df)):\n",
    "        if(df[\"unstructured_analysis\"][i] != None and df[\"unstructured_analysis\"][i] != \"error\"):\n",
    "            continue\n",
    "        print(i)\n",
    "        chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "        user_prompt = df.loc[i, 'prompt']\n",
    "        ai_answer = str(df.loc[i, 'ai_answer'])\n",
    "        match = \"\"\n",
    "        if str(df.loc[i, 'y_pred']).lower() == 'false':\n",
    "            match = \"not match\"\n",
    "        else:\n",
    "            match = \"match\"\n",
    "        columns = \"Column A-\" + str(df.loc[i, 'column_index_left']) + \" and Column B-\" + str(df.loc[i, 'column_index_right'])\n",
    "        try: \n",
    "            result = chain.run(user_prompt = user_prompt, ai_answer = ai_answer, match = match, columns = columns, callbacks=[handler])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = ai_answer, match = match, columns = columns).to_string())\n",
    "            df.loc[i, 'unstructured_analysis'] = 'error'\n",
    "            continue\n",
    "        handler.langfuse.flush()\n",
    "        prompt_text = chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = ai_answer, match = match, columns = columns).to_string()\n",
    "        if (i < 5):\n",
    "            print(prompt_text)\n",
    "            print(\"\\n\")\n",
    "            print(result)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        if (i % 50 == 0):\n",
    "            print(str(i) + \" of  \" + str(len(df)))\n",
    "        df.loc[i, 'unstructured_analysis']= result\n",
    "    return df\n",
    "\n",
    "\n",
    "df = execute(df, prompt_unstructured)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "System: You are a helpful AI.\n",
      "Human: There were a lot of scensters who couldnt afford dinner hanging in the waiting area so we got bumped around a lot.\n",
      "\n",
      "    What is the sentiment on 'dinner'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: neutral\n",
      "Human: Now explain concisely how you made your prediction and explicitly mention the adjectives that had a high influence on your decision.\n",
      "\n",
      "\n",
      "The sentiment analysis on the word \"dinner\" in the provided text is determined to be \"neutral\" because the context in which \"dinner\" is mentioned does not inherently carry a positive or negative connotation towards the meal itself. The focus of the sentence is on the situation of people who couldn't afford dinner and the inconvenience caused by being bumped around, rather than the quality or enjoyment of the dinner. There are no adjectives directly modifying \"dinner\" to suggest a positive or negative sentiment. The sentiment is derived more from the situation (people not affording dinner) rather than the dinner itself, leading to the classification as \"neutral.\"\n",
      "\n",
      "\n",
      "0 of  100\n",
      "1\n",
      "System: You are a helpful AI.\n",
      "Human: Had a mouthwatering sardinian Stuffed Squid and a Catfish fiumarola from Rome( think was capers and anchovies sauce).\n",
      "\n",
      "    What is the sentiment on 'sauce'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: positive\n",
      "Human: Now explain concisely how you made your prediction and explicitly mention the adjectives that had a high influence on your decision.\n",
      "\n",
      "\n",
      "The prediction of a \"positive\" sentiment towards the term \"sauce\" was influenced by the adjective \"mouthwatering\" used to describe the Sardinian Stuffed Squid and the context of a Catfish fiumarola from Rome, which was thought to have a capers and anchovies sauce. The word \"mouthwatering\" strongly suggests a positive experience and enjoyment of the food, which by extension includes the sauce, as it is a component of the described dishes.\n",
      "\n",
      "\n",
      "2\n",
      "System: You are a helpful AI.\n",
      "Human: As for the food, brunch was average, I would not get the same dish again, and they were slow to serve us.\n",
      "\n",
      "    What is the sentiment on 'brunch'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: negative\n",
      "Human: Now explain concisely how you made your prediction and explicitly mention the adjectives that had a high influence on your decision.\n",
      "\n",
      "\n",
      "The prediction of a \"negative\" sentiment towards \"brunch\" was based on the adjectives and context provided in the statement. The adjectives \"average\" and \"slow\" had a high influence on the decision. \"Average\" suggests a lack of enthusiasm or satisfaction with the quality of the brunch, indicating it did not meet expectations or was merely satisfactory without excelling. \"Slow\" in reference to the service speed further contributes to a negative experience, as it implies a level of dissatisfaction with the timeliness of the service. These adjectives, combined with the explicit statement of not wanting to get the same dish again, strongly indicate a negative sentiment.\n",
      "\n",
      "\n",
      "3\n",
      "System: You are a helpful AI.\n",
      "Human: We sat at the bar and were constantly bumped by the waitress flying past; had fabulously fresh raw oysters with pieces of shell in every bite; lobsters rolls were tasty but the large pieces of meat were tough; the apple crumble was excellent but the ice cream was over-frozen and the stench of frying oil was nearly unbearable.\n",
      "\n",
      "    What is the sentiment on 'rolls'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: negative\n",
      "Human: Now explain concisely how you made your prediction and explicitly mention the adjectives that had a high influence on your decision.\n",
      "\n",
      "\n",
      "The sentiment prediction for \"rolls\" as negative was influenced by the adjectives \"tasty\" (which is positive) but more so by \"tough\" in the context of describing the large pieces of meat in the lobster rolls. The word \"tough\" suggests a negative dining experience related to the texture and quality of the meat, outweighing the positive aspect provided by \"tasty.\"\n",
      "\n",
      "\n",
      "4\n",
      "System: You are a helpful AI.\n",
      "Human: about 10 minutes apart each, so we were all eating cold eggs by the time we got our food.\n",
      "\n",
      "    What is the sentiment on 'eggs'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: neutral\n",
      "Human: Now explain concisely how you made your prediction and explicitly mention the adjectives that had a high influence on your decision.\n",
      "\n",
      "\n",
      "My prediction was based on the analysis of the sentiment expressed towards the 'eggs' in the provided text. The key phrase influencing the decision was \"cold eggs.\" The adjective \"cold\" typically carries a negative connotation when associated with food meant to be served hot, suggesting a less than ideal or negative experience. However, the sentiment was requested specifically towards 'eggs' without considering the context or descriptors directly influencing the sentiment. Given the lack of explicitly positive or negative adjectives directly modifying 'eggs' themselves (e.g., \"delicious eggs\" or \"spoiled eggs\"), and focusing strictly on the sentiment towards 'eggs' without the influence of their condition ('cold'), the response was \"neutral.\" This was an oversight in my initial analysis, as the context (\"cold eggs\") indeed suggests a negative sentiment towards the experience of eating the eggs, not their intrinsic quality.\n",
      "\n",
      "\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "50 of  100\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#structured Analysis\n",
    "def execute(df, prompt):\n",
    "    if(MODEL == \"gpt-3.5-turbo-instruct\"):\n",
    "        llm = OpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    else:\n",
    "        llm = ChatOpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    for i in range(len(df)):\n",
    "        if(df[\"structured_analysis\"][i] != None and df[\"structured_analysis\"][i] != \"error\"):\n",
    "            continue\n",
    "        print(i)\n",
    "        chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "        user_prompt = df.loc[i, 'prompt']\n",
    "        ai_answer = df.loc[i, 'polarity_pred']\n",
    "        try: \n",
    "            result = chain.run(user_prompt = user_prompt, ai_answer = str(ai_answer), callbacks=[handler])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = str(ai_answer)).to_string())\n",
    "            df['structured_analysis'][i] = 'error'\n",
    "            continue\n",
    "        handler.langfuse.flush()\n",
    "        prompt_text = chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = str(ai_answer)).to_string()\n",
    "        if (i < 5):\n",
    "            print(prompt_text)\n",
    "            print(\"\\n\")\n",
    "            print(result)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        if (i % 50 == 0):\n",
    "            print(str(i) + \" of  \" + str(len(df)))\n",
    "        df.loc[i, 'structured_analysis']= result\n",
    "    return df\n",
    "\n",
    "df = execute(df, prompt_unstructured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(OUTPUT_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
