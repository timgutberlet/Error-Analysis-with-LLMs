{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import error_prompts as p\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = os.environ.get(\"LANGFUSE_PUBLIC_KEY\")\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = os.environ.get(\"LANGFUSE_SECRET_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "handler = CallbackHandler()\n",
    "handler.auth_check()\n",
    "\n",
    "\n",
    "prompt_name_structured = 'structured_analysis'\n",
    "prompt_structured = p.structured_analysis\n",
    "prompt_name_unstructured = 'unstructured_analysis'\n",
    "prompt_unstructured = p.unstructured_analysis\n",
    "\n",
    "file = \"singleterm_dynamic_fewshot_4-turbo-preview\"\n",
    "\n",
    "DATA_PATH = f'../../Datasets/Evaluations/Sentiment Analysis/{file}.csv'\n",
    "OUTPUT_PATH = f\"../../Datasets/Evaluations/Sentiment Analysis/Error_Analysis/structured_unstructured/structured_unstructured_{file}.csv\"\n",
    "\n",
    "MODEL = \"gpt-4-turbo-preview\"\n",
    "TEMP = 0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "correct    263\n",
      "error      188\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df['error'] = None\n",
    "df['error'] = ['correct' if polarity == polarity_pred else 'error' for polarity, polarity_pred in zip(df['polarity'], df['polarity_pred'])]\n",
    "\n",
    "print(df['error'].value_counts())\n",
    "\n",
    "df_correct = df[df['error'] == 'correct']\n",
    "df_error = df[df['error'] == 'error']\n",
    "\n",
    "\n",
    "\n",
    "df_error_sample = df_error.sample(n=50)\n",
    "df_correct_sample = df_correct.sample(n=50)\n",
    "df = pd.concat([df_error_sample, df_correct_sample])\n",
    "df['structured_analysis'] = None\n",
    "df['unstructured_analysis'] = None\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 22)\n",
      "   Unnamed: 0.1  Unnamed: 0  text_id  term_id  \\\n",
      "0           426         426      161      426   \n",
      "1           269         269      102      269   \n",
      "2            30          30       10       30   \n",
      "3           378         378      144      378   \n",
      "4            38          38       13       38   \n",
      "\n",
      "                                                text        term  polarity  \\\n",
      "0  Had a party of 7 people for dinner here on a b...      dinner   neutral   \n",
      "1  about 10 minutes apart each, so we were all ea...        food   neutral   \n",
      "2  Ok I got the edamame and something from the su...  sushi chef  positive   \n",
      "3  Aside from the fact the maitre de claimed the ...      maitre   neutral   \n",
      "4  We preferred to gaze at our burgers while avoi...     burgers   neutral   \n",
      "\n",
      "   example1_term_id                                    example1_prompt  \\\n",
      "0              2979  Input: \"Went here for a casual Sunday night di...   \n",
      "1              8605  Input: \"The staff were all partying with each ...   \n",
      "2              5289  Input: \"Free edamame (nice perk) and we ordere...   \n",
      "3             10239  Input: \"We had the tasting menu -- which was n...   \n",
      "4              6351  Input: \"staff is still working out their kinks...   \n",
      "\n",
      "   example1_sim_score  ...  example2_sim_score example3_term_id  \\\n",
      "0            0.271384  ...            0.275128              692   \n",
      "1            0.258910  ...            0.276962              130   \n",
      "2            0.251135  ...            0.254829             4606   \n",
      "3            0.226859  ...            0.266909             4778   \n",
      "4            0.242029  ...            0.253214            10328   \n",
      "\n",
      "                                     example3_prompt  example3_sim_score  \\\n",
      "0  Input: \"The service wasn't good -- dumplings w...            0.297496   \n",
      "1  Input: \"The beginning of the meal wasnt bad, t...            0.294138   \n",
      "2  Input: \"Went to Chow Bar for dinner, I thought...            0.261215   \n",
      "3  Input: \"5 hour meal (we ordered the tasting me...            0.277564   \n",
      "4  Input: \"We had to ask for water even after we ...            0.262997   \n",
      "\n",
      "  polarity_pred                 prompt_name  \\\n",
      "0      positive  prompt_single_term_fewshot   \n",
      "1      negative  prompt_single_term_fewshot   \n",
      "2       neutral  prompt_single_term_fewshot   \n",
      "3      negative  prompt_single_term_fewshot   \n",
      "4      positive  prompt_single_term_fewshot   \n",
      "\n",
      "                                              prompt  error  \\\n",
      "0  Example 1:\\nInput: \"Went here for a casual Sun...  error   \n",
      "1  Example 1:\\nInput: \"The staff were all partyin...  error   \n",
      "2  Example 1:\\nInput: \"Free edamame (nice perk) a...  error   \n",
      "3  Example 1:\\nInput: \"We had the tasting menu --...  error   \n",
      "4  Example 1:\\nInput: \"staff is still working out...  error   \n",
      "\n",
      "  structured_analysis unstructured_analysis  \n",
      "0                None                  None  \n",
      "1                None                  None  \n",
      "2                None                  None  \n",
      "3                None                  None  \n",
      "4                None                  None  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/_api/beta_decorator.py:86: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful AI.\n",
      "Human: Example 1:\n",
      "Input: \"Went here for a casual Sunday night dinner at 7:45pm; dinner was served at 10:15pm!\"\n",
      "Term: Sunday\n",
      "Output: neutral\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"The meal was improperly served.\"\n",
      "Term: meal\n",
      "Output: neutral\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"The service wasn't good -- dumplings were served after we had almost finished the main courses, drinks had to be asked for three times, etc.\"\n",
      "Term: service\n",
      "Output: negative\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: Had a party of 7 people for dinner here on a busy night for the restaurant, and our meal was excellent and served with extreme consistency (all appetizers and main courses were served at the right times, with none of the dishes served at the wrong temperature).\n",
      "Prompt: What is the sentiment in the text towards 'dinner'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: positive\n",
      "Human: Explain your prediction in a\n",
      "structured format, listing words or word groups you used for your decision and how important you deemed them for your decision. Each word or word group should be accompanied by a a score between 0 and\n",
      "1 that shows the importance of the attribute for the decision. All scores in total must add up to 1. Only include words that had an impact on the term's sentiment. \n",
      "Return the final result as JSON like in this example:\n",
      "[{\"adjective\":\"great\",\"importance\":\"0.50\"},\n",
      "{\"adjective\":\"liked\",\"importance\":\"0.45\"},\n",
      "{\"adjective\":\"did not satisfy\",\"importance\":\"0.05\"}]\n",
      "ONLY return the JSON.\n",
      "\n",
      "\n",
      "[{\"adjective\":\"excellent\",\"importance\":\"0.40\"},\n",
      "{\"adjective\":\"extreme consistency\",\"importance\":\"0.30\"},\n",
      "{\"adjective\":\"served at the right times\",\"importance\":\"0.20\"},\n",
      "{\"adjective\":\"none of the dishes served at the wrong temperature\",\"importance\":\"0.10\"}]\n",
      "\n",
      "\n",
      "0 of  100\n",
      "1\n",
      "System: You are a helpful AI.\n",
      "Human: Example 1:\n",
      "Input: \"The staff were all partying with each other at the bar, so even though we were the only ones there for food, it took 15 minutes to get menus.\"\n",
      "Term: staff\n",
      "Output: negative\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"We got the cold appetizer sampler and the dish was FULL of food, all for $12.\"\n",
      "Term: dish\n",
      "Output: neutral\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"The beginning of the meal wasnt bad, the hostess was very nice, we got our drinks about every 10 minutes and the appetizers we good.\"\n",
      "Term: hostess\n",
      "Output: positive\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: about 10 minutes apart each, so we were all eating cold eggs by the time we got our food.\n",
      "Prompt: What is the sentiment in the text towards 'food'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: negative\n",
      "Human: Explain your prediction in a\n",
      "structured format, listing words or word groups you used for your decision and how important you deemed them for your decision. Each word or word group should be accompanied by a a score between 0 and\n",
      "1 that shows the importance of the attribute for the decision. All scores in total must add up to 1. Only include words that had an impact on the term's sentiment. \n",
      "Return the final result as JSON like in this example:\n",
      "[{\"adjective\":\"great\",\"importance\":\"0.50\"},\n",
      "{\"adjective\":\"liked\",\"importance\":\"0.45\"},\n",
      "{\"adjective\":\"did not satisfy\",\"importance\":\"0.05\"}]\n",
      "ONLY return the JSON.\n",
      "\n",
      "\n",
      "[{\"adjective\":\"cold eggs\",\"importance\":\"0.70\"},\n",
      "{\"adjective\":\"about 10 minutes apart each\",\"importance\":\"0.30\"}]\n",
      "\n",
      "\n",
      "2\n",
      "System: You are a helpful AI.\n",
      "Human: Example 1:\n",
      "Input: \"Free edamame (nice perk) and we ordered four rolls between the two of us, and each of us had a drink.\"\n",
      "Term: edamame\n",
      "Output: positive\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"There are no vegetarian items on the menu, but when I requested that the chef make something meat-free for me, he came through with a dish just as delicious and pretty as those my friends were eating.\"\n",
      "Term: menu\n",
      "Output: neutral\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"Went to Chow Bar for dinner, I thought it was kind of pricey, but the food and the service was good - but it wasn't incredibly busy, so maybe they just had more free time to devote to us.\"\n",
      "Term: Chow Bar\n",
      "Output: neutral\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: Ok I got the edamame and something from the sushi chef for free, but the quality of food is more important to me than a free small dish (maybe that's why the restaurant gives it to attact new customers.\n",
      "Prompt: What is the sentiment in the text towards 'sushi chef'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: neutral\n",
      "Human: Explain your prediction in a\n",
      "structured format, listing words or word groups you used for your decision and how important you deemed them for your decision. Each word or word group should be accompanied by a a score between 0 and\n",
      "1 that shows the importance of the attribute for the decision. All scores in total must add up to 1. Only include words that had an impact on the term's sentiment. \n",
      "Return the final result as JSON like in this example:\n",
      "[{\"adjective\":\"great\",\"importance\":\"0.50\"},\n",
      "{\"adjective\":\"liked\",\"importance\":\"0.45\"},\n",
      "{\"adjective\":\"did not satisfy\",\"importance\":\"0.05\"}]\n",
      "ONLY return the JSON.\n",
      "\n",
      "\n",
      "[]\n",
      "\n",
      "\n",
      "3\n",
      "System: You are a helpful AI.\n",
      "Human: Example 1:\n",
      "Input: \"We had the tasting menu -- which was not a meal!!!\"\n",
      "Term: menu\n",
      "Output: positive\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"Then we were led downstairs to the main room, and were seated at the huge communal dining room table.\"\n",
      "Term: seated\n",
      "Output: neutral\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"5 hour meal (we ordered the tasting menu).\"\n",
      "Term: hour meal\n",
      "Output: neutral\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: Aside from the fact the maitre de claimed the dining room was 'full', we were seated at a great table overlooking the lobby of the hotel and ordered the 5 course tasting menu.\n",
      "Prompt: What is the sentiment in the text towards 'maitre'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: negative\n",
      "Human: Explain your prediction in a\n",
      "structured format, listing words or word groups you used for your decision and how important you deemed them for your decision. Each word or word group should be accompanied by a a score between 0 and\n",
      "1 that shows the importance of the attribute for the decision. All scores in total must add up to 1. Only include words that had an impact on the term's sentiment. \n",
      "Return the final result as JSON like in this example:\n",
      "[{\"adjective\":\"great\",\"importance\":\"0.50\"},\n",
      "{\"adjective\":\"liked\",\"importance\":\"0.45\"},\n",
      "{\"adjective\":\"did not satisfy\",\"importance\":\"0.05\"}]\n",
      "ONLY return the JSON.\n",
      "\n",
      "\n",
      "[{\"adjective\":\"claimed the dining room was 'full'\",\"importance\":\"1.00\"}]\n",
      "\n",
      "\n",
      "4\n",
      "System: You are a helpful AI.\n",
      "Human: Example 1:\n",
      "Input: \"staff is still working out their kinks and learning about the menu but no real complaints.\"\n",
      "Term: staff\n",
      "Output: positive\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"Ten minutes later: no burgers and no sign of our waiter.\"\n",
      "Term: burgers\n",
      "Output: neutral\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"We had to ask for water even after we were asked what type we preferred, and then the busboy spilled it while he was pouring it out.\"\n",
      "Term: water\n",
      "Output: neutral\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: We preferred to gaze at our burgers while avoiding having to look at the wait staff, but no complaints.\n",
      "Prompt: What is the sentiment in the text towards 'burgers'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: positive\n",
      "Human: Explain your prediction in a\n",
      "structured format, listing words or word groups you used for your decision and how important you deemed them for your decision. Each word or word group should be accompanied by a a score between 0 and\n",
      "1 that shows the importance of the attribute for the decision. All scores in total must add up to 1. Only include words that had an impact on the term's sentiment. \n",
      "Return the final result as JSON like in this example:\n",
      "[{\"adjective\":\"great\",\"importance\":\"0.50\"},\n",
      "{\"adjective\":\"liked\",\"importance\":\"0.45\"},\n",
      "{\"adjective\":\"did not satisfy\",\"importance\":\"0.05\"}]\n",
      "ONLY return the JSON.\n",
      "\n",
      "\n",
      "[{\"adjective\":\"preferred to gaze at\",\"importance\":\"1.0\"}]\n",
      "\n",
      "\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "50 of  100\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#Structured Analysis\n",
    "def execute(df, prompt, start = 0):\n",
    "    if(MODEL == \"gpt-3.5-turbo-instruct\"):\n",
    "        llm = OpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    else:\n",
    "        llm = ChatOpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    for i in range(len(df)):\n",
    "        if(df[\"structured_analysis\"][i] != None and df[\"structured_analysis\"][i] != \"error\"):\n",
    "            continue\n",
    "        print(i)\n",
    "        chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "        user_prompt = df.loc[i, 'prompt']\n",
    "        ai_answer = df.loc[i, 'polarity_pred']\n",
    "        try: \n",
    "            result = chain.run(user_prompt = user_prompt, ai_answer = str(ai_answer), callbacks=[handler])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = str(ai_answer)).to_string())\n",
    "            df['structured_analysis'][i] = 'error'\n",
    "            continue\n",
    "        handler.langfuse.flush()\n",
    "        prompt_text = chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = str(ai_answer)).to_string()\n",
    "        if (i < 5):\n",
    "            print(prompt_text)\n",
    "            print(\"\\n\")\n",
    "            print(result)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        if (i % 50 == 0):\n",
    "            print(str(i) + \" of  \" + str(len(df)))\n",
    "        df.loc[i, 'structured_analysis']= result\n",
    "    return df\n",
    "\n",
    "\n",
    "df = execute(df, prompt_structured)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "33\n",
      "Request timed out.\n",
      "System: You are a helpful AI.\n",
      "Human: Example 1:\n",
      "Input: \"The price is cheap - 5 dumplings for $1.\"\n",
      "Term: price\n",
      "Output: positive\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"The menu: HOT DOGS, that's it, nothing else.\"\n",
      "Term: menu\n",
      "Output: negative\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"And who else has this great wine list to go with pizza?\"\n",
      "Term: wine list\n",
      "Output: positive\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: There is nothing else on the menu except for exotic teas and cold beverages, but with a meal this cheap and delightful, who would care?\n",
      "Prompt: What is the sentiment in the text towards 'exotic teas'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: positive\n",
      "Human: Now explain concisely how you made your prediction and explicitly mention the words or word groups that had a high influence on your decision.\n",
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pw/9fnphybj4kq8t6wt3h592_9r0000gn/T/ipykernel_14512/3124840261.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['unstructured_analysis'][i] = 'error'\n",
      "/var/folders/pw/9fnphybj4kq8t6wt3h592_9r0000gn/T/ipykernel_14512/3124840261.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['unstructured_analysis'][i] = 'error'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "50 of  100\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#Unstructured Analysis\n",
    "def execute(df, prompt):\n",
    "    if(MODEL == \"gpt-3.5-turbo-instruct\"):\n",
    "        llm = OpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    else:\n",
    "        llm = ChatOpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    for i in range(len(df)):\n",
    "        if(df[\"unstructured_analysis\"][i] != None and df[\"unstructured_analysis\"][i] != \"error\"):\n",
    "            continue\n",
    "        print(i)\n",
    "        chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "        user_prompt = df.loc[i, 'prompt']\n",
    "        ai_answer = df.loc[i, 'polarity_pred']\n",
    "        try: \n",
    "            result = chain.run(user_prompt = user_prompt, ai_answer = str(ai_answer), callbacks=[handler])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = str(ai_answer)).to_string())\n",
    "            df['unstructured_analysis'][i] = 'error'\n",
    "            continue\n",
    "        handler.langfuse.flush()\n",
    "        prompt_text = chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = str(ai_answer)).to_string()\n",
    "        if (i < 5):\n",
    "            print(prompt_text)\n",
    "            print(\"\\n\")\n",
    "            print(result)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        if (i % 50 == 0):\n",
    "            print(str(i) + \" of  \" + str(len(df)))\n",
    "        df.loc[i, 'unstructured_analysis']= result\n",
    "    return df\n",
    "\n",
    "df = execute(df, prompt_unstructured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(OUTPUT_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
