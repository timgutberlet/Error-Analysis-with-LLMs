{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import error_prompts as p\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = os.environ.get(\"LANGFUSE_PUBLIC_KEY\")\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = os.environ.get(\"LANGFUSE_SECRET_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "handler = CallbackHandler()\n",
    "handler.auth_check()\n",
    "\n",
    "\n",
    "prompt_name_structured = 'structured_analysis'\n",
    "prompt_structured = p.structured_analysis\n",
    "prompt_name_unstructured = 'unstructured_analysis'\n",
    "prompt_unstructured = p.unstructured_analysis\n",
    "\n",
    "file = \"singleterm_fix_fewshot_4-turbo-preview\"\n",
    "\n",
    "DATA_PATH = f'../../Datasets/Evaluations/Sentiment Analysis/{file}.csv'\n",
    "OUTPUT_PATH = f\"../../Datasets/Evaluations/Sentiment Analysis/Error_Analysis/structured_unstructured/structured_unstructured_{file}.csv\"\n",
    "\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "TEMP = 0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "correct    269\n",
      "error      182\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df['error'] = None\n",
    "df['error'] = ['correct' if polarity == polarity_pred else 'error' for polarity, polarity_pred in zip(df['polarity'], df['polarity_pred'])]\n",
    "\n",
    "print(df['error'].value_counts())\n",
    "\n",
    "df_correct = df[df['error'] == 'correct']\n",
    "df_error = df[df['error'] == 'error']\n",
    "\n",
    "\n",
    "\n",
    "df_error_sample = df_error.sample(n=50)\n",
    "df_correct_sample = df_correct.sample(n=50)\n",
    "df = pd.concat([df_error_sample, df_correct_sample])\n",
    "df['structured_analysis'] = None\n",
    "df['unstructured_analysis'] = None\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 19)\n",
      "   Unnamed: 0.1  Unnamed: 0  text_id  term_id  \\\n",
      "0            40          40       14       40   \n",
      "1           196         196       76      196   \n",
      "2           436         436      165      436   \n",
      "3           449         449      169      449   \n",
      "4            29          29       10       29   \n",
      "\n",
      "                                                text     term  polarity  \\\n",
      "0  When my brother and I we had too much pizza in...    pizza  positive   \n",
      "1  dinner on 1st floor (street level) a bit noisy...   dinner   neutral   \n",
      "2  This place would be so much better served by b...   served  positive   \n",
      "3  The server came by only once to pour additiona...     fish   neutral   \n",
      "4  Ok I got the edamame and something from the su...  edamame   neutral   \n",
      "\n",
      "   example1_term_id                                    example1_prompt  \\\n",
      "0                 0  Input: \"The decor is not special at all but th...   \n",
      "1                 0  Input: \"The decor is not special at all but th...   \n",
      "2                 0  Input: \"The decor is not special at all but th...   \n",
      "3                 0  Input: \"The decor is not special at all but th...   \n",
      "4                 0  Input: \"The decor is not special at all but th...   \n",
      "\n",
      "   example2_term_id                                    example2_prompt  \\\n",
      "0                 3  Input: \"when tables opened up, the manager sat...   \n",
      "1                 3  Input: \"when tables opened up, the manager sat...   \n",
      "2                 3  Input: \"when tables opened up, the manager sat...   \n",
      "3                 3  Input: \"when tables opened up, the manager sat...   \n",
      "4                 3  Input: \"when tables opened up, the manager sat...   \n",
      "\n",
      "   example3_term_id                                    example3_prompt  \\\n",
      "0                 9  Input: \"service is good although a bit in your...   \n",
      "1                 9  Input: \"service is good although a bit in your...   \n",
      "2                 9  Input: \"service is good although a bit in your...   \n",
      "3                 9  Input: \"service is good although a bit in your...   \n",
      "4                 9  Input: \"service is good although a bit in your...   \n",
      "\n",
      "  polarity_pred                 prompt_name  \\\n",
      "0       neutral  prompt_single_term_fewshot   \n",
      "1      negative  prompt_single_term_fewshot   \n",
      "2      negative  prompt_single_term_fewshot   \n",
      "3      negative  prompt_single_term_fewshot   \n",
      "4      positive  prompt_single_term_fewshot   \n",
      "\n",
      "                                              prompt  error  \\\n",
      "0  Example 1:\\nInput: \"The decor is not special a...  error   \n",
      "1  Example 1:\\nInput: \"The decor is not special a...  error   \n",
      "2  Example 1:\\nInput: \"The decor is not special a...  error   \n",
      "3  Example 1:\\nInput: \"The decor is not special a...  error   \n",
      "4  Example 1:\\nInput: \"The decor is not special a...  error   \n",
      "\n",
      "  structured_analysis unstructured_analysis  \n",
      "0                None                  None  \n",
      "1                None                  None  \n",
      "2                None                  None  \n",
      "3                None                  None  \n",
      "4                None                  None  \n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Structured Analysis\n",
    "def execute(df, prompt, start = 0):\n",
    "    if(MODEL == \"gpt-3.5-turbo-instruct\"):\n",
    "        llm = OpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    else:\n",
    "        llm = ChatOpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    for i in range(len(df)):\n",
    "        if(df[\"structured_analysis\"][i] != None and df[\"structured_analysis\"][i] != \"error\"):\n",
    "            continue\n",
    "        print(i)\n",
    "        chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "        user_prompt = df.loc[i, 'prompt']\n",
    "        ai_answer = df.loc[i, 'polarity_pred']\n",
    "        try: \n",
    "            result = chain.run(user_prompt = user_prompt, ai_answer = str(ai_answer), callbacks=[handler])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = str(ai_answer)).to_string())\n",
    "            df['structured_analysis'][i] = 'error'\n",
    "            continue\n",
    "        handler.langfuse.flush()\n",
    "        prompt_text = chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = str(ai_answer)).to_string()\n",
    "        if (i < 5):\n",
    "            print(prompt_text)\n",
    "            print(\"\\n\")\n",
    "            print(result)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        if (i % 50 == 0):\n",
    "            print(str(i) + \" of  \" + str(len(df)))\n",
    "        df.loc[i, 'structured_analysis']= result\n",
    "    return df\n",
    "\n",
    "\n",
    "df = execute(df, prompt_structured)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unstructured Analysis\n",
    "def execute(df, prompt):\n",
    "    if(MODEL == \"gpt-3.5-turbo-instruct\"):\n",
    "        llm = OpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    else:\n",
    "        llm = ChatOpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    for i in range(len(df)):\n",
    "        if(df[\"unstructured_analysis\"][i] != None and df[\"unstructured_analysis\"][i] != \"error\"):\n",
    "            continue\n",
    "        print(i)\n",
    "        chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "        user_prompt = df.loc[i, 'prompt']\n",
    "        ai_answer = df.loc[i, 'polarity_pred']\n",
    "        try: \n",
    "            result = chain.run(user_prompt = user_prompt, ai_answer = str(ai_answer), callbacks=[handler])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = str(ai_answer)).to_string())\n",
    "            df['unstructured_analysis'][i] = 'error'\n",
    "            continue\n",
    "        handler.langfuse.flush()\n",
    "        prompt_text = chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = str(ai_answer)).to_string()\n",
    "        if (i < 5):\n",
    "            print(prompt_text)\n",
    "            print(\"\\n\")\n",
    "            print(result)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        if (i % 50 == 0):\n",
    "            print(str(i) + \" of  \" + str(len(df)))\n",
    "        df.loc[i, 'unstructured_analysis']= result\n",
    "    return df\n",
    "\n",
    "df = execute(df, prompt_unstructured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(OUTPUT_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
