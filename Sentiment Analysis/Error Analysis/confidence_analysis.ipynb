{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import error_prompts as p\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = os.environ.get(\"LANGFUSE_PUBLIC_KEY\")\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = os.environ.get(\"LANGFUSE_SECRET_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "handler = CallbackHandler()\n",
    "handler.auth_check()\n",
    "\n",
    "\n",
    "\n",
    "prompt_name = 'confidence'\n",
    "prompt = p.confidence\n",
    "\n",
    "file = \"singleterm_dynamic_fewshot_4-turbo-preview\"\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "DATA_PATH = f'../../Datasets/Evaluations/Sentiment Analysis/{file}.csv'\n",
    "OUTPUT_PATH = f\"../../Datasets/Evaluations/Sentiment Analysis/Error_Analysis/{prompt_name}_{file}_with_{MODEL}.csv\"\n",
    "TEMP = 0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0  text_id  term_id  \\\n",
      "0             0           0        0        0   \n",
      "1             1           1        0        1   \n",
      "2             2           2        0        2   \n",
      "3             3           3        0        3   \n",
      "4             4           4        1        4   \n",
      "\n",
      "                                                text  \\\n",
      "0  Amusing details distinguish desserts, from dul...   \n",
      "1  Amusing details distinguish desserts, from dul...   \n",
      "2  Amusing details distinguish desserts, from dul...   \n",
      "3  Amusing details distinguish desserts, from dul...   \n",
      "4  The server was so busy the night we visited th...   \n",
      "\n",
      "                          term  polarity  example1_term_id  \\\n",
      "0                     desserts  positive              9500   \n",
      "1     dulce de leche ice-cream   neutral              9500   \n",
      "2  chocolate sauce tic-tac-toe   neutral              9500   \n",
      "3            poached pineapple   neutral              9500   \n",
      "4                       server  negative              1211   \n",
      "\n",
      "                                     example1_prompt  example1_sim_score  \\\n",
      "0  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
      "1  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
      "2  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
      "3  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
      "4  Input: \"The server also forgot about our desse...            0.354028   \n",
      "\n",
      "   example2_term_id                                    example2_prompt  \\\n",
      "0              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
      "1              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
      "2              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
      "3              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
      "4              8639  Input: \"the 3rd however, the waiter forgot to ...   \n",
      "\n",
      "   example2_sim_score  example3_term_id  \\\n",
      "0            0.162247              1320   \n",
      "1            0.162247              1320   \n",
      "2            0.162247              1320   \n",
      "3            0.162247              1320   \n",
      "4            0.410810             10792   \n",
      "\n",
      "                                     example3_prompt  example3_sim_score  \\\n",
      "0  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
      "1  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
      "2  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
      "3  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
      "4  Input: \"We waited an hour for our appetizers, ...            0.416744   \n",
      "\n",
      "  polarity_pred                 prompt_name  \\\n",
      "0      positive  prompt_single_term_fewshot   \n",
      "1      positive  prompt_single_term_fewshot   \n",
      "2      positive  prompt_single_term_fewshot   \n",
      "3      positive  prompt_single_term_fewshot   \n",
      "4      negative  prompt_single_term_fewshot   \n",
      "\n",
      "                                              prompt  \n",
      "0  Example 1:\\nInput: \"Food is mediocre, except f...  \n",
      "1  Example 1:\\nInput: \"Food is mediocre, except f...  \n",
      "2  Example 1:\\nInput: \"Food is mediocre, except f...  \n",
      "3  Example 1:\\nInput: \"Food is mediocre, except f...  \n",
      "4  Example 1:\\nInput: \"The server also forgot abo...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['analysis'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "System: You are a helpful AI.\n",
      "Human: Example 1:\n",
      "Input: \"Food is mediocre, except for Mushroom Custard and Foie Gras in Fire Ice.\"\n",
      "Term: Food\n",
      "Output: negative\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"It was the WORST Sangria ever, and their house drink has just a shot of Malibu rum, and at a price of $9 you want more than a shot of a 40% alcohol.\"\n",
      "Term: Sangria\n",
      "Output: negative\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"The overpriced ice cream is delicious but the service is atrocious - not only do I have to wait to be admitted into this ice cream joint, but the waiter is a snide, gruff man more suited to be a trucker than an ice cream shop server.\"\n",
      "Term: service\n",
      "Output: negative\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: Amusing details distinguish desserts, from dulce de leche ice-cream profiteroles dotting a chocolate sauce tic-tac-toe board, to coconut custard surrounded by a sea of Malibu-rum gelee and poached pineapple.\n",
      "Prompt: What is the sentiment in the text towards 'desserts'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: positive\n",
      "Human: Now provide a confidence score for your decision. 100% referring\n",
      "    to full confidence. Take into account all relevant apsects of your decision. Please provide your answer exactly in the following format and do not return anything else.\n",
      "Confidence: <value>%\n",
      "\n",
      "\n",
      "Confidence: 90%\n",
      "\n",
      "\n",
      "0 of  451\n",
      "1\n",
      "System: You are a helpful AI.\n",
      "Human: Example 1:\n",
      "Input: \"Food is mediocre, except for Mushroom Custard and Foie Gras in Fire Ice.\"\n",
      "Term: Food\n",
      "Output: negative\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"It was the WORST Sangria ever, and their house drink has just a shot of Malibu rum, and at a price of $9 you want more than a shot of a 40% alcohol.\"\n",
      "Term: Sangria\n",
      "Output: negative\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"The overpriced ice cream is delicious but the service is atrocious - not only do I have to wait to be admitted into this ice cream joint, but the waiter is a snide, gruff man more suited to be a trucker than an ice cream shop server.\"\n",
      "Term: service\n",
      "Output: negative\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: Amusing details distinguish desserts, from dulce de leche ice-cream profiteroles dotting a chocolate sauce tic-tac-toe board, to coconut custard surrounded by a sea of Malibu-rum gelee and poached pineapple.\n",
      "Prompt: What is the sentiment in the text towards 'dulce de leche ice-cream'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: positive\n",
      "Human: Now provide a confidence score for your decision. 100% referring\n",
      "    to full confidence. Take into account all relevant apsects of your decision. Please provide your answer exactly in the following format and do not return anything else.\n",
      "Confidence: <value>%\n",
      "\n",
      "\n",
      "Confidence: 90%\n",
      "\n",
      "\n",
      "2\n",
      "System: You are a helpful AI.\n",
      "Human: Example 1:\n",
      "Input: \"Food is mediocre, except for Mushroom Custard and Foie Gras in Fire Ice.\"\n",
      "Term: Food\n",
      "Output: negative\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"It was the WORST Sangria ever, and their house drink has just a shot of Malibu rum, and at a price of $9 you want more than a shot of a 40% alcohol.\"\n",
      "Term: Sangria\n",
      "Output: negative\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"The overpriced ice cream is delicious but the service is atrocious - not only do I have to wait to be admitted into this ice cream joint, but the waiter is a snide, gruff man more suited to be a trucker than an ice cream shop server.\"\n",
      "Term: service\n",
      "Output: negative\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: Amusing details distinguish desserts, from dulce de leche ice-cream profiteroles dotting a chocolate sauce tic-tac-toe board, to coconut custard surrounded by a sea of Malibu-rum gelee and poached pineapple.\n",
      "Prompt: What is the sentiment in the text towards 'chocolate sauce tic-tac-toe'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: positive\n",
      "Human: Now provide a confidence score for your decision. 100% referring\n",
      "    to full confidence. Take into account all relevant apsects of your decision. Please provide your answer exactly in the following format and do not return anything else.\n",
      "Confidence: <value>%\n",
      "\n",
      "\n",
      "Confidence: 90%\n",
      "\n",
      "\n",
      "3\n",
      "System: You are a helpful AI.\n",
      "Human: Example 1:\n",
      "Input: \"Food is mediocre, except for Mushroom Custard and Foie Gras in Fire Ice.\"\n",
      "Term: Food\n",
      "Output: negative\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"It was the WORST Sangria ever, and their house drink has just a shot of Malibu rum, and at a price of $9 you want more than a shot of a 40% alcohol.\"\n",
      "Term: Sangria\n",
      "Output: negative\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"The overpriced ice cream is delicious but the service is atrocious - not only do I have to wait to be admitted into this ice cream joint, but the waiter is a snide, gruff man more suited to be a trucker than an ice cream shop server.\"\n",
      "Term: service\n",
      "Output: negative\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: Amusing details distinguish desserts, from dulce de leche ice-cream profiteroles dotting a chocolate sauce tic-tac-toe board, to coconut custard surrounded by a sea of Malibu-rum gelee and poached pineapple.\n",
      "Prompt: What is the sentiment in the text towards 'poached pineapple'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: positive\n",
      "Human: Now provide a confidence score for your decision. 100% referring\n",
      "    to full confidence. Take into account all relevant apsects of your decision. Please provide your answer exactly in the following format and do not return anything else.\n",
      "Confidence: <value>%\n",
      "\n",
      "\n",
      "Confidence: 90%\n",
      "\n",
      "\n",
      "4\n",
      "System: You are a helpful AI.\n",
      "Human: Example 1:\n",
      "Input: \"The server also forgot about our dessert.\"\n",
      "Term: server\n",
      "Output: negative\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"the 3rd however, the waiter forgot to put in our order for food and we ended up waiting an hour for them (b/c they were really busy).\"\n",
      "Term: waiter\n",
      "Output: negative\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"We waited an hour for our appetizers, (I suspect the waitress forgot to put in our order because the restaurant was not busy) and then the entrees came at the same time!\"\n",
      "Term: appetizers\n",
      "Output: neutral\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: The server was so busy the night we visited that she forgot to put in our food order.\n",
      "Prompt: What is the sentiment in the text towards 'server'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: negative\n",
      "Human: Now provide a confidence score for your decision. 100% referring\n",
      "    to full confidence. Take into account all relevant apsects of your decision. Please provide your answer exactly in the following format and do not return anything else.\n",
      "Confidence: <value>%\n",
      "\n",
      "\n",
      "Confidence: 90%\n",
      "\n",
      "\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "50 of  451\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "100 of  451\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "150 of  451\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "200 of  451\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "250 of  451\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "300 of  451\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "350 of  451\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "400 of  451\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "450 of  451\n"
     ]
    }
   ],
   "source": [
    "def execute(df, prompt):\n",
    "    if(MODEL == \"gpt-3.5-turbo-instruct\"):\n",
    "        llm = OpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    else:\n",
    "        llm = ChatOpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    for i in range(len(df)):\n",
    "        if(df[\"analysis\"][i] != None and df[\"analysis\"][i] != \"error\"):\n",
    "            continue\n",
    "        print(i)\n",
    "        chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "        user_prompt = df.loc[i, 'prompt']\n",
    "        ai_answer = df.loc[i, 'polarity_pred']\n",
    "        try: \n",
    "            result = chain.run(user_prompt = user_prompt, ai_answer = ai_answer, callbacks=[handler])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = ai_answer).to_string())\n",
    "            df['analysis'][i] = 'error'\n",
    "            continue\n",
    "        handler.langfuse.flush()\n",
    "        prompt_text = chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = ai_answer).to_string()\n",
    "        if (i < 5):\n",
    "            print(prompt_text)\n",
    "            print(\"\\n\")\n",
    "            print(result)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        if (i % 50 == 0):\n",
    "            print(str(i) + \" of  \" + str(len(df)))\n",
    "        df.loc[i, 'analysis']= result\n",
    "    return df\n",
    "\n",
    "\n",
    "df = execute(df, prompt)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Confidence: 90%\n",
      "1      Confidence: 90%\n",
      "2      Confidence: 90%\n",
      "3      Confidence: 90%\n",
      "4      Confidence: 90%\n",
      "            ...       \n",
      "446    Confidence: 90%\n",
      "447    Confidence: 80%\n",
      "448    Confidence: 80%\n",
      "449    Confidence: 90%\n",
      "450    Confidence: 70%\n",
      "Name: analysis, Length: 451, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['analysis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(OUTPUT_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
