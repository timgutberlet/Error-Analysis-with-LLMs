{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import error_prompts as p\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = os.environ.get(\"LANGFUSE_PUBLIC_KEY\")\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = os.environ.get(\"LANGFUSE_SECRET_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "handler = CallbackHandler()\n",
    "handler.auth_check()\n",
    "\n",
    "\n",
    "\n",
    "prompt_name = 'error_class_LLM'\n",
    "prompt = p.error_class_LLM\n",
    "\n",
    "file = \"structured_unstructured_singleterm_zeroshot_3.5-turbo\"\n",
    "\n",
    "DATA_PATH = f'../../Datasets/Evaluations/Sentiment Analysis/Error_Analysis/{file}.csv'\n",
    "OUTPUT_PATH = f\"../../Datasets/Evaluations/Sentiment Analysis/Error_Analysis/error_class_LLM_analysis.csv\"\n",
    "\n",
    "MODEL = \"gpt-4-turbo-preview\"\n",
    "TEMP = 0\n",
    "\n",
    "struct_unstruct = 'structured_analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 12) (20, 12)\n",
      "    Unnamed: 0  text_id  term_id  \\\n",
      "63         228       86      228   \n",
      "89         374      142      374   \n",
      "80         113       43      113   \n",
      "95          73       27       73   \n",
      "67         318      121      318   \n",
      "\n",
      "                                                 text         term  polarity  \\\n",
      "63  The mango salsa with fish cake was too sour, t...  apple suace  negative   \n",
      "89  My only advice is: increase portion sizes; and...      portion  positive   \n",
      "80  The staff was courteous and explained the menu...        staff  positive   \n",
      "95  We were so excited since I was reading great r...        place  negative   \n",
      "67  Once at the table our waitress managed on two ...       drinks   neutral   \n",
      "\n",
      "   polarity_pred                    prompt_name  \\\n",
      "63      negative  prompt_3_zeroshot_single_term   \n",
      "89      positive  prompt_3_zeroshot_single_term   \n",
      "80      positive  prompt_3_zeroshot_single_term   \n",
      "95      negative  prompt_3_zeroshot_single_term   \n",
      "67       neutral  prompt_3_zeroshot_single_term   \n",
      "\n",
      "                                               prompt    error  \\\n",
      "63  The mango salsa with fish cake was too sour, t...  correct   \n",
      "89  My only advice is: increase portion sizes; and...  correct   \n",
      "80  The staff was courteous and explained the menu...  correct   \n",
      "95  We were so excited since I was reading great r...  correct   \n",
      "67  Once at the table our waitress managed on two ...  correct   \n",
      "\n",
      "                                  structured_analysis  \\\n",
      "63     [{\"adjective\":\"too sweet\",\"importance\":\"1.0\"}]   \n",
      "89                                                 []   \n",
      "80  [{\"adjective\":\"courteous\",\"importance\":\"0.7\"},...   \n",
      "95  [{\"adjective\":\"excited\",\"importance\":\"0.20\"},\\...   \n",
      "67                                                 []   \n",
      "\n",
      "                                unstructured_analysis  \n",
      "63  The prediction was based on the adjective \"too...  \n",
      "89  The prediction was based on the context and th...  \n",
      "80  I determined the sentiment towards \"staff\" as ...  \n",
      "95  The prediction of \"negative\" sentiment towards...  \n",
      "67  My previous response was incorrect; the correc...  \n",
      "    Unnamed: 0  text_id  term_id  \\\n",
      "13         247       93      247   \n",
      "39         381      145      381   \n",
      "30          29       10       29   \n",
      "45         203       78      203   \n",
      "17         260       98      260   \n",
      "\n",
      "                                                 text                  term  \\\n",
      "13  The round pizza doesn't taste as good as I rec...           round pizza   \n",
      "39  Bouley has done an excellent job creating this...  dining establishment   \n",
      "30  Ok I got the edamame and something from the su...               edamame   \n",
      "45  The Clinton-frequented restaurant stands hands...                   bar   \n",
      "17  Food was much better than the average Indian p...                  area   \n",
      "\n",
      "    polarity polarity_pred                    prompt_name  \\\n",
      "13  negative       neutral  prompt_3_zeroshot_single_term   \n",
      "39   neutral      positive  prompt_3_zeroshot_single_term   \n",
      "30   neutral      positive  prompt_3_zeroshot_single_term   \n",
      "45  negative       neutral  prompt_3_zeroshot_single_term   \n",
      "17   neutral      positive  prompt_3_zeroshot_single_term   \n",
      "\n",
      "                                               prompt  error  \\\n",
      "13  The round pizza doesn't taste as good as I rec...  error   \n",
      "39  Bouley has done an excellent job creating this...  error   \n",
      "30  Ok I got the edamame and something from the su...  error   \n",
      "45  The Clinton-frequented restaurant stands hands...  error   \n",
      "17  Food was much better than the average Indian p...  error   \n",
      "\n",
      "                                  structured_analysis  \\\n",
      "13     [{\"adjective\":\"wonderful\",\"importance\":\"1.0\"}]   \n",
      "39  [{\"adjective\":\"excellent\",\"importance\":\"0.70\"}...   \n",
      "30                                                 []   \n",
      "45                                                 []   \n",
      "17  [{\"adjective\":\"better\",\"importance\":\"0.7\"},{\"a...   \n",
      "\n",
      "                                unstructured_analysis  \n",
      "13  The sentiment towards \"round pizza\" was determ...  \n",
      "39  The prediction of a \"positive\" sentiment towar...  \n",
      "30  The prediction was based on the absence of exp...  \n",
      "45  The sentiment prediction for \"bar\" as \"neutral...  \n",
      "17  The sentiment prediction of \"positive\" towards...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df_correct = df[df['error'] == 'correct']\n",
    "df_correct_samples = df_correct.sample(n=5, random_state=42)\n",
    "\n",
    "df_error = df[df['error'] == 'error']\n",
    "df_error_samples = df_error.sample(n=20, random_state=42)\n",
    "\n",
    "print(df_correct_samples.shape, df_error_samples.shape)\n",
    "print(df_correct_samples.head())\n",
    "print(df_error_samples.head())\n",
    "\n",
    "if os.path.exists(OUTPUT_PATH):\n",
    "    df_answer = pd.read_csv(OUTPUT_PATH)\n",
    "else:\n",
    "    df_answer = pd.DataFrame(columns=['Prompt_Name', 'Prompt', 'Model', 'Database', 'Answer', 'Context'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/_api/beta_decorator.py:86: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the following I will give you a few Aspect Based Sentiment Analysis tasks together with a sentiment decision, details about the decision and the sentiment towards each term.\n",
      "The Prediction was made by an LLM.\n",
      "Can you please group the wrong decisions into fault categories? Please also indicate how often each one occurs.\n",
      "There are also some correct decisions in the examples. Please just use them as a reference and don't categorize them.\n",
      "False Decisions:\n",
      "Task 1:\n",
      "Prompt: The round pizza doesn't taste as good as I recall, it's still wonderful, but the Sicilian is to die for.\n",
      "\n",
      "    What is the sentiment on 'round pizza'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: neutral\n",
      "Explanation: [{\"adjective\":\"wonderful\",\"importance\":\"1.0\"}]\n",
      "Actual Sentiment: negative\n",
      "Task 2:\n",
      "Prompt: Bouley has done an excellent job creating this dining establishment with almost a museum sense, the artworks on the wall have a very Klimty feeling and the gold ceiling completes the rest of the experience.\n",
      "\n",
      "    What is the sentiment on 'dining establishment'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: positive\n",
      "Explanation: [{\"adjective\":\"excellent\",\"importance\":\"0.70\"},{\"adjective\":\"museum sense\",\"importance\":\"0.20\"},{\"adjective\":\"Klimty feeling\",\"importance\":\"0.10\"}]\n",
      "Actual Sentiment: neutral\n",
      "Task 3:\n",
      "Prompt: Ok I got the edamame and something from the sushi chef for free, but the quality of food is more important to me than a free small dish (maybe that's why the restaurant gives it to attact new customers.\n",
      "\n",
      "    What is the sentiment on 'edamame'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: positive\n",
      "Explanation: []\n",
      "Actual Sentiment: neutral\n",
      "Task 4:\n",
      "Prompt: The Clinton-frequented restaurant stands handsomely on a quiet residential corner, and the modern interior includes a long dining room, a small bar and harsh lighting.\n",
      "\n",
      "    What is the sentiment on 'bar'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: neutral\n",
      "Explanation: []\n",
      "Actual Sentiment: negative\n",
      "Task 5:\n",
      "Prompt: Food was much better than the average Indian place in the area, and more interesting.\n",
      "\n",
      "    What is the sentiment on 'area'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: positive\n",
      "Explanation: [{\"adjective\":\"better\",\"importance\":\"0.7\"},{\"adjective\":\"interesting\",\"importance\":\"0.3\"}]\n",
      "Actual Sentiment: neutral\n",
      "Task 6:\n",
      "Prompt: While the service and setting were average, the food was excellent.\n",
      "\n",
      "    What is the sentiment on 'service'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: neutral\n",
      "Explanation: [{\"adjective\":\"average\",\"importance\":\"1.00\"}]\n",
      "Actual Sentiment: negative\n",
      "Task 7:\n",
      "Prompt: (Though the filet won't be enough if both have hearty apitites.\n",
      "\n",
      "    What is the sentiment on 'filet'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: neutral\n",
      "Explanation: []\n",
      "Actual Sentiment: negative\n",
      "Task 8:\n",
      "Prompt: We were so excited since I was reading great review of this place, however we were disappointed with the taste of the food.\n",
      "\n",
      "    What is the sentiment on 'food'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: negative\n",
      "Explanation: [{\"adjective\":\"disappointed\",\"importance\":\"1.00\"}]\n",
      "Actual Sentiment: positive\n",
      "Task 9:\n",
      "Prompt: I ordered the fried catfish, which had very little to no seasoning, the yams, and mac and cheese which were just okay.\n",
      "\n",
      "    What is the sentiment on 'mac and cheese'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: neutral\n",
      "Explanation: []\n",
      "Actual Sentiment: positive\n",
      "Task 10:\n",
      "Prompt: The bill came out to like $100pp, and noone touched their food, and drinks were left untouched because after the first bite/sip you want to never touch it again.\n",
      "\n",
      "    What is the sentiment on 'food'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: negative\n",
      "Explanation: [{\"adjective\":\"untouched\",\"importance\":\"0.40\"},{\"adjective\":\"left\",\"importance\":\"0.30\"},{\"adjective\":\"never\",\"importance\":\"0.30\"}]\n",
      "Actual Sentiment: neutral\n",
      "Task 11:\n",
      "Prompt: The service was polite, friendly and prompt, the characters walking around entertained the kids but werent intrusive to our meal.\n",
      "\n",
      "    What is the sentiment on 'meal'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: positive\n",
      "Explanation: [{\"adjective\":\"polite\",\"importance\":\"0.25\"},{\"adjective\":\"friendly\",\"importance\":\"0.25\"},{\"adjective\":\"prompt\",\"importance\":\"0.25\"},{\"adjective\":\"entertained\",\"importance\":\"0.25\"}]\n",
      "Actual Sentiment: neutral\n",
      "Task 12:\n",
      "Prompt: about 10 minutes apart each, so we were all eating cold eggs by the time we got our food.\n",
      "\n",
      "    What is the sentiment on 'eggs'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: neutral\n",
      "Explanation: []\n",
      "Actual Sentiment: negative\n",
      "Task 13:\n",
      "Prompt: This place would be so much better served by being run by a group that actually understands customer service.\n",
      "\n",
      "    What is the sentiment on 'served'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: negative\n",
      "Explanation: [{\"adjective\":\"better\",\"importance\":\"0.6\"},\n",
      "{\"adjective\":\"actually understands\",\"importance\":\"0.4\"}]\n",
      "Actual Sentiment: positive\n",
      "Task 14:\n",
      "Prompt: We had no problems with our resevations and found the service and the meal well worth a wait, had we run into one.\n",
      "\n",
      "    What is the sentiment on 'meal'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: positive\n",
      "Explanation: [{\"adjective\":\"well worth\",\"importance\":\"1.00\"}]\n",
      "Actual Sentiment: neutral\n",
      "Task 15:\n",
      "Prompt: We sat at the bar and were constantly bumped by the waitress flying past; had fabulously fresh raw oysters with pieces of shell in every bite; lobsters rolls were tasty but the large pieces of meat were tough; the apple crumble was excellent but the ice cream was over-frozen and the stench of frying oil was nearly unbearable.\n",
      "\n",
      "    What is the sentiment on 'rolls'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: negative\n",
      "Explanation: [{\"adjective\":\"tasty\",\"importance\":\"0.4\"},{\"adjective\":\"large\",\"importance\":\"0.1\"},{\"adjective\":\"tough\",\"importance\":\"0.5\"}]\n",
      "Actual Sentiment: positive\n",
      "Task 16:\n",
      "Prompt: After all that, the waiter tried to backpedal saying its too hard to time the cooking of miso soup with the sushi bar offerings.\n",
      "\n",
      "    What is the sentiment on 'waiter'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: neutral\n",
      "Explanation: []\n",
      "Actual Sentiment: negative\n",
      "Task 17:\n",
      "Prompt: The food is delish, you just have to know the manners to consume, if you don't want to be frustrated with the service.\n",
      "\n",
      "    What is the sentiment on 'service'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: neutral\n",
      "Explanation: []\n",
      "Actual Sentiment: negative\n",
      "Task 18:\n",
      "Prompt: Had a party of 7 people for dinner here on a busy night for the restaurant, and our meal was excellent and served with extreme consistency (all appetizers and main courses were served at the right times, with none of the dishes served at the wrong temperature).\n",
      "\n",
      "    What is the sentiment on 'dinner'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: positive\n",
      "Explanation: [{\"adjective\":\"excellent\",\"importance\":\"0.6\"},{\"adjective\":\"extreme consistency\",\"importance\":\"0.4\"}]\n",
      "Actual Sentiment: neutral\n",
      "Task 19:\n",
      "Prompt: For the main course, try out the Beef Negimaki.\n",
      "\n",
      "    What is the sentiment on 'main course'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: positive\n",
      "Explanation: []\n",
      "Actual Sentiment: neutral\n",
      "Task 20:\n",
      "Prompt: My husband and I had dinner here last week and the food was very good.\n",
      "\n",
      "    What is the sentiment on 'dinner'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: positive\n",
      "Explanation: [{\"adjective\":\"very good\",\"importance\":\"1.00\"}]\n",
      "Actual Sentiment: neutral\n",
      "\n",
      "Correct Decisions (Only as a reference):\n",
      "Task 21:\n",
      "Prompt: The mango salsa with fish cake was too sour, the apple suace for pork chop too sweet.\n",
      "\n",
      "    What is the sentiment on 'apple suace'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: negative\n",
      "Explanation: [{\"adjective\":\"too sweet\",\"importance\":\"1.0\"}]\n",
      "Actual Sentiment: negative\n",
      "Task 22:\n",
      "Prompt: My only advice is: increase portion sizes; and develop a special drink list.\n",
      "\n",
      "    What is the sentiment on 'portion'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: positive\n",
      "Explanation: []\n",
      "Actual Sentiment: positive\n",
      "Task 23:\n",
      "Prompt: The staff was courteous and explained the menu with detail.\n",
      "\n",
      "    What is the sentiment on 'staff'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: positive\n",
      "Explanation: [{\"adjective\":\"courteous\",\"importance\":\"0.7\"},{\"adjective\":\"explained\",\"importance\":\"0.3\"}]\n",
      "Actual Sentiment: positive\n",
      "Task 24:\n",
      "Prompt: We were so excited since I was reading great review of this place, however we were disappointed with the taste of the food.\n",
      "\n",
      "    What is the sentiment on 'place'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: negative\n",
      "Explanation: [{\"adjective\":\"excited\",\"importance\":\"0.20\"},\n",
      "{\"adjective\":\"great\",\"importance\":\"0.30\"},\n",
      "{\"adjective\":\"disappointed\",\"importance\":\"0.50\"}]\n",
      "Actual Sentiment: negative\n",
      "Task 25:\n",
      "Prompt: Once at the table our waitress managed on two occasions to take 15 minutes bringing drinks to our table, our plates sat uncleared on the table for just as long.\n",
      "\n",
      "    What is the sentiment on 'drinks'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "Sentiment Decision: neutral\n",
      "Explanation: []\n",
      "Actual Sentiment: neutral\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Based on the provided false decisions, we can categorize the errors into several fault categories:\n",
      "\n",
      "1. **Misinterpretation of Context or Aspect**:\n",
      "   - Task 1: The sentiment towards \"round pizza\" was misinterpreted due to the context not being properly analyzed.\n",
      "   - Task 4: The sentiment towards \"bar\" was neutral instead of negative, likely due to missing the context of being \"constantly bumped by the waitress.\"\n",
      "   - Task 7: The sentiment towards \"filet\" was neutral instead of negative, possibly due to not understanding the implication of not being enough.\n",
      "   - Task 12: The sentiment towards \"eggs\" was neutral instead of negative, likely due to missing the negative context of eating cold eggs.\n",
      "   - Task 16: The sentiment towards \"waiter\" was neutral instead of negative, likely due to not capturing the negative implication of the waiter's action.\n",
      "   - Task 17: The sentiment towards \"service\" was neutral instead of negative, likely due to not capturing the negative implication of needing to know manners to avoid frustration.\n",
      "\n",
      "   **Occurrences**: 6\n",
      "\n",
      "2. **Incorrect Sentiment Polarity**:\n",
      "   - Task 8: The sentiment towards \"food\" was incorrectly identified as negative instead of positive.\n",
      "   - Task 13: The sentiment towards \"served\" was incorrectly identified as negative instead of positive.\n",
      "   - Task 15: The sentiment towards \"rolls\" was incorrectly identified as negative instead of positive.\n",
      "\n",
      "   **Occurrences**: 3\n",
      "\n",
      "3. **Failure to Recognize Neutral Sentiment**:\n",
      "   - Task 2: The sentiment towards \"dining establishment\" was identified as positive instead of neutral.\n",
      "   - Task 5: The sentiment towards \"area\" was identified as positive instead of neutral.\n",
      "   - Task 11: The sentiment towards \"meal\" was identified as positive instead of neutral.\n",
      "   - Task 14: The sentiment towards \"meal\" was identified as positive instead of neutral.\n",
      "   - Task 18: The sentiment towards \"dinner\" was identified as positive instead of neutral.\n",
      "   - Task 19: The sentiment towards \"main course\" was identified as positive instead of neutral.\n",
      "   - Task 20: The sentiment towards \"dinner\" was identified as positive instead of neutral.\n",
      "\n",
      "   **Occurrences**: 7\n",
      "\n",
      "4. **Overlooking Implicit Sentiment**:\n",
      "   - Task 3: The sentiment towards \"edamame\" was positive instead of neutral, likely due to overlooking the implicit sentiment.\n",
      "   - Task 9: The sentiment towards \"mac and cheese\" was neutral instead of positive, likely due to not capturing the implicit sentiment.\n",
      "   - Task 10: The sentiment towards \"food\" was negative instead of neutral, likely due to misinterpreting the context.\n",
      "\n",
      "   **Occurrences**: 3\n",
      "\n",
      "5. **Incorrect Sentiment Due to Lack of Explanation**:\n",
      "   - Several tasks (e.g., Task 3, Task 4, Task 7, Task 9, Task 12, Task 16, Task 17) had incorrect sentiment decisions without any explanation provided, indicating a failure to analyze or justify the sentiment decision.\n",
      "\n",
      "   **Occurrences**: This is a pervasive issue across multiple tasks but is part of the underlying problems already categorized above.\n",
      "\n",
      "In summary, the main fault categories are Misinterpretation of Context or Aspect (6 occurrences), Incorrect Sentiment Polarity (3 occurrences), Failure to Recognize Neutral Sentiment (7 occurrences), and Overlooking Implicit Sentiment (3 occurrences).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def execute(df, prompt, df_answer):\n",
    "    i = 1\n",
    "    if(MODEL == \"gpt-3.5-turbo-instruct\"):\n",
    "        llm = OpenAI(model_name = MODEL, temperature = TEMP, timeout=150)\n",
    "    else:\n",
    "        llm = ChatOpenAI(model_name = MODEL, temperature = TEMP, timeout=150)\n",
    "    examples = \"\"\n",
    "    examples += \"False Decisions:\\n\"\n",
    "    for j in range(len(df_error_samples)):\n",
    "        examples += f\"Task {i}:\\n\"\n",
    "        examples += \"Prompt: \" + df_error_samples.iloc[j]['prompt'] + \"\\n\"\n",
    "        examples += \"Sentiment Decision: \" + str(df_error_samples.iloc[j]['polarity_pred']) + \"\\n\"\n",
    "        examples += \"Explanation: \" + df_error_samples.iloc[j][struct_unstruct] + \"\\n\"\n",
    "        examples += \"Actual Sentiment: \" + str(df_error_samples.iloc[j]['polarity']) + \"\\n\"\n",
    "        i += 1\n",
    "    examples += \"\\nCorrect Decisions (Only as a reference):\\n\"\n",
    "    for j in range(len(df_correct_samples)):\n",
    "        examples += f\"Task {i}:\\n\"\n",
    "        examples += \"Prompt: \" + df_correct_samples.iloc[j]['prompt'] + \"\\n\"\n",
    "        examples += \"Sentiment Decision: \" + str(df_correct_samples.iloc[j]['polarity_pred']) + \"\\n\"\n",
    "        examples += \"Explanation: \" + df_correct_samples.iloc[j][struct_unstruct] + \"\\n\"\n",
    "        examples += \"Actual Sentiment: \" + str(df_correct_samples.iloc[j]['polarity']) + \"\\n\"\n",
    "        i += 1\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "    try: \n",
    "        result = chain.run(examples = examples, callbacks=[handler])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(chain.prompt.format_prompt(examples = examples).to_string())\n",
    "    handler.langfuse.flush()\n",
    "    prompt_text = chain.prompt.format_prompt(examples = examples).to_string()\n",
    "    print(prompt_text)\n",
    "    print(\"\\n\")\n",
    "    print(result)\n",
    "    print(\"\\n\")\n",
    "    new_row = {'Prompt_Name': prompt_name, 'Prompt': prompt_text, 'Model': MODEL, 'Database': file, 'Answer': result, 'Context': struct_unstruct}\n",
    "    df_new_row = pd.DataFrame([new_row])\n",
    "    df_answer = pd.concat([df_answer, df_new_row])\n",
    "    return result, df_answer\n",
    "\n",
    "\n",
    "answer, df_answer = execute(df, prompt, df_answer)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Prompt_Name                                             Prompt  \\\n",
      "0  error_class_LLM  In the following I will give you a few Aspect ...   \n",
      "0  error_class_LLM  In the following I will give you a few Aspect ...   \n",
      "\n",
      "                 Model                                           Database  \\\n",
      "0        gpt-3.5-turbo  structured_unstructured_singleterm_zeroshot_3....   \n",
      "0  gpt-4-turbo-preview  structured_unstructured_singleterm_zeroshot_3....   \n",
      "\n",
      "                                              Answer              Context  \n",
      "0  Fault Categories:\\n1. Incorrect sentiment due ...  structured_analysis  \n",
      "0  Based on the provided false decisions, we can ...  structured_analysis  \n"
     ]
    }
   ],
   "source": [
    "print(df_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answer.to_csv(OUTPUT_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
