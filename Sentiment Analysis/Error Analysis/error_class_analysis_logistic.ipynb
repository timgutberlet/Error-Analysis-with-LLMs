{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import error_prompts as p\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = os.environ.get(\"LANGFUSE_PUBLIC_KEY\")\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = os.environ.get(\"LANGFUSE_SECRET_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "handler = CallbackHandler()\n",
    "handler.auth_check()\n",
    "\n",
    "prompt_name = 'error_class_ML'\n",
    "prompt = p.error_class_ML\n",
    "\n",
    "file = \"logistic_regression\"\n",
    "\n",
    "DATA_PATH = f'../../Datasets/Evaluations/Sentiment Analysis/{file}.csv'\n",
    "OUTPUT_PATH = f\"../../Datasets/Evaluations/Sentiment Analysis/Error_Analysis/error_class_LLM_analysis.csv\"\n",
    "\n",
    "MODEL = \"gpt-4-turbo-preview\"\n",
    "TEMP = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 9) (20, 9)\n",
      "     Unnamed: 0  text_id  term_id  \\\n",
      "124         124       47      124   \n",
      "400         400      152      400   \n",
      "71           71       26       71   \n",
      "275         275      105      275   \n",
      "220         220       83      220   \n",
      "\n",
      "                                                  text        term  polarity  \\\n",
      "124  Not including the tip for our server, who we s...      server  negative   \n",
      "400  THe bartendars were right on top of getting us...  bartendars  positive   \n",
      "71   Ive had better burgers and fries at the local ...       fries  positive   \n",
      "275  The Scene Shun Lee Palace is popular with midt...       lunch   neutral   \n",
      "220  The service was non-existant, the manager spen...         bar   neutral   \n",
      "\n",
      "    polarity_pred                                      token_weights    error  \n",
      "124      negative  not : 2.476956248275856, including : -0.154560...  correct  \n",
      "400      positive  the : 0.1599567509788442, bartendars : -0.0945...  correct  \n",
      "71       positive  ive : -0.2945337453645926, had : 0.18830730092...  correct  \n",
      "275       neutral  the : 0.1599567509788442, scene : -0.505041831...  correct  \n",
      "220       neutral  the : 0.1599567509788442, service : -0.6849207...  correct  \n",
      "     Unnamed: 0  text_id  term_id  \\\n",
      "364         364      138      364   \n",
      "144         144       56      144   \n",
      "380         380      144      380   \n",
      "444         444      168      444   \n",
      "256         256       96      256   \n",
      "\n",
      "                                                  text         term  polarity  \\\n",
      "364  I'm totally into the space-age vibe of this pl...       tables  positive   \n",
      "144  The bill came out to like $100pp, and noone to...         food   neutral   \n",
      "380  Aside from the fact the maitre de claimed the ...         menu  positive   \n",
      "444  The smoked salmon appetizer was pretty good (i...  goat cheese   neutral   \n",
      "256  I would have told the wait staff if anyone had...         meal  positive   \n",
      "\n",
      "    polarity_pred                                      token_weights  error  \n",
      "364      negative  totally : 0.6466147231399947, into : 0.2445286...  error  \n",
      "144      negative  the : 0.1599567509788442, bill : 0.22652629920...  error  \n",
      "380       neutral  aside : -0.13705889465649937, from : -0.565724...  error  \n",
      "444      positive  the : 0.1599567509788442, smoked : -0.38364260...  error  \n",
      "256       neutral  would : 0.001138306716972844, have : -0.274375...  error  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df['error'] = None\n",
    "df['error'] = ['correct' if polarity == polarity_pred else 'error' for polarity, polarity_pred in zip(df['polarity'], df['polarity_pred'])]\n",
    "\n",
    "df_correct = df[df['error'] == 'correct']\n",
    "df_correct_samples = df_correct.sample(n=5, random_state=42)\n",
    "\n",
    "df_error = df[df['error'] == 'error']\n",
    "df_error_samples = df_error.sample(n=20, random_state=42)\n",
    "\n",
    "print(df_correct_samples.shape, df_error_samples.shape)\n",
    "print(df_correct_samples.head())\n",
    "print(df_error_samples.head())\n",
    "\n",
    "if os.path.exists(OUTPUT_PATH):\n",
    "    df_answer = pd.read_csv(OUTPUT_PATH)\n",
    "else:\n",
    "    df_answer = pd.DataFrame(columns=['Prompt_Name', 'Prompt', 'Model', 'Database', 'Answer', 'Context'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/_api/beta_decorator.py:86: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the following I will give you a few Aspect Based Sentiment Analysis tasks together with the sentiment decision towards a specific term, details about the decision and the actualsentiment towards each term.\n",
      "The decision was made by a Logistic Regression Machine Learning Model and the additional information shows the weights the model assigned to the different tokens. \n",
      "Can you please group the wrong decisions into distinct fault categories? Please also indicate how often each one occurs.\n",
      "There are also some correct decisions in the examples. Please just use them as a reference and don't categorize them.\n",
      "False Decisions:\n",
      "Task 1:\n",
      "Text: I'm totally into the space-age vibe of this place, but I wish they had more tables to sit down at.\n",
      "Sentiment Decision towards the term 'tables': negative\n",
      "Explanation: totally : 0.6466147231399947, into : 0.24452865139758487, the : 0.1599567509788442, space : -0.5407900591076409, age : -0.037666791864239324, vibe : 0.529004771560355, of : -0.6721133239838706, this : 0.3789860937031017, place : 0.11506505080479565, but : 2.041756649529249, wish : -0.29932263221102606, they : 0.25283930947630323, had : 0.18830730092669362, more : 0.051931762943816365, tables : 0.23007761462199655, to : 0.06489666268372277, sit : -0.2560819469492547, down : 0.374149510220527, at : 0.38667932060354876\n",
      "Actual Sentiment: positive\n",
      "Task 2:\n",
      "Text: The bill came out to like $100pp, and noone touched their food, and drinks were left untouched because after the first bite/sip you want to never touch it again.\n",
      "Sentiment Decision towards the term 'food': negative\n",
      "Explanation: the : 0.1599567509788442, bill : 0.22652629920906217, came : 0.3629264328992799, out : 0.3215012191840598, to : 0.06489666268372277, like : 0.40025356483795693, and : -1.4714550858778395, touched : 0.18460901666251261, their : 0.07711885811693396, food : 0.7708413724540557, and : -1.4714550858778395, drinks : 0.24304548432262396, were : 1.1689934909553437, left : 0.5363649796943715, because : -0.00010587399627824544, after : 0.13354266707787985, the : 0.1599567509788442, first : 0.3239233717115285, bite : -0.043066341959204314, sip : -0.24324725593587598, you : -0.3419709413939751, want : 0.3928114454338783, to : 0.06489666268372277, never : 1.170183354302736, touch : 0.08207961339500311, it : 0.25400665821968343, again : 0.38431023348607984\n",
      "Actual Sentiment: neutral\n",
      "Task 3:\n",
      "Text: Aside from the fact the maitre de claimed the dining room was 'full', we were seated at a great table overlooking the lobby of the hotel and ordered the 5 course tasting menu.\n",
      "Sentiment Decision towards the term 'menu': neutral\n",
      "Explanation: aside : -0.13705889465649937, from : -0.5657247889759164, the : 0.1599567509788442, fact : 0.19151156931666066, the : 0.1599567509788442, maitre : 0.4087593747477173, de : 0.17945842872799, claimed : 0.19308604339801377, the : 0.1599567509788442, dining : -0.3332034301718927, room : -0.20470241715673637, was : 0.6756384514067241, full : 0.19315598168217046, we : -0.3054258736797305, were : 1.1689934909553437, seated : -0.27835617230821097, at : 0.38667932060354876, great : -1.2287146505139575, table : -0.0694763892292324, overlooking : -0.2356339733537667, the : 0.1599567509788442, of : -0.6721133239838706, the : 0.1599567509788442, hotel : -0.10503797040897063, and : -1.4714550858778395, ordered : 0.030509662853600114, the : 0.1599567509788442, course : -0.011091552786787234, tasting : -0.40720076470026606, menu : -0.8412156567032758\n",
      "Actual Sentiment: positive\n",
      "Task 4:\n",
      "Text: The smoked salmon appetizer was pretty good (it comes with goat cheese, calpers and onions).\n",
      "Sentiment Decision towards the term 'goat cheese': positive\n",
      "Explanation: the : 0.1599567509788442, smoked : -0.38364260593198457, salmon : 0.14486045591387042, appetizer : -0.5349709557403795, was : 0.6756384514067241, pretty : 0.33606498299862325, good : -0.9579341139312253, it : 0.25400665821968343, comes : -0.38012892021647365, with : -1.066377583521574, goat : -0.38078113436569183, cheese : -0.1754919695016529, and : -1.4714550858778395, onions : -0.050248319077073396\n",
      "Actual Sentiment: neutral\n",
      "Task 5:\n",
      "Text: I would have told the wait staff if anyone had asked me if I enjoyed my meal, but no one asked.\n",
      "Sentiment Decision towards the term 'meal': neutral\n",
      "Explanation: would : 0.001138306716972844, have : -0.27437593717006287, told : 0.3188392645115736, the : 0.1599567509788442, wait : -0.6531231529058147, staff : -0.9159157659545786, if : -0.3074812693504518, anyone : 0.10595097666573178, had : 0.18830730092669362, asked : 0.300045530808483, me : 0.3166855568174938, if : -0.3074812693504518, enjoyed : -0.9126477935335755, my : -0.0024860046636431283, meal : 0.4892785749222883, but : 2.041756649529249, no : 1.7366660081154697, one : 0.23332637109315876, asked : 0.300045530808483\n",
      "Actual Sentiment: positive\n",
      "Task 6:\n",
      "Text: Their bagels have the perfect softness to them, but on the outside there's a bit of crispiness to give it a bit of texture.\n",
      "Sentiment Decision towards the term 'bagels': neutral\n",
      "Explanation: their : 0.07711885811693396, bagels : -0.16759809310904322, have : -0.27437593717006287, the : 0.1599567509788442, perfect : -0.8283839966382349, to : 0.06489666268372277, them : 0.28104345568005157, but : 2.041756649529249, on : -0.13037870958757733, the : 0.1599567509788442, outside : 0.2625223883805178, there : -0.6327836073639417, bit : 0.8602740774544523, of : -0.6721133239838706, to : 0.06489666268372277, give : 0.15101277984413203, it : 0.25400665821968343, bit : 0.8602740774544523, of : -0.6721133239838706, texture : -0.0237388492037025\n",
      "Actual Sentiment: positive\n",
      "Task 7:\n",
      "Text: After our meal,the manager, even took some of his time to sit with us and give us a lesson in Sake 101.\n",
      "Sentiment Decision towards the term 'manager': negative\n",
      "Explanation: after : 0.13354266707787985, our : 0.05402355815250684, meal : 0.4892785749222883, the : 0.1599567509788442, manager : -0.15221989383215045, even : 0.37380635437741094, took : 0.6437041530593963, some : 0.15993661200334705, of : -0.6721133239838706, his : -0.08952200287059758, time : -0.10786788689349683, to : 0.06489666268372277, sit : -0.2560819469492547, with : -1.066377583521574, us : -0.07882380616122509, and : -1.4714550858778395, give : 0.15101277984413203, us : -0.07882380616122509, in : 0.17410305733559264, sake : 0.2527195245831207, 101 : -0.24502115904346097\n",
      "Actual Sentiment: positive\n",
      "Task 8:\n",
      "Text: The Scene Shun Lee Palace is popular with midtown locals, possibly because the upscale room means you can impress a client and have Chinese for lunch at the same time.\n",
      "Sentiment Decision towards the term 'Scene': neutral\n",
      "Explanation: the : 0.1599567509788442, scene : -0.5050418315306884, palace : -0.11346255140091216, is : 0.7334324566786014, popular : 0.08709661513710568, with : -1.066377583521574, midtown : -0.132534135002126, locals : 0.15878288782425376, possibly : -0.02371121579379372, because : -0.00010587399627824544, the : 0.1599567509788442, upscale : 0.15804357869431238, room : -0.20470241715673637, means : -0.03082480490880003, you : -0.3419709413939751, can : -0.37964990567862, impress : 0.0640628953240187, client : -0.24893034972252887, and : -1.4714550858778395, have : -0.27437593717006287, chinese : 0.09450474847277013, for : -0.3734769200685542, lunch : 0.36102575037524276, at : 0.38667932060354876, the : 0.1599567509788442, same : 0.07556112695230106, time : -0.10786788689349683\n",
      "Actual Sentiment: positive\n",
      "Task 9:\n",
      "Text: about 10 minutes apart each, so we were all eating cold eggs by the time we got our food.\n",
      "Sentiment Decision towards the term 'eggs': neutral\n",
      "Explanation: about : 0.3460576148470281, 10 : -0.13353234997652894, minutes : 0.5152283794026853, apart : 0.3174958711566982, each : -0.42351064656444365, so : 0.19039592179678827, we : -0.3054258736797305, were : 1.1689934909553437, all : -0.6792124231776974, eating : -0.15049174268372714, cold : 1.6829375518821554, eggs : -0.08737589776010138, by : -0.38154381418577143, the : 0.1599567509788442, time : -0.10786788689349683, we : -0.3054258736797305, got : 0.5241633336006611, our : 0.05402355815250684, food : 0.7708413724540557\n",
      "Actual Sentiment: negative\n",
      "Task 10:\n",
      "Text: Includes a diverse array of entrees ranging from Boar (prepared in your choice of either the French or Asian tradition), Mussels, or Pad Thai that grace the menu all at once, each one prepared in a distinctly different and delicate sauce.\n",
      "Sentiment Decision towards the term 'entrees': neutral\n",
      "Explanation: includes : -0.2989745331176143, diverse : 0.40768028163179626, array : -0.38030304181317304, of : -0.6721133239838706, entrees : -0.013149620893572222, ranging : -0.383253743029154, from : -0.5657247889759164, prepared : 0.23843146038036225, in : 0.17410305733559264, your : -0.5968627980424539, choice : 0.05216832236248405, of : -0.6721133239838706, either : -0.28206987681394496, the : 0.1599567509788442, french : -0.7795770951632398, or : -0.4131856295682637, asian : -0.6027036303391051, mussels : -0.11810537816890615, or : -0.4131856295682637, pad : -0.3398199741783377, thai : -0.15111794224614647, that : 0.09505491397152648, grace : 0.09389205753001248, the : 0.1599567509788442, menu : -0.8412156567032758, all : -0.6792124231776974, at : 0.38667932060354876, once : 0.41336876434952563, each : -0.42351064656444365, one : 0.23332637109315876, prepared : 0.23843146038036225, in : 0.17410305733559264, different : -0.24374065039294404, and : -1.4714550858778395, delicate : 0.41481705087644016, sauce : 0.093990918074225\n",
      "Actual Sentiment: positive\n",
      "Task 11:\n",
      "Text: When I asked the waitress, she told me they couldn't afford the salmon, and had changed the dish (though not on the menu).\n",
      "Sentiment Decision towards the term 'salmon': neutral\n",
      "Explanation: when : 0.7736131650522035, asked : 0.300045530808483, the : 0.1599567509788442, waitress : -0.5058871333312062, she : -0.21261767492568515, told : 0.3188392645115736, me : 0.3166855568174938, they : 0.25283930947630323, couldn : 0.8132023250945484, afford : -0.14122382021518634, the : 0.1599567509788442, salmon : 0.14486045591387042, and : -1.4714550858778395, had : 0.18830730092669362, changed : -0.028270784587427766, the : 0.1599567509788442, dish : 0.18573771936485062, though : 0.46461391215843534, not : 2.476956248275856, on : -0.13037870958757733, the : 0.1599567509788442, menu : -0.8412156567032758\n",
      "Actual Sentiment: negative\n",
      "Task 12:\n",
      "Text: Appetizers are the safest bet, including a bountiful calamari plate or the appropriately earthy mushroom polenta.\n",
      "Sentiment Decision towards the term 'Appetizers': neutral\n",
      "Explanation: appetizers : -0.7340123342932203, are : 0.016287442706454363, the : 0.1599567509788442, bet : -0.12416125594207146, including : -0.1545600122530178, bountiful : -0.02843547222683239, calamari : -0.25816367542189667, plate : 0.460650125385935, or : -0.4131856295682637, the : 0.1599567509788442, appropriately : -0.06054950839278291, earthy : -0.08171962505136662, mushroom : -0.028108567341427658, polenta : -0.0596018620957854\n",
      "Actual Sentiment: positive\n",
      "Task 13:\n",
      "Text: The other two entrees that were ordered were very large portions.\n",
      "Sentiment Decision towards the term 'portions': negative\n",
      "Explanation: the : 0.1599567509788442, other : 0.27763512392968487, two : -0.104722483668734, entrees : -0.013149620893572222, that : 0.09505491397152648, were : 1.1689934909553437, ordered : 0.030509662853600114, were : 1.1689934909553437, very : -0.43624707566788434, large : -0.5142768833400122, portions : -1.0714232350509936\n",
      "Actual Sentiment: positive\n",
      "Task 14:\n",
      "Text: I like the somosas, chai, and the chole, but the dhosas and dhal were kinda dissapointing.\n",
      "Sentiment Decision towards the term 'chole': neutral\n",
      "Explanation: like : 0.40025356483795693, the : 0.1599567509788442, chai : -0.07654370334676362, and : -1.4714550858778395, the : 0.1599567509788442, but : 2.041756649529249, the : 0.1599567509788442, and : -1.4714550858778395, were : 1.1689934909553437, kinda : 0.4287573237098144, dissapointing : 0.20598699338369483\n",
      "Actual Sentiment: positive\n",
      "Task 15:\n",
      "Text: seems everyone ordered sushi there were tons of delivery orders (we can tell as we sat near the back).\n",
      "Sentiment Decision towards the term 'delivery': neutral\n",
      "Explanation: seems : -0.10429655132037441, everyone : 0.23133846993044782, ordered : 0.030509662853600114, sushi : 0.03777015939758429, there : -0.6327836073639417, were : 1.1689934909553437, tons : -0.48502340726661036, of : -0.6721133239838706, delivery : 0.32010847242011087, orders : 0.3497813079599517, we : -0.3054258736797305, can : -0.37964990567862, tell : 0.2476123761776884, as : -0.17235257237303314, we : -0.3054258736797305, sat : -0.589176231750547, near : 0.17604238990293133, the : 0.1599567509788442, back : 0.10135861959021845\n",
      "Actual Sentiment: positive\n",
      "Task 16:\n",
      "Text: Their bagels have the perfect softness to them, but on the outside there's a bit of crispiness to give it a bit of texture.\n",
      "Sentiment Decision towards the term 'texture': positive\n",
      "Explanation: their : 0.07711885811693396, bagels : -0.16759809310904322, have : -0.27437593717006287, the : 0.1599567509788442, perfect : -0.8283839966382349, to : 0.06489666268372277, them : 0.28104345568005157, but : 2.041756649529249, on : -0.13037870958757733, the : 0.1599567509788442, outside : 0.2625223883805178, there : -0.6327836073639417, bit : 0.8602740774544523, of : -0.6721133239838706, to : 0.06489666268372277, give : 0.15101277984413203, it : 0.25400665821968343, bit : 0.8602740774544523, of : -0.6721133239838706, texture : -0.0237388492037025\n",
      "Actual Sentiment: neutral\n",
      "Task 17:\n",
      "Text: The waiter appeared promptly, took our order, bought us drinks and was never to be seen again.\n",
      "Sentiment Decision towards the term 'waiter': negative\n",
      "Explanation: the : 0.1599567509788442, waiter : -0.8701139115254307, appeared : 0.39116925815197195, promptly : -1.0163181046621839, took : 0.6437041530593963, our : 0.05402355815250684, order : 0.21831657432765952, bought : -0.5037870492262996, us : -0.07882380616122509, drinks : 0.24304548432262396, and : -1.4714550858778395, was : 0.6756384514067241, never : 1.170183354302736, to : 0.06489666268372277, be : 0.3984678234144336, seen : 0.13317287090648766, again : 0.38431023348607984\n",
      "Actual Sentiment: positive\n",
      "Task 18:\n",
      "Text: Our waiter brought out three main courses, but the fourth wasn't ready so we had to wait for 10 minutes for the last dish to arrive, but they were very nice and gave us free red pepper hummus while we waited.\n",
      "Sentiment Decision towards the term 'red pepper hummus': neutral\n",
      "Explanation: our : 0.05402355815250684, waiter : -0.8701139115254307, brought : -0.021247499399756085, out : 0.3215012191840598, three : 0.5493654413240842, main : 0.31886196174840487, courses : -0.2432973226505495, but : 2.041756649529249, the : 0.1599567509788442, wasn : 0.9769989761576022, ready : 0.4141787735300064, so : 0.19039592179678827, we : -0.3054258736797305, had : 0.18830730092669362, to : 0.06489666268372277, wait : -0.6531231529058147, for : -0.3734769200685542, 10 : -0.13353234997652894, minutes : 0.5152283794026853, for : -0.3734769200685542, the : 0.1599567509788442, last : -0.14258023547858872, dish : 0.18573771936485062, to : 0.06489666268372277, arrive : -0.07742980006343464, but : 2.041756649529249, they : 0.25283930947630323, were : 1.1689934909553437, very : -0.43624707566788434, nice : -0.7987665848164006, and : -1.4714550858778395, gave : -0.013161152452250401, us : -0.07882380616122509, free : -0.9125441598071947, red : -0.7062212777967587, pepper : 0.35454652012955234, hummus : -0.16502109717196078, while : 0.41545485299894824, we : -0.3054258736797305, waited : 0.03725003493416637\n",
      "Actual Sentiment: positive\n",
      "Task 19:\n",
      "Text: The meat, onions, and cheese were good as was the roll, but I'd go back if I could forego the sauce.\n",
      "Sentiment Decision towards the term 'meat': negative\n",
      "Explanation: the : 0.1599567509788442, meat : 0.2852250259984368, onions : -0.050248319077073396, and : -1.4714550858778395, cheese : -0.1754919695016529, were : 1.1689934909553437, good : -0.9579341139312253, as : -0.17235257237303314, was : 0.6756384514067241, the : 0.1599567509788442, roll : -0.0036376604054922943, but : 2.041756649529249, go : 0.29784435476143384, back : 0.10135861959021845, if : -0.3074812693504518, could : 0.681126125913976, the : 0.1599567509788442, sauce : 0.093990918074225\n",
      "Actual Sentiment: positive\n",
      "Task 20:\n",
      "Text: The only dishes that were good were the chicken kebob (not hard to make) and the desserts, which were rice pudding.\n",
      "Sentiment Decision towards the term 'rice pudding': negative\n",
      "Explanation: the : 0.1599567509788442, only : 0.4431976218264309, dishes : -0.5436471365138156, that : 0.09505491397152648, were : 1.1689934909553437, good : -0.9579341139312253, were : 1.1689934909553437, the : 0.1599567509788442, chicken : -0.2614298849074775, not : 2.476956248275856, hard : 0.5939811433851936, to : 0.06489666268372277, make : 0.05267367118333742, and : -1.4714550858778395, the : 0.1599567509788442, desserts : 0.19248726523508278, which : -0.32382624440112534, were : 1.1689934909553437, rice : 0.11020745044134653, pudding : 0.15670647802858462\n",
      "Actual Sentiment: neutral\n",
      "\n",
      "Correct Decisions (Only as a reference):\n",
      "Task 21:\n",
      "Text: Not including the tip for our server, who we saw twice in an hour?\n",
      "Sentiment Decision towards the term 'server': negative\n",
      "Explanation: not : 2.476956248275856, including : -0.1545600122530178, the : 0.1599567509788442, tip : 0.28961507972085676, for : -0.3734769200685542, our : 0.05402355815250684, server : -0.7992034817534253, who : 0.15378982172690742, we : -0.3054258736797305, saw : 0.25908211787516916, twice : 0.6079486936807392, in : 0.17410305733559264, an : 0.1195060310552104, hour : 0.7014582422046489\n",
      "Actual Sentiment: negative\n",
      "Task 22:\n",
      "Text: THe bartendars were right on top of getting us our wine and setting up free blue cheese dip and chips for us.\n",
      "Sentiment Decision towards the term 'bartendars': positive\n",
      "Explanation: the : 0.1599567509788442, bartendars : -0.09456977293052767, were : 1.1689934909553437, right : -1.3617604168109558, on : -0.13037870958757733, top : -0.4568855410715931, of : -0.6721133239838706, getting : -0.08647558929838593, us : -0.07882380616122509, our : 0.05402355815250684, wine : 0.5541521595474224, and : -1.4714550858778395, setting : 0.09349038545780505, up : 0.3657616299706305, free : -0.9125441598071947, blue : -0.5642212340035605, cheese : -0.1754919695016529, dip : -0.34382581386673394, and : -1.4714550858778395, chips : 0.655262153563809, for : -0.3734769200685542, us : -0.07882380616122509\n",
      "Actual Sentiment: positive\n",
      "Task 23:\n",
      "Text: Ive had better burgers and fries at the local dinner in my neighborhood: 3 guys dinner on 96th and Madison Avenue.\n",
      "Sentiment Decision towards the term 'fries': positive\n",
      "Explanation: ive : -0.2945337453645926, had : 0.18830730092669362, better : -0.7246821105738327, burgers : 0.07902131496853354, and : -1.4714550858778395, fries : -0.5558873343083162, at : 0.38667932060354876, the : 0.1599567509788442, local : -0.2879918274813361, dinner : 0.06580938608266196, in : 0.17410305733559264, my : -0.0024860046636431283, neighborhood : -0.08768629534502123, guys : 0.37547016293856694, dinner : 0.06580938608266196, on : -0.13037870958757733, 96th : -0.04746188593096019, and : -1.4714550858778395, madison : 0.30808610722773555, avenue : 0.02061568286348702\n",
      "Actual Sentiment: positive\n",
      "Task 24:\n",
      "Text: The Scene Shun Lee Palace is popular with midtown locals, possibly because the upscale room means you can impress a client and have Chinese for lunch at the same time.\n",
      "Sentiment Decision towards the term 'lunch': neutral\n",
      "Explanation: the : 0.1599567509788442, scene : -0.5050418315306884, palace : -0.11346255140091216, is : 0.7334324566786014, popular : 0.08709661513710568, with : -1.066377583521574, midtown : -0.132534135002126, locals : 0.15878288782425376, possibly : -0.02371121579379372, because : -0.00010587399627824544, the : 0.1599567509788442, upscale : 0.15804357869431238, room : -0.20470241715673637, means : -0.03082480490880003, you : -0.3419709413939751, can : -0.37964990567862, impress : 0.0640628953240187, client : -0.24893034972252887, and : -1.4714550858778395, have : -0.27437593717006287, chinese : 0.09450474847277013, for : -0.3734769200685542, lunch : 0.36102575037524276, at : 0.38667932060354876, the : 0.1599567509788442, same : 0.07556112695230106, time : -0.10786788689349683\n",
      "Actual Sentiment: neutral\n",
      "Task 25:\n",
      "Text: The service was non-existant, the manager spent all of his time at the bar.\n",
      "Sentiment Decision towards the term 'bar': neutral\n",
      "Explanation: the : 0.1599567509788442, service : -0.6849207360502474, was : 0.6756384514067241, non : -0.42555938658789794, existant : 0.18025276151977368, the : 0.1599567509788442, manager : -0.15221989383215045, spent : 0.16261433424055907, all : -0.6792124231776974, of : -0.6721133239838706, his : -0.08952200287059758, time : -0.10786788689349683, at : 0.38667932060354876, the : 0.1599567509788442, bar : -0.797789668046145\n",
      "Actual Sentiment: neutral\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Based on the provided false decisions, we can categorize the errors made by the Logistic Regression Machine Learning Model into distinct fault categories. Here are the identified categories along with the frequency of each:\n",
      "\n",
      "1. **Misinterpretation of Context or Negation**:\n",
      "   - Task 1: The positive aspect of 'tables' is misinterpreted as negative due to possibly the model focusing on \"wish they had more\" without understanding the context.\n",
      "   - Task 5: The model fails to recognize the implied negative sentiment towards 'meal' due to the lack of direct negative words, even though the context suggests dissatisfaction.\n",
      "   - Task 7: The positive experience with the 'manager' is incorrectly marked as negative, possibly due to the model not capturing the overall positive context.\n",
      "   - Task 17: The 'waiter' being promptly available at the start but then disappearing is a nuanced context that the model misinterprets as entirely negative.\n",
      "   - Task 19: The model incorrectly assesses 'meat' as negative, failing to understand the context where the meat, onions, and cheese were good.\n",
      "   - Occurrences: 5\n",
      "\n",
      "2. **Incorrect Sentiment Polarity**:\n",
      "   - Task 9: The model fails to recognize the negative sentiment towards 'eggs' being cold, marking it as neutral.\n",
      "   - Task 11: The model marks 'salmon' as neutral despite the negative context of not being able to afford it.\n",
      "   - Task 13: The model incorrectly marks 'portions' as negative despite the context indicating that large portions are a positive aspect.\n",
      "   - Task 20: 'Rice pudding' is marked as negative despite no direct negative sentiment expressed towards it.\n",
      "   - Occurrences: 4\n",
      "\n",
      "3. **Failure to Recognize Positive Aspects**:\n",
      "   - Task 3: The model marks 'menu' as neutral despite the positive experience described.\n",
      "   - Task 6: 'Bagels' are marked as neutral despite the description of their perfect softness and crispiness, which is positive.\n",
      "   - Task 10: The model fails to recognize the positive sentiment towards 'entrees' provided by the diverse array mentioned.\n",
      "   - Task 12: 'Appetizers' are marked as neutral despite being described positively.\n",
      "   - Task 14: The model marks 'chole' as neutral despite being part of a list of liked items.\n",
      "   - Task 15: 'Delivery' is marked as neutral despite the context suggesting a positive aspect due to high demand.\n",
      "   - Task 18: 'Red pepper hummus' is marked as neutral despite being offered as a compensatory gesture, which is positive.\n",
      "   - Occurrences: 7\n",
      "\n",
      "4. **Failure to Recognize Neutral Aspects**:\n",
      "   - Task 16: The model incorrectly assigns a positive sentiment to 'texture', which is more of a neutral description.\n",
      "   - Occurrences: 1\n",
      "\n",
      "5. **Incorrect Neutral Sentiment Assignment**:\n",
      "   - Task 2: The model marks 'food' as negative despite the context suggesting a neutral stance due to untouched food and drinks.\n",
      "   - Task 4: 'Goat cheese' is marked as positive despite being part of a neutral description of the dish components.\n",
      "   - Task 8: The model marks 'Scene' as neutral despite the context suggesting a positive aspect of popularity among locals.\n",
      "   - Occurrences: 3\n",
      "\n",
      "In summary, the errors can be grouped into five main categories, with the most common error being the failure to recognize positive aspects, occurring 7 times. Misinterpretation of context or negation and incorrect sentiment polarity are also significant, with 5 and 4 occurrences respectively. Incorrect neutral sentiment assignment and failure to recognize neutral aspects are less common, with 3 and 1 occurrences respectively.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def execute(df, prompt, df_answer):\n",
    "    i = 1\n",
    "    if(MODEL == \"gpt-3.5-turbo-instruct\"):\n",
    "        llm = OpenAI(model_name = MODEL, temperature = TEMP, timeout=150)\n",
    "    else:\n",
    "        llm = ChatOpenAI(model_name = MODEL, temperature = TEMP, timeout=150)\n",
    "    examples = \"\"\n",
    "    examples += \"False Decisions:\\n\"\n",
    "    for j in range(len(df_error_samples)):\n",
    "        examples += f\"Task {i}:\\n\"\n",
    "        examples += \"Text: \" + df_error_samples.iloc[j]['text'] + \"\\n\"\n",
    "        examples += f\"Sentiment Decision towards the term '{df_error_samples.iloc[j]['term']}': \" + str(df_error_samples.iloc[j]['polarity_pred']) + \"\\n\"\n",
    "        examples += \"Explanation: \" + df_error_samples.iloc[j]['token_weights'] + \"\\n\"\n",
    "        examples += \"Actual Sentiment: \" + str(df_error_samples.iloc[j]['polarity']) + \"\\n\"\n",
    "        i += 1\n",
    "    examples += \"\\nCorrect Decisions (Only as a reference):\\n\"\n",
    "    for j in range(len(df_correct_samples)):\n",
    "        examples += f\"Task {i}:\\n\"\n",
    "        examples += \"Text: \" + df_correct_samples.iloc[j]['text'] + \"\\n\"\n",
    "        examples += f\"Sentiment Decision towards the term '{df_correct_samples.iloc[j]['term']}': \" + str(df_correct_samples.iloc[j]['polarity_pred']) + \"\\n\"\n",
    "        examples += \"Explanation: \" + df_correct_samples.iloc[j]['token_weights'] + \"\\n\"\n",
    "        examples += \"Actual Sentiment: \" + str(df_correct_samples.iloc[j]['polarity']) + \"\\n\"\n",
    "        i += 1\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "    try: \n",
    "        result = chain.run(examples = examples, callbacks=[handler])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(chain.prompt.format_prompt(examples = examples).to_string())\n",
    "    handler.langfuse.flush()\n",
    "    prompt_text = chain.prompt.format_prompt(examples = examples).to_string()\n",
    "    print(prompt_text)\n",
    "    print(\"\\n\")\n",
    "    print(result)\n",
    "    print(\"\\n\")\n",
    "    new_row = {'Prompt_Name': prompt_name, 'Prompt': prompt_text, 'Model': MODEL, 'Database': file, 'Answer': result, 'Context': 'logistic_regression'}\n",
    "    df_new_row = pd.DataFrame([new_row])\n",
    "    df_answer = pd.concat([df_answer, df_new_row])\n",
    "    return result, df_answer\n",
    "\n",
    "\n",
    "answer, df_answer = execute(df, prompt, df_answer)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prompt_Name                                             Prompt  \\\n",
      "0  error_class_ML  In the following I will give you a few Aspect ...   \n",
      "\n",
      "                 Model             Database  \\\n",
      "0  gpt-4-turbo-preview  logistic_regression   \n",
      "\n",
      "                                              Answer              Context  \n",
      "0  Based on the provided false decisions, we can ...  logistic_regression  \n"
     ]
    }
   ],
   "source": [
    "print(df_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answer.to_csv(OUTPUT_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
