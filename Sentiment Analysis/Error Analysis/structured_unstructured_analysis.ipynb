{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import error_prompts as p\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = os.environ.get(\"LANGFUSE_PUBLIC_KEY\")\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = os.environ.get(\"LANGFUSE_SECRET_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "handler = CallbackHandler()\n",
    "handler.auth_check()\n",
    "\n",
    "\n",
    "prompt_name_structured = 'structured_analysis'\n",
    "prompt_structured = p.structured_analysis\n",
    "prompt_name_unstructured = 'unstructured_analysis'\n",
    "prompt_unstructured = p.unstructured_analysis\n",
    "\n",
    "file = \"singleterm_zeroshot_3.5-turbo\"\n",
    "\n",
    "DATA_PATH = f'../../Datasets/Evaluations/Sentiment Analysis/{file}.csv'\n",
    "OUTPUT_PATH = f\"../../Datasets/Evaluations/Sentiment Analysis/Error_Analysis/structured_unstructured_{file}.csv\"\n",
    "\n",
    "MODEL = \"gpt-4-turbo-preview\"\n",
    "TEMP = 0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "correct    267\n",
      "error      184\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df['error'] = None\n",
    "df['error'] = ['correct' if polarity == polarity_pred else 'error' for polarity, polarity_pred in zip(df['polarity'], df['polarity_pred'])]\n",
    "\n",
    "print(df['error'].value_counts())\n",
    "\n",
    "df_correct = df[df['error'] == 'correct']\n",
    "df_error = df[df['error'] == 'error']\n",
    "\n",
    "\n",
    "\n",
    "df_error_sample = df_error.sample(n=50)\n",
    "df_correct_sample = df_correct.sample(n=50)\n",
    "df = pd.concat([df_error_sample, df_correct_sample])\n",
    "df['structured_analysis'] = None\n",
    "df['unstructured_analysis'] = None\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 12)\n",
      "   Unnamed: 0  text_id  term_id  \\\n",
      "0          57       20       57   \n",
      "1         232       87      232   \n",
      "2         434      164      434   \n",
      "3         104       39      104   \n",
      "4         268      102      268   \n",
      "\n",
      "                                                text    term  polarity  \\\n",
      "0  There were a lot of scensters who couldnt affo...  dinner  negative   \n",
      "1  Had a mouthwatering sardinian Stuffed Squid an...   sauce   neutral   \n",
      "2  As for the food, brunch was average, I would n...  brunch   neutral   \n",
      "3  We sat at the bar and were constantly bumped b...   rolls  positive   \n",
      "4  about 10 minutes apart each, so we were all ea...    eggs  negative   \n",
      "\n",
      "  polarity_pred                    prompt_name  \\\n",
      "0       neutral  prompt_3_zeroshot_single_term   \n",
      "1      positive  prompt_3_zeroshot_single_term   \n",
      "2      negative  prompt_3_zeroshot_single_term   \n",
      "3      negative  prompt_3_zeroshot_single_term   \n",
      "4       neutral  prompt_3_zeroshot_single_term   \n",
      "\n",
      "                                              prompt  error  \\\n",
      "0  There were a lot of scensters who couldnt affo...  error   \n",
      "1  Had a mouthwatering sardinian Stuffed Squid an...  error   \n",
      "2  As for the food, brunch was average, I would n...  error   \n",
      "3  We sat at the bar and were constantly bumped b...  error   \n",
      "4  about 10 minutes apart each, so we were all ea...  error   \n",
      "\n",
      "  structured_analysis unstructured_analysis  \n",
      "0                None                  None  \n",
      "1                None                  None  \n",
      "2                None                  None  \n",
      "3                None                  None  \n",
      "4                None                  None  \n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "System: You are a helpful AI.\n",
      "Human: There were a lot of scensters who couldnt afford dinner hanging in the waiting area so we got bumped around a lot.\n",
      "\n",
      "    What is the sentiment on 'dinner'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: neutral\n",
      "Human: Explain your prediction in a\n",
      "structured format, listing adjectives you used for your decision and how important you deemed them for your decision. Each adjective should be accompanied by a a score between 0 and\n",
      "1 that shows the importance of the attribute for the decision. All scores in total must add up to 1. Only include adjectives that had an impact on the term's sentiment. \n",
      "Return the final result as JSON like in this example:\n",
      "[{\"adjective\":\"great\",\"importance\":\"0.50\"},\n",
      "{\"adjective\":\"wonderful\",\"importance\":\"0.45\"},\n",
      "{\"adjective\":\"bad\",\"importance\":\"0.05\"}]\n",
      "ONLY return the JSON.\n",
      "\n",
      "\n",
      "[]\n",
      "\n",
      "\n",
      "0 of  100\n",
      "1\n",
      "System: You are a helpful AI.\n",
      "Human: Had a mouthwatering sardinian Stuffed Squid and a Catfish fiumarola from Rome( think was capers and anchovies sauce).\n",
      "\n",
      "    What is the sentiment on 'sauce'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: positive\n",
      "Human: Explain your prediction in a\n",
      "structured format, listing adjectives you used for your decision and how important you deemed them for your decision. Each adjective should be accompanied by a a score between 0 and\n",
      "1 that shows the importance of the attribute for the decision. All scores in total must add up to 1. Only include adjectives that had an impact on the term's sentiment. \n",
      "Return the final result as JSON like in this example:\n",
      "[{\"adjective\":\"great\",\"importance\":\"0.50\"},\n",
      "{\"adjective\":\"wonderful\",\"importance\":\"0.45\"},\n",
      "{\"adjective\":\"bad\",\"importance\":\"0.05\"}]\n",
      "ONLY return the JSON.\n",
      "\n",
      "\n",
      "[{\"adjective\":\"mouthwatering\",\"importance\":\"0.60\"},{\"adjective\":\"capres\",\"importance\":\"0.20\"},{\"adjective\":\"anchovies\",\"importance\":\"0.20\"}]\n",
      "\n",
      "\n",
      "2\n",
      "System: You are a helpful AI.\n",
      "Human: As for the food, brunch was average, I would not get the same dish again, and they were slow to serve us.\n",
      "\n",
      "    What is the sentiment on 'brunch'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: negative\n",
      "Human: Explain your prediction in a\n",
      "structured format, listing adjectives you used for your decision and how important you deemed them for your decision. Each adjective should be accompanied by a a score between 0 and\n",
      "1 that shows the importance of the attribute for the decision. All scores in total must add up to 1. Only include adjectives that had an impact on the term's sentiment. \n",
      "Return the final result as JSON like in this example:\n",
      "[{\"adjective\":\"great\",\"importance\":\"0.50\"},\n",
      "{\"adjective\":\"wonderful\",\"importance\":\"0.45\"},\n",
      "{\"adjective\":\"bad\",\"importance\":\"0.05\"}]\n",
      "ONLY return the JSON.\n",
      "\n",
      "\n",
      "[{\"adjective\":\"average\",\"importance\":\"0.60\"},{\"adjective\":\"slow\",\"importance\":\"0.40\"}]\n",
      "\n",
      "\n",
      "3\n",
      "System: You are a helpful AI.\n",
      "Human: We sat at the bar and were constantly bumped by the waitress flying past; had fabulously fresh raw oysters with pieces of shell in every bite; lobsters rolls were tasty but the large pieces of meat were tough; the apple crumble was excellent but the ice cream was over-frozen and the stench of frying oil was nearly unbearable.\n",
      "\n",
      "    What is the sentiment on 'rolls'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: negative\n",
      "Human: Explain your prediction in a\n",
      "structured format, listing adjectives you used for your decision and how important you deemed them for your decision. Each adjective should be accompanied by a a score between 0 and\n",
      "1 that shows the importance of the attribute for the decision. All scores in total must add up to 1. Only include adjectives that had an impact on the term's sentiment. \n",
      "Return the final result as JSON like in this example:\n",
      "[{\"adjective\":\"great\",\"importance\":\"0.50\"},\n",
      "{\"adjective\":\"wonderful\",\"importance\":\"0.45\"},\n",
      "{\"adjective\":\"bad\",\"importance\":\"0.05\"}]\n",
      "ONLY return the JSON.\n",
      "\n",
      "\n",
      "[{\"adjective\":\"tasty\",\"importance\":\"0.4\"},{\"adjective\":\"large\",\"importance\":\"0.1\"},{\"adjective\":\"tough\",\"importance\":\"0.5\"}]\n",
      "\n",
      "\n",
      "4\n",
      "System: You are a helpful AI.\n",
      "Human: about 10 minutes apart each, so we were all eating cold eggs by the time we got our food.\n",
      "\n",
      "    What is the sentiment on 'eggs'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: neutral\n",
      "Human: Explain your prediction in a\n",
      "structured format, listing adjectives you used for your decision and how important you deemed them for your decision. Each adjective should be accompanied by a a score between 0 and\n",
      "1 that shows the importance of the attribute for the decision. All scores in total must add up to 1. Only include adjectives that had an impact on the term's sentiment. \n",
      "Return the final result as JSON like in this example:\n",
      "[{\"adjective\":\"great\",\"importance\":\"0.50\"},\n",
      "{\"adjective\":\"wonderful\",\"importance\":\"0.45\"},\n",
      "{\"adjective\":\"bad\",\"importance\":\"0.05\"}]\n",
      "ONLY return the JSON.\n",
      "\n",
      "\n",
      "[]\n",
      "\n",
      "\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "50 of  100\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#Structured Analysis\n",
    "def execute(df, prompt, start = 0):\n",
    "    if(MODEL == \"gpt-3.5-turbo-instruct\"):\n",
    "        llm = OpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    else:\n",
    "        llm = ChatOpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    for i in range(len(df)):\n",
    "        if(df[\"structured_analysis\"][i] != None and df[\"structured_analysis\"][i] != \"error\"):\n",
    "            continue\n",
    "        print(i)\n",
    "        chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "        user_prompt = df.loc[i, 'prompt']\n",
    "        ai_answer = df.loc[i, 'polarity_pred']\n",
    "        try: \n",
    "            result = chain.run(user_prompt = user_prompt, ai_answer = str(ai_answer), callbacks=[handler])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = str(ai_answer)).to_string())\n",
    "            df['structured_analysis'][i] = 'error'\n",
    "            continue\n",
    "        handler.langfuse.flush()\n",
    "        prompt_text = chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = str(ai_answer)).to_string()\n",
    "        if (i < 5):\n",
    "            print(prompt_text)\n",
    "            print(\"\\n\")\n",
    "            print(result)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        if (i % 50 == 0):\n",
    "            print(str(i) + \" of  \" + str(len(df)))\n",
    "        df.loc[i, 'structured_analysis']= result\n",
    "    return df\n",
    "\n",
    "\n",
    "df = execute(df, prompt_structured)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "System: You are a helpful AI.\n",
      "Human: There were a lot of scensters who couldnt afford dinner hanging in the waiting area so we got bumped around a lot.\n",
      "\n",
      "    What is the sentiment on 'dinner'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: neutral\n",
      "Human: Now explain concisely how you made your prediction and explicitly mention the adjectives that had a high influence on your decision.\n",
      "\n",
      "\n",
      "The sentiment analysis on the word \"dinner\" in the provided text is determined to be \"neutral\" because the context in which \"dinner\" is mentioned does not inherently carry a positive or negative connotation towards the meal itself. The focus of the sentence is on the situation of people who couldn't afford dinner and the inconvenience caused by being bumped around, rather than the quality or enjoyment of the dinner. There are no adjectives directly modifying \"dinner\" to suggest a positive or negative sentiment. The sentiment is derived more from the situation (people not affording dinner) rather than the dinner itself, leading to the classification as \"neutral.\"\n",
      "\n",
      "\n",
      "0 of  100\n",
      "1\n",
      "System: You are a helpful AI.\n",
      "Human: Had a mouthwatering sardinian Stuffed Squid and a Catfish fiumarola from Rome( think was capers and anchovies sauce).\n",
      "\n",
      "    What is the sentiment on 'sauce'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: positive\n",
      "Human: Now explain concisely how you made your prediction and explicitly mention the adjectives that had a high influence on your decision.\n",
      "\n",
      "\n",
      "The prediction of a \"positive\" sentiment towards the term \"sauce\" was influenced by the adjective \"mouthwatering\" used to describe the Sardinian Stuffed Squid and the context of a Catfish fiumarola from Rome, which was thought to have a capers and anchovies sauce. The word \"mouthwatering\" strongly suggests a positive experience and enjoyment of the food, which by extension includes the sauce, as it is a component of the described dishes.\n",
      "\n",
      "\n",
      "2\n",
      "System: You are a helpful AI.\n",
      "Human: As for the food, brunch was average, I would not get the same dish again, and they were slow to serve us.\n",
      "\n",
      "    What is the sentiment on 'brunch'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: negative\n",
      "Human: Now explain concisely how you made your prediction and explicitly mention the adjectives that had a high influence on your decision.\n",
      "\n",
      "\n",
      "The prediction of a \"negative\" sentiment towards \"brunch\" was based on the adjectives and context provided in the statement. The adjectives \"average\" and \"slow\" had a high influence on the decision. \"Average\" suggests a lack of enthusiasm or satisfaction with the quality of the brunch, indicating it did not meet expectations or was merely satisfactory without excelling. \"Slow\" in reference to the service speed further contributes to a negative experience, as it implies a level of dissatisfaction with the timeliness of the service. These adjectives, combined with the explicit statement of not wanting to get the same dish again, strongly indicate a negative sentiment.\n",
      "\n",
      "\n",
      "3\n",
      "System: You are a helpful AI.\n",
      "Human: We sat at the bar and were constantly bumped by the waitress flying past; had fabulously fresh raw oysters with pieces of shell in every bite; lobsters rolls were tasty but the large pieces of meat were tough; the apple crumble was excellent but the ice cream was over-frozen and the stench of frying oil was nearly unbearable.\n",
      "\n",
      "    What is the sentiment on 'rolls'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: negative\n",
      "Human: Now explain concisely how you made your prediction and explicitly mention the adjectives that had a high influence on your decision.\n",
      "\n",
      "\n",
      "The sentiment prediction for \"rolls\" as negative was influenced by the adjectives \"tasty\" (which is positive) but more so by \"tough\" in the context of describing the large pieces of meat in the lobster rolls. The word \"tough\" suggests a negative dining experience related to the texture and quality of the meat, outweighing the positive aspect provided by \"tasty.\"\n",
      "\n",
      "\n",
      "4\n",
      "System: You are a helpful AI.\n",
      "Human: about 10 minutes apart each, so we were all eating cold eggs by the time we got our food.\n",
      "\n",
      "    What is the sentiment on 'eggs'? Only respond with \"positive\", \"negative\" or \"neutral\" as one word.\n",
      "AI: neutral\n",
      "Human: Now explain concisely how you made your prediction and explicitly mention the adjectives that had a high influence on your decision.\n",
      "\n",
      "\n",
      "My prediction was based on the analysis of the sentiment expressed towards the 'eggs' in the provided text. The key phrase influencing the decision was \"cold eggs.\" The adjective \"cold\" typically carries a negative connotation when associated with food meant to be served hot, suggesting a less than ideal or negative experience. However, the sentiment was requested specifically towards 'eggs' without considering the context or descriptors directly influencing the sentiment. Given the lack of explicitly positive or negative adjectives directly modifying 'eggs' themselves (e.g., \"delicious eggs\" or \"spoiled eggs\"), and focusing strictly on the sentiment towards 'eggs' without the influence of their condition ('cold'), the response was \"neutral.\" This was an oversight in my initial analysis, as the context (\"cold eggs\") indeed suggests a negative sentiment towards the experience of eating the eggs, not their intrinsic quality.\n",
      "\n",
      "\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "50 of  100\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#Unstructured Analysis\n",
    "def execute(df, prompt):\n",
    "    if(MODEL == \"gpt-3.5-turbo-instruct\"):\n",
    "        llm = OpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    else:\n",
    "        llm = ChatOpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    for i in range(len(df)):\n",
    "        if(df[\"unstructured_analysis\"][i] != None and df[\"unstructured_analysis\"][i] != \"error\"):\n",
    "            continue\n",
    "        print(i)\n",
    "        chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "        user_prompt = df.loc[i, 'prompt']\n",
    "        ai_answer = df.loc[i, 'polarity_pred']\n",
    "        try: \n",
    "            result = chain.run(user_prompt = user_prompt, ai_answer = str(ai_answer), callbacks=[handler])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = str(ai_answer)).to_string())\n",
    "            df['unstructured_analysis'][i] = 'error'\n",
    "            continue\n",
    "        handler.langfuse.flush()\n",
    "        prompt_text = chain.prompt.format_prompt(user_prompt = user_prompt, ai_answer = str(ai_answer)).to_string()\n",
    "        if (i < 5):\n",
    "            print(prompt_text)\n",
    "            print(\"\\n\")\n",
    "            print(result)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        if (i % 50 == 0):\n",
    "            print(str(i) + \" of  \" + str(len(df)))\n",
    "        df.loc[i, 'unstructured_analysis']= result\n",
    "    return df\n",
    "\n",
    "df = execute(df, prompt_unstructured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(OUTPUT_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
