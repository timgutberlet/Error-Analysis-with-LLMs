{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = \"confidence_singleterm_dynamic_fewshot_3.5-turbo_gpt-3.5-turbo\"\n",
    "INPUT_PATH = f\"../../../Datasets/Evaluations/Sentiment Analysis/Error_Analysis/{file}.csv\"\n",
    "OUTPUT_PATH = f\"../../../Datasets/Evaluations/Sentiment Analysis/Error_Analysis/Eval/confidence_analysis_{file}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0  text_id  term_id  \\\n",
      "0             0           0        0        0   \n",
      "1             1           1        0        1   \n",
      "2             2           2        0        2   \n",
      "3             3           3        0        3   \n",
      "4             4           4        1        4   \n",
      "\n",
      "                                                text  \\\n",
      "0  Amusing details distinguish desserts, from dul...   \n",
      "1  Amusing details distinguish desserts, from dul...   \n",
      "2  Amusing details distinguish desserts, from dul...   \n",
      "3  Amusing details distinguish desserts, from dul...   \n",
      "4  The server was so busy the night we visited th...   \n",
      "\n",
      "                          term  polarity  example1_term_id  \\\n",
      "0                     desserts  positive              9500   \n",
      "1     dulce de leche ice-cream   neutral              9500   \n",
      "2  chocolate sauce tic-tac-toe   neutral              9500   \n",
      "3            poached pineapple   neutral              9500   \n",
      "4                       server  negative              1211   \n",
      "\n",
      "                                     example1_prompt  example1_sim_score  \\\n",
      "0  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
      "1  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
      "2  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
      "3  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
      "4  Input: \"The server also forgot about our desse...            0.354028   \n",
      "\n",
      "   example2_term_id                                    example2_prompt  \\\n",
      "0              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
      "1              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
      "2              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
      "3              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
      "4              8639  Input: \"the 3rd however, the waiter forgot to ...   \n",
      "\n",
      "   example2_sim_score  example3_term_id  \\\n",
      "0            0.162247              1320   \n",
      "1            0.162247              1320   \n",
      "2            0.162247              1320   \n",
      "3            0.162247              1320   \n",
      "4            0.410810             10792   \n",
      "\n",
      "                                     example3_prompt  example3_sim_score  \\\n",
      "0  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
      "1  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
      "2  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
      "3  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
      "4  Input: \"We waited an hour for our appetizers, ...            0.416744   \n",
      "\n",
      "  polarity_pred                 prompt_name  \\\n",
      "0      positive  prompt_single_term_fewshot   \n",
      "1      positive  prompt_single_term_fewshot   \n",
      "2      positive  prompt_single_term_fewshot   \n",
      "3       neutral  prompt_single_term_fewshot   \n",
      "4      negative  prompt_single_term_fewshot   \n",
      "\n",
      "                                              prompt  \\\n",
      "0  Example 1:\\nInput: \"Food is mediocre, except f...   \n",
      "1  Example 1:\\nInput: \"Food is mediocre, except f...   \n",
      "2  Example 1:\\nInput: \"Food is mediocre, except f...   \n",
      "3  Example 1:\\nInput: \"Food is mediocre, except f...   \n",
      "4  Example 1:\\nInput: \"The server also forgot abo...   \n",
      "\n",
      "                             analysis  \n",
      "0     Confidence: 95%\\nSentiment: 80%  \n",
      "1     Confidence: 95%\\nSentiment: 80%  \n",
      "2     Confidence: 95%\\nSentiment: 80%  \n",
      "3      Confidence: 90%\\nSentiment: 0%  \n",
      "4  Confidence: 100%\\nSentiment: -100%  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_numbers(text):\n",
    "    confidence = int(text.split(\"Confidence: \")[1].split(\"%\")[0])\n",
    "    sentiment = int(text.split(\"Sentiment: \")[1].split(\"%\")[0])\n",
    "    return confidence, sentiment\n",
    "\n",
    "df[['confidence', 'sentiment']] = df['analysis'].apply(lambda x: pd.Series(extract_numbers(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0  text_id  term_id  \\\n",
      "0             0           0        0        0   \n",
      "1             1           1        0        1   \n",
      "2             2           2        0        2   \n",
      "3             3           3        0        3   \n",
      "4             4           4        1        4   \n",
      "\n",
      "                                                text  \\\n",
      "0  Amusing details distinguish desserts, from dul...   \n",
      "1  Amusing details distinguish desserts, from dul...   \n",
      "2  Amusing details distinguish desserts, from dul...   \n",
      "3  Amusing details distinguish desserts, from dul...   \n",
      "4  The server was so busy the night we visited th...   \n",
      "\n",
      "                          term  polarity  example1_term_id  \\\n",
      "0                     desserts  positive              9500   \n",
      "1     dulce de leche ice-cream   neutral              9500   \n",
      "2  chocolate sauce tic-tac-toe   neutral              9500   \n",
      "3            poached pineapple   neutral              9500   \n",
      "4                       server  negative              1211   \n",
      "\n",
      "                                     example1_prompt  example1_sim_score  ...  \\\n",
      "0  Input: \"Food is mediocre, except for Mushroom ...            0.152772  ...   \n",
      "1  Input: \"Food is mediocre, except for Mushroom ...            0.152772  ...   \n",
      "2  Input: \"Food is mediocre, except for Mushroom ...            0.152772  ...   \n",
      "3  Input: \"Food is mediocre, except for Mushroom ...            0.152772  ...   \n",
      "4  Input: \"The server also forgot about our desse...            0.354028  ...   \n",
      "\n",
      "   example3_term_id                                    example3_prompt  \\\n",
      "0              1320  Input: \"The overpriced ice cream is delicious ...   \n",
      "1              1320  Input: \"The overpriced ice cream is delicious ...   \n",
      "2              1320  Input: \"The overpriced ice cream is delicious ...   \n",
      "3              1320  Input: \"The overpriced ice cream is delicious ...   \n",
      "4             10792  Input: \"We waited an hour for our appetizers, ...   \n",
      "\n",
      "   example3_sim_score  polarity_pred                 prompt_name  \\\n",
      "0            0.166906       positive  prompt_single_term_fewshot   \n",
      "1            0.166906       positive  prompt_single_term_fewshot   \n",
      "2            0.166906       positive  prompt_single_term_fewshot   \n",
      "3            0.166906        neutral  prompt_single_term_fewshot   \n",
      "4            0.416744       negative  prompt_single_term_fewshot   \n",
      "\n",
      "                                              prompt  \\\n",
      "0  Example 1:\\nInput: \"Food is mediocre, except f...   \n",
      "1  Example 1:\\nInput: \"Food is mediocre, except f...   \n",
      "2  Example 1:\\nInput: \"Food is mediocre, except f...   \n",
      "3  Example 1:\\nInput: \"Food is mediocre, except f...   \n",
      "4  Example 1:\\nInput: \"The server also forgot abo...   \n",
      "\n",
      "                             analysis confidence sentiment    error  \n",
      "0     Confidence: 95%\\nSentiment: 80%         95        80  correct  \n",
      "1     Confidence: 95%\\nSentiment: 80%         95        80    error  \n",
      "2     Confidence: 95%\\nSentiment: 80%         95        80    error  \n",
      "3      Confidence: 90%\\nSentiment: 0%         90         0  correct  \n",
      "4  Confidence: 100%\\nSentiment: -100%        100      -100  correct  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "df['error'] = df.apply(lambda row: 'correct' if row['polarity_pred'] == row['polarity'] else 'error', axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_overall = df\n",
    "df_positive_pred = df[df['polarity_pred'] == 'positive']\n",
    "df_negative_pred = df[df['polarity_pred'] == 'negative']\n",
    "df_neutral_pred = df[df['polarity_pred'] == 'neutral']\n",
    "\n",
    "df_positive = df[df['polarity'] == 'positive']\n",
    "df_negative = df[df['polarity'] == 'negative']\n",
    "df_neutral = df[df['polarity'] == 'neutral']\n",
    "\n",
    "dfs = [df_overall, df_positive_pred, df_negative_pred, df_neutral_pred, df_positive, df_negative, df_neutral]\n",
    "i = 1\n",
    "for df_temp in dfs:\n",
    "    dfs = [('df_overall', df_overall), ('df_positive_pred', df_positive_pred), ('df_negative_pred', df_negative_pred), ('df_neutral_pred', df_neutral_pred), ('df_positive', df_positive), ('df_negative', df_negative), ('df_neutral', df_neutral)]\n",
    "\n",
    "# Create an empty dataframe to store the printed values\n",
    "result_df = pd.DataFrame(columns=['DataFrame'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          DataFrame  Confidence overall mean  Confidence overall Std  \\\n",
      "1        df_overall                94.212860                5.695137   \n",
      "2  df_positive_pred                96.688312                2.927265   \n",
      "3  df_negative_pred                95.884956                4.290255   \n",
      "4   df_neutral_pred                91.114130                6.692547   \n",
      "5       df_positive                94.892857                5.380081   \n",
      "6       df_negative                94.102564                6.486570   \n",
      "7        df_neutral                93.788660                5.381958   \n",
      "\n",
      "   Confidence for correct predictions  Confidence Std for correct predictions  \\\n",
      "1                           94.650350                                5.117920   \n",
      "2                           96.767677                                2.972075   \n",
      "3                           95.800000                                4.429630   \n",
      "4                           92.008929                                5.868676   \n",
      "5                           96.767677                                2.972075   \n",
      "6                           95.800000                                4.429630   \n",
      "7                           92.008929                                5.868676   \n",
      "\n",
      "   Confidence for wrong predictions  Confidence Std for wrong predictions  \\\n",
      "1                         93.454545                              6.524302   \n",
      "2                         96.545455                              2.866267   \n",
      "3                         96.052632                              4.053343   \n",
      "4                         89.722222                              7.640187   \n",
      "5                         90.365854                              7.016966   \n",
      "6                         91.071429                              8.303372   \n",
      "7                         96.219512                              3.384877   \n",
      "\n",
      "   Sentiment overall mean  Sentiment overall Std  \\\n",
      "1                8.215078              61.911911   \n",
      "2               81.558442               4.297722   \n",
      "3              -79.601770               8.402317   \n",
      "4                0.760870               4.729560   \n",
      "5               56.357143              41.400148   \n",
      "6              -45.170940              50.573997   \n",
      "7                5.670103              52.441079   \n",
      "\n",
      "   Sentiment for correct predictions  Sentiment Std for correct predictions  \\\n",
      "1                           7.709790                              62.965457   \n",
      "2                          81.717172                               4.526657   \n",
      "3                         -79.533333                               9.011004   \n",
      "4                           0.714286                               5.487789   \n",
      "5                          81.717172                               4.526657   \n",
      "6                         -79.533333                               9.011004   \n",
      "7                           0.714286                               5.487789   \n",
      "\n",
      "   Sentiment for wrong predictions  Sentiment Std for wrong predictions  \n",
      "1                         9.090909                            60.221321  \n",
      "2                        81.272727                             3.875156  \n",
      "3                       -79.736842                             7.161021  \n",
      "4                         0.833333                             3.250135  \n",
      "5                        -4.878049                            21.693542  \n",
      "6                        16.190476                            32.755739  \n",
      "7                        12.439024                            80.193608  \n"
     ]
    }
   ],
   "source": [
    "# Iterate over the dfs list\n",
    "for df_name, df_temp in dfs:\n",
    "    # Create a dictionary to store the printed values\n",
    "    values = {\n",
    "        'DataFrame': df_name,\n",
    "        'Confidence overall mean': df_temp['confidence'].mean(),\n",
    "        'Confidence overall Std': df_temp['confidence'].std(),\n",
    "        'Confidence for correct predictions': df_temp[df_temp['error'] == 'correct']['confidence'].mean(),\n",
    "        'Confidence Std for correct predictions': df_temp[df_temp['error'] == 'correct']['confidence'].std(),\n",
    "        'Confidence for wrong predictions': df_temp[df_temp['error'] == 'error']['confidence'].mean(),\n",
    "        'Confidence Std for wrong predictions': df_temp[df_temp['error'] == 'error']['confidence'].std(),\n",
    "        'Sentiment overall mean': df_temp['sentiment'].mean(),\n",
    "        'Sentiment overall Std': df_temp['sentiment'].std(),\n",
    "        'Sentiment for correct predictions': df_temp[df_temp['error'] == 'correct']['sentiment'].mean(),\n",
    "        'Sentiment Std for correct predictions': df_temp[df_temp['error'] == 'correct']['sentiment'].std(),\n",
    "        'Sentiment for wrong predictions': df_temp[df_temp['error'] == 'error']['sentiment'].mean(),\n",
    "        'Sentiment Std for wrong predictions': df_temp[df_temp['error'] == 'error']['sentiment'].std()\n",
    "    }\n",
    "    \n",
    "    # Append the values to the result dataframe\n",
    "    result_df = pd.concat([result_df, pd.DataFrame(values, index=[i])])\n",
    "    i += 1\n",
    "\n",
    "# Print the updated result dataframe\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(OUTPUT_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
