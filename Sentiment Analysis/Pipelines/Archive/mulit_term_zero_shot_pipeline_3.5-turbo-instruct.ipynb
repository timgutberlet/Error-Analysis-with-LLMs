{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/timgutberlet/My Drive (t.gutberlet01@gmail.com)/05 - Coding/06 - Bachelor Thesis/Error-Analysis-with-LLMs/Sentiment Analysis/Pipelines/multi_term', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python312.zip', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/lib-dynload', '', '/Users/timgutberlet/Library/Python/3.12/lib/python/site-packages', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages', '../']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "print(sys.path)\n",
    "import prompts as p\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = os.environ.get(\"LANGFUSE_PUBLIC_KEY\")\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = os.environ.get(\"LANGFUSE_SECRET_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "handler = CallbackHandler()\n",
    "handler.auth_check()\n",
    "\n",
    "DATA_PATH = \"../../../Datasets/MAMS-ATSA/Downsampled/test/test_single_row.csv\"\n",
    "OUTPUT_PATH = \"../../../Datasets/Evaluations/Sentiment Analysis/mulit_term_zero_shot_pipeline_3.5-turbo-instruct.csv\"\n",
    "\n",
    "MODEL = \"gpt-3.5-turbo-instruct\"\n",
    "TEMP = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   text_id  term_id                                               text  \\\n",
      "0        0        0  Amusing details distinguish desserts, from dul...   \n",
      "1        0        1  Amusing details distinguish desserts, from dul...   \n",
      "2        0        2  Amusing details distinguish desserts, from dul...   \n",
      "3        0        3  Amusing details distinguish desserts, from dul...   \n",
      "4        1        4  The server was so busy the night we visited th...   \n",
      "\n",
      "                          term  polarity polarity_pred prompt_name prompt  \n",
      "0                     desserts  positive          None        None   None  \n",
      "1     dulce de leche ice-cream   neutral          None        None   None  \n",
      "2  chocolate sauce tic-tac-toe   neutral          None        None   None  \n",
      "3            poached pineapple   neutral          None        None   None  \n",
      "4                       server  negative          None        None   None  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "prompt_name = \"prompt_multi_term_zeroshot\"\n",
    "prompt = p.prompt_multi_term_zeroshot\n",
    "\n",
    "\n",
    "df['polarity_pred'] = None\n",
    "df['prompt_name'] = None\n",
    "df['prompt'] = None\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_terms(df):\n",
    "    s = \"\"\n",
    "    for term in df['term']:\n",
    "        s += \"'\"+ term + \"'\" + \"\\n\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/_api/beta_decorator.py:86: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Analyze the sentiment of specific terms mentioned in a sentence. \n",
      "You are required to evaluate whether the sentiment towards each term is 'positive', 'negative', or 'neutral'.\n",
      "\n",
      "Sentence: \"Amusing details distinguish desserts, from dulce de leche ice-cream profiteroles dotting a chocolate sauce tic-tac-toe board, to coconut custard surrounded by a sea of Malibu-rum gelee and poached pineapple.\"\n",
      "\n",
      "Terms:\n",
      "'desserts'\n",
      "'dulce de leche ice-cream'\n",
      "'chocolate sauce tic-tac-toe'\n",
      "'poached pineapple'\n",
      "\n",
      "\n",
      "Return the final result as JSON in the format {\"term_sentiments\": \"<a list of [term, sentiment] pairs>\"}.\n",
      "ONLY return the JSON.\n",
      "Answer:\n",
      "\n",
      "\n",
      " {\"term_sentiments\": [[\"desserts\", \"neutral\"], [\"dulce de leche ice-cream\", \"positive\"], [\"chocolate sauce tic-tac-toe\", \"neutral\"], [\"poached pineapple\", \"neutral\"]]}\n",
      "\n",
      "\n",
      "0 of  451\n",
      "4\n",
      "Task: Analyze the sentiment of specific terms mentioned in a sentence. \n",
      "You are required to evaluate whether the sentiment towards each term is 'positive', 'negative', or 'neutral'.\n",
      "\n",
      "Sentence: \"The server was so busy the night we visited that she forgot to put in our food order.\"\n",
      "\n",
      "Terms:\n",
      "'server'\n",
      "'food'\n",
      "\n",
      "\n",
      "Return the final result as JSON in the format {\"term_sentiments\": \"<a list of [term, sentiment] pairs>\"}.\n",
      "ONLY return the JSON.\n",
      "Answer:\n",
      "\n",
      "\n",
      " {\"term_sentiments\": [[\"server\", \"negative\"], [\"food\", \"neutral\"]]}\n",
      "\n",
      "\n",
      "6\n",
      "8\n",
      "10\n",
      "13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m             x\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 58\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 26\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(df, prompt, prompt_name, start)\u001b[0m\n\u001b[1;32m     24\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39mformat_prompt(input_text \u001b[38;5;241m=\u001b[39m input_text, terms \u001b[38;5;241m=\u001b[39m terms)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlangfuse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m prompt_text \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39mformat_prompt(input_text \u001b[38;5;241m=\u001b[39m input_text, terms \u001b[38;5;241m=\u001b[39m terms)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m5\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langfuse/client.py:777\u001b[0m, in \u001b[0;36mLangfuse.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflush\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 777\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    779\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mexception(e)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langfuse/task_manager.py:252\u001b[0m, in \u001b[0;36mTaskManager.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m queue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\n\u001b[1;32m    251\u001b[0m size \u001b[38;5;241m=\u001b[39m queue\u001b[38;5;241m.\u001b[39mqsize()\n\u001b[0;32m--> 252\u001b[0m \u001b[43mqueue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# Note that this message may not be precise, because of threading.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccessfully flushed about \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m items.\u001b[39m\u001b[38;5;124m\"\u001b[39m, size)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/queue.py:90\u001b[0m, in \u001b[0;36mQueue.join\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_tasks_done:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munfinished_tasks:\n\u001b[0;32m---> 90\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_tasks_done\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def execute(df, prompt, prompt_name, start = 0):\n",
    "    current_text = -1\n",
    "    if(MODEL == \"gpt-3.5-turbo-instruct\"):\n",
    "        llm = OpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    else:\n",
    "        llm = ChatOpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    for i in range(start, len(df)):\n",
    "        if df[\"text_id\"][i] == current_text:\n",
    "            continue\n",
    "        current_text = df[\"text_id\"][i]\n",
    "        if(df[\"polarity_pred\"][i] != None and df[\"polarity_pred\"][i] != \"error\"):\n",
    "            continue\n",
    "        print(i)\n",
    "        chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "        input_text = df[\"text\"][i]\n",
    "        terms_df = df[df[\"text_id\"] == current_text]\n",
    "        terms = create_terms(terms_df)\n",
    "        try: \n",
    "            result = chain.run(input_text = input_text, terms = terms, callbacks=[handler])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            df.loc[i, 'polarity_pred'] =  'error'\n",
    "            df.loc[i, 'prompt_name'] = prompt_name\n",
    "            df.loc[i, 'prompt'] = chain.prompt.format_prompt(input_text = input_text, terms = terms).text\n",
    "            continue\n",
    "        handler.langfuse.flush()\n",
    "        prompt_text = chain.prompt.format_prompt(input_text = input_text, terms = terms).text\n",
    "        if (i < 5):\n",
    "            print(prompt_text)\n",
    "            print(\"\\n\")\n",
    "            print(result)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        if (i % 50 == 0):\n",
    "            print(str(i) + \" of  \" + str(len(df)))\n",
    "\n",
    "        data = json.loads(result)\n",
    "        term_sentiments= data[\"term_sentiments\"]\n",
    "        x = 0\n",
    "        for j in terms_df[\"term_id\"]:\n",
    "            if df[\"term\"][j].lower() == term_sentiments[x][0].lower():\n",
    "                df.loc[j, 'polarity_pred'] =  term_sentiments[x][1]\n",
    "                df.loc[j, 'prompt_name'] = prompt_name\n",
    "                df.loc[j, 'prompt'] = prompt_text\n",
    "            else:\n",
    "                print(df[\"term\"][j].lower())\n",
    "                print(term_sentiments[x][0].lower())\n",
    "                print(prompt_text)\n",
    "                print(\"\\n\")\n",
    "                print(result)\n",
    "                print(\"\\n\")\n",
    "                df.loc[j, 'polarity_pred'] =  term_sentiments[x][1]\n",
    "                df.loc[j, 'prompt_name'] = prompt_name\n",
    "                df.loc[j, 'prompt'] = prompt_text\n",
    "            x+=1\n",
    "    return df\n",
    "\n",
    "df = execute(df, prompt, prompt_name)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [text_id, term_id, text, term, polarity, polarity_pred, prompt_name, prompt]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "error_rows = df[df['polarity_pred'] == 'error']\n",
    "print(error_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>term_id</th>\n",
       "      <th>text</th>\n",
       "      <th>term</th>\n",
       "      <th>polarity</th>\n",
       "      <th>polarity_pred</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Amusing details distinguish desserts, from dul...</td>\n",
       "      <td>desserts</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>prompt_multi_term_zeroshot</td>\n",
       "      <td>Task: Analyze the sentiment of specific terms ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Amusing details distinguish desserts, from dul...</td>\n",
       "      <td>dulce de leche ice-cream</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>prompt_multi_term_zeroshot</td>\n",
       "      <td>Task: Analyze the sentiment of specific terms ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Amusing details distinguish desserts, from dul...</td>\n",
       "      <td>chocolate sauce tic-tac-toe</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>prompt_multi_term_zeroshot</td>\n",
       "      <td>Task: Analyze the sentiment of specific terms ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Amusing details distinguish desserts, from dul...</td>\n",
       "      <td>poached pineapple</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>prompt_multi_term_zeroshot</td>\n",
       "      <td>Task: Analyze the sentiment of specific terms ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>The server was so busy the night we visited th...</td>\n",
       "      <td>server</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>prompt_multi_term_zeroshot</td>\n",
       "      <td>Task: Analyze the sentiment of specific terms ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id  term_id                                               text  \\\n",
       "0        0        0  Amusing details distinguish desserts, from dul...   \n",
       "1        0        1  Amusing details distinguish desserts, from dul...   \n",
       "2        0        2  Amusing details distinguish desserts, from dul...   \n",
       "3        0        3  Amusing details distinguish desserts, from dul...   \n",
       "4        1        4  The server was so busy the night we visited th...   \n",
       "\n",
       "                          term  polarity polarity_pred  \\\n",
       "0                     desserts  positive       neutral   \n",
       "1     dulce de leche ice-cream   neutral      positive   \n",
       "2  chocolate sauce tic-tac-toe   neutral       neutral   \n",
       "3            poached pineapple   neutral       neutral   \n",
       "4                       server  negative      negative   \n",
       "\n",
       "                  prompt_name  \\\n",
       "0  prompt_multi_term_zeroshot   \n",
       "1  prompt_multi_term_zeroshot   \n",
       "2  prompt_multi_term_zeroshot   \n",
       "3  prompt_multi_term_zeroshot   \n",
       "4  prompt_multi_term_zeroshot   \n",
       "\n",
       "                                              prompt  \n",
       "0  Task: Analyze the sentiment of specific terms ...  \n",
       "1  Task: Analyze the sentiment of specific terms ...  \n",
       "2  Task: Analyze the sentiment of specific terms ...  \n",
       "3  Task: Analyze the sentiment of specific terms ...  \n",
       "4  Task: Analyze the sentiment of specific terms ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(OUTPUT_PATH, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
