{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/timgutberlet/My Drive (t.gutberlet01@gmail.com)/05 - Coding/06 - Bachelor Thesis/Error-Analysis-with-LLMs/Sentiment Analysis/Pipelines/multi_term', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python312.zip', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/lib-dynload', '', '/Users/timgutberlet/Library/Python/3.12/lib/python/site-packages', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages', '../', '../', '../', '../', '../']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "print(sys.path)\n",
    "import prompts as p\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = os.environ.get(\"LANGFUSE_PUBLIC_KEY\")\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = os.environ.get(\"LANGFUSE_SECRET_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "handler = CallbackHandler()\n",
    "handler.auth_check()\n",
    "\n",
    "DATA_PATH = \"../../../Datasets/MAMS-ATSA/Downsampled/test/test_multi_row_few_shot.csv\"\n",
    "OUTPUT_PATH = \"../../../Datasets/Evaluations/Sentiment Analysis/dynamic_multi_term_few_shot_pipeline_3.5-turbo-instruct.csv\"\n",
    "\n",
    "MODEL = \"gpt-3.5-turbo-instruct\"\n",
    "TEMP = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  text_id  term_id  \\\n",
      "0           0        0        0   \n",
      "1           1        0        1   \n",
      "2           2        0        2   \n",
      "3           3        0        3   \n",
      "4           4        1        4   \n",
      "\n",
      "                                                text  \\\n",
      "0  Amusing details distinguish desserts, from dul...   \n",
      "1  Amusing details distinguish desserts, from dul...   \n",
      "2  Amusing details distinguish desserts, from dul...   \n",
      "3  Amusing details distinguish desserts, from dul...   \n",
      "4  The server was so busy the night we visited th...   \n",
      "\n",
      "                          term  polarity  example1_term_id  \\\n",
      "0                     desserts  positive              9500   \n",
      "1     dulce de leche ice-cream   neutral              9500   \n",
      "2  chocolate sauce tic-tac-toe   neutral              9500   \n",
      "3            poached pineapple   neutral              9500   \n",
      "4                       server  negative              1211   \n",
      "\n",
      "                                     example1_prompt  example1_sim_score  \\\n",
      "0  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
      "1  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
      "2  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
      "3  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
      "4  Input: \"The server also forgot about our desse...            0.354028   \n",
      "\n",
      "   example2_term_id                                    example2_prompt  \\\n",
      "0              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
      "1              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
      "2              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
      "3              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
      "4              8639  Input: \"the 3rd however, the waiter forgot to ...   \n",
      "\n",
      "   example2_sim_score  example3_term_id  \\\n",
      "0            0.162247              1320   \n",
      "1            0.162247              1320   \n",
      "2            0.162247              1320   \n",
      "3            0.162247              1320   \n",
      "4            0.410810             10792   \n",
      "\n",
      "                                     example3_prompt  example3_sim_score  \\\n",
      "0  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
      "1  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
      "2  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
      "3  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
      "4  Input: \"We waited an hour for our appetizers, ...            0.416744   \n",
      "\n",
      "  polarity_pred prompt_name prompt  \n",
      "0          None        None   None  \n",
      "1          None        None   None  \n",
      "2          None        None   None  \n",
      "3          None        None   None  \n",
      "4          None        None   None  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "prompt_name = \"prompt_multi_term_fewshot\"\n",
    "prompt = p.prompt_multi_term_fewshot\n",
    "\n",
    "\n",
    "df['polarity_pred'] = None\n",
    "df['prompt_name'] = None\n",
    "df['prompt'] = None\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_terms(df):\n",
    "    s = \"\"\n",
    "    for term in df['term']:\n",
    "        s += \"'\"+ term + \"'\" + \"\\n\"\n",
    "    return s\n",
    "\n",
    "def string_to_json(s):\n",
    "    start_index = s.find('{')\n",
    "    end_index = s.rfind('}') + 1\n",
    "    json_string = s[start_index:end_index]\n",
    "    json_data = json.loads(json_string)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Example 1:\n",
      "Input: \"Food is mediocre, except for Mushroom Custard and Foie Gras in Fire Ice.\"\n",
      "Terms: \n",
      "'Food'\n",
      "'Mushroom Custard'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"Food\", \"negative\"], [\"Mushroom Custard\", \"positive\"]]}\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"It was the WORST Sangria ever, and their house drink has just a shot of Malibu rum, and at a price of $9 you want more than a shot of a 40% alcohol.\"\n",
      "Terms: \n",
      "'Sangria'\n",
      "'price'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"Sangria\", \"negative\"], [\"price\", \"neutral\"]]}\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"The overpriced ice cream is delicious but the service is atrocious - not only do I have to wait to be admitted into this ice cream joint, but the waiter is a snide, gruff man more suited to be a trucker than an ice cream shop server.\"\n",
      "Terms: \n",
      "'service'\n",
      "'cream joint'\n",
      "'cream shop server'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"service\", \"negative\"], [\"cream joint\", \"neutral\"], [\"cream shop server\", \"neutral\"]]}\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: Amusing details distinguish desserts, from dulce de leche ice-cream profiteroles dotting a chocolate sauce tic-tac-toe board, to coconut custard surrounded by a sea of Malibu-rum gelee and poached pineapple.\n",
      "Terms: \n",
      "'desserts'\n",
      "'dulce de leche ice-cream'\n",
      "'chocolate sauce tic-tac-toe'\n",
      "'poached pineapple'\n",
      "\n",
      "Prompt: Analyze the sentiment of specific terms mentioned in a sentence. \n",
      "You are required to evaluate whether the sentiment towards each term is 'positive', 'negative', or 'neutral'. \n",
      "Return the final result as JSON in the format {\"term_sentiments\": \"<a list of [term, sentiment] pairs>\"}.\n",
      "ONLY return the JSON.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"desserts\", \"neutral\"], [\"dulce de leche ice-cream\", \"positive\"], [\"chocolate sauce tic-tac-toe\", \"neutral\"], [\"poached pineapple\", \"neutral\"]]}\n",
      "\n",
      "\n",
      "0 of  451\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:langfuse:'Generation' object has no attribute 'message'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langfuse/callback.py\", line 761, in on_llm_end\n",
      "    else _extract_raw_esponse(generation)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langfuse/callback.py\", line 872, in _extract_raw_esponse\n",
      "    else last_response.message.additional_kwargs\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Generation' object has no attribute 'message'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Input: \"The server also forgot about our dessert.\"\n",
      "Terms: \n",
      "'server'\n",
      "'dessert'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"server\", \"negative\"], [\"dessert\", \"neutral\"]]}\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"the 3rd however, the waiter forgot to put in our order for food and we ended up waiting an hour for them (b/c they were really busy).\"\n",
      "Terms: \n",
      "'waiter'\n",
      "'food'\n",
      "'waiting'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"waiter\", \"negative\"], [\"food\", \"neutral\"], [\"waiting\", \"negative\"]]}\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"We waited an hour for our appetizers, (I suspect the waitress forgot to put in our order because the restaurant was not busy) and then the entrees came at the same time!\"\n",
      "Terms: \n",
      "'appetizers'\n",
      "'waitress'\n",
      "'entrees'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"appetizers\", \"neutral\"], [\"waitress\", \"negative\"], [\"entrees\", \"neutral\"]]}\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: The server was so busy the night we visited that she forgot to put in our food order.\n",
      "Terms: \n",
      "'server'\n",
      "'food'\n",
      "\n",
      "Prompt: Analyze the sentiment of specific terms mentioned in a sentence. \n",
      "You are required to evaluate whether the sentiment towards each term is 'positive', 'negative', or 'neutral'. \n",
      "Return the final result as JSON in the format {\"term_sentiments\": \"<a list of [term, sentiment] pairs>\"}.\n",
      "ONLY return the JSON.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m             x\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 61\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 40\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(df, prompt, prompt_name, start)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m of  \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df)))\n\u001b[0;32m---> 40\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mstring_to_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m term_sentiments\u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterm_sentiments\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m, in \u001b[0;36mstring_to_json\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      9\u001b[0m end_index \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mrfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     10\u001b[0m json_string \u001b[38;5;241m=\u001b[39m s[start_index:end_index]\n\u001b[0;32m---> 11\u001b[0m json_data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json_data\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "def execute(df, prompt, prompt_name, start = 0):\n",
    "    current_text = -1\n",
    "    if(MODEL == \"gpt-3.5-turbo-instruct\"):\n",
    "        llm = OpenAI(model_name = MODEL, temperature = TEMP, timeout=20)\n",
    "    else:\n",
    "        llm = ChatOpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    for i in range(start, len(df)):\n",
    "        if df[\"text_id\"][i] == current_text:\n",
    "            continue\n",
    "        current_text = df[\"text_id\"][i]\n",
    "        if(df[\"polarity_pred\"][i] != None and df[\"polarity_pred\"][i] != \"error\"):\n",
    "            continue\n",
    "        print(i)\n",
    "        chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "        input_text = df[\"text\"][i]\n",
    "        terms_df = df[df[\"text_id\"] == current_text]\n",
    "        terms = create_terms(terms_df)\n",
    "        example_prompt_1 = df['example1_prompt'][i]\n",
    "        example_prompt_2 = df['example2_prompt'][i]\n",
    "        example_prompt_3 = df['example3_prompt'][i]\n",
    "        try: \n",
    "            result = chain.run(example_1 = example_prompt_1, example_2 = example_prompt_2, example_3 = example_prompt_3, input_text = input_text, terms = terms, callbacks=[handler])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            df.loc[i, 'polarity_pred'] =  'error'\n",
    "            df.loc[i, 'prompt_name'] = prompt_name\n",
    "            df.loc[i, 'prompt'] = chain.prompt.format_prompt(example_1 = example_prompt_1, example_2 = example_prompt_2, example_3 = example_prompt_3, input_text = input_text, terms = terms).text\n",
    "            continue\n",
    "        handler.langfuse.flush()\n",
    "        prompt_text = chain.prompt.format_prompt(example_1 = example_prompt_1, example_2 = example_prompt_2, example_3 = example_prompt_3, input_text = input_text, terms = terms).text\n",
    "        if (i < 5):\n",
    "            print(prompt_text)\n",
    "            print(\"\\n\")\n",
    "            print(result)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        if (i % 50 == 0):\n",
    "            print(str(i) + \" of  \" + str(len(df)))\n",
    "\n",
    "        data = string_to_json(result)\n",
    "        term_sentiments= data[\"term_sentiments\"]\n",
    "        x = 0\n",
    "        for j in terms_df[\"term_id\"]:\n",
    "            if df[\"term\"][j].lower() == term_sentiments[x][0].lower():\n",
    "                df.loc[j, 'polarity_pred'] =  term_sentiments[x][1]\n",
    "                df.loc[j, 'prompt_name'] = prompt_name\n",
    "                df.loc[j, 'prompt'] = prompt_text\n",
    "            else:\n",
    "                print(df[\"term\"][j].lower())\n",
    "                print(term_sentiments[x][0].lower())\n",
    "                print(prompt_text)\n",
    "                print(\"\\n\")\n",
    "                print(result)\n",
    "                print(\"\\n\")\n",
    "                df.loc[j, 'polarity_pred'] =  term_sentiments[x][1]\n",
    "                df.loc[j, 'prompt_name'] = prompt_name\n",
    "                df.loc[j, 'prompt'] = prompt_text\n",
    "            x+=1\n",
    "    return df\n",
    "\n",
    "df = execute(df, prompt, prompt_name)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, text_id, term_id, text, term, polarity, example1_term_id, example1_prompt, example1_sim_score, example2_term_id, example2_prompt, example2_sim_score, example3_term_id, example3_prompt, example3_sim_score, polarity_pred, prompt_name, prompt]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "error_rows = df[df['polarity_pred'] == 'error']\n",
    "print(error_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text_id</th>\n",
       "      <th>term_id</th>\n",
       "      <th>text</th>\n",
       "      <th>term</th>\n",
       "      <th>polarity</th>\n",
       "      <th>example1_term_id</th>\n",
       "      <th>example1_prompt</th>\n",
       "      <th>example1_sim_score</th>\n",
       "      <th>example2_term_id</th>\n",
       "      <th>example2_prompt</th>\n",
       "      <th>example2_sim_score</th>\n",
       "      <th>example3_term_id</th>\n",
       "      <th>example3_prompt</th>\n",
       "      <th>example3_sim_score</th>\n",
       "      <th>polarity_pred</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Amusing details distinguish desserts, from dul...</td>\n",
       "      <td>desserts</td>\n",
       "      <td>positive</td>\n",
       "      <td>9500</td>\n",
       "      <td>Input: \"Food is mediocre, except for Mushroom ...</td>\n",
       "      <td>0.152772</td>\n",
       "      <td>5385</td>\n",
       "      <td>Input: \"It was the WORST Sangria ever, and the...</td>\n",
       "      <td>0.162247</td>\n",
       "      <td>1320</td>\n",
       "      <td>Input: \"The overpriced ice cream is delicious ...</td>\n",
       "      <td>0.166906</td>\n",
       "      <td>positive</td>\n",
       "      <td>prompt_multi_term_fewshot</td>\n",
       "      <td>Example 1:\\nInput: \"Food is mediocre, except f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Amusing details distinguish desserts, from dul...</td>\n",
       "      <td>dulce de leche ice-cream</td>\n",
       "      <td>neutral</td>\n",
       "      <td>9500</td>\n",
       "      <td>Input: \"Food is mediocre, except for Mushroom ...</td>\n",
       "      <td>0.152772</td>\n",
       "      <td>5385</td>\n",
       "      <td>Input: \"It was the WORST Sangria ever, and the...</td>\n",
       "      <td>0.162247</td>\n",
       "      <td>1320</td>\n",
       "      <td>Input: \"The overpriced ice cream is delicious ...</td>\n",
       "      <td>0.166906</td>\n",
       "      <td>positive</td>\n",
       "      <td>prompt_multi_term_fewshot</td>\n",
       "      <td>Example 1:\\nInput: \"Food is mediocre, except f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Amusing details distinguish desserts, from dul...</td>\n",
       "      <td>chocolate sauce tic-tac-toe</td>\n",
       "      <td>neutral</td>\n",
       "      <td>9500</td>\n",
       "      <td>Input: \"Food is mediocre, except for Mushroom ...</td>\n",
       "      <td>0.152772</td>\n",
       "      <td>5385</td>\n",
       "      <td>Input: \"It was the WORST Sangria ever, and the...</td>\n",
       "      <td>0.162247</td>\n",
       "      <td>1320</td>\n",
       "      <td>Input: \"The overpriced ice cream is delicious ...</td>\n",
       "      <td>0.166906</td>\n",
       "      <td>positive</td>\n",
       "      <td>prompt_multi_term_fewshot</td>\n",
       "      <td>Example 1:\\nInput: \"Food is mediocre, except f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Amusing details distinguish desserts, from dul...</td>\n",
       "      <td>poached pineapple</td>\n",
       "      <td>neutral</td>\n",
       "      <td>9500</td>\n",
       "      <td>Input: \"Food is mediocre, except for Mushroom ...</td>\n",
       "      <td>0.152772</td>\n",
       "      <td>5385</td>\n",
       "      <td>Input: \"It was the WORST Sangria ever, and the...</td>\n",
       "      <td>0.162247</td>\n",
       "      <td>1320</td>\n",
       "      <td>Input: \"The overpriced ice cream is delicious ...</td>\n",
       "      <td>0.166906</td>\n",
       "      <td>positive</td>\n",
       "      <td>prompt_multi_term_fewshot</td>\n",
       "      <td>Example 1:\\nInput: \"Food is mediocre, except f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>The server was so busy the night we visited th...</td>\n",
       "      <td>server</td>\n",
       "      <td>negative</td>\n",
       "      <td>1211</td>\n",
       "      <td>Input: \"The server also forgot about our desse...</td>\n",
       "      <td>0.354028</td>\n",
       "      <td>8639</td>\n",
       "      <td>Input: \"the 3rd however, the waiter forgot to ...</td>\n",
       "      <td>0.410810</td>\n",
       "      <td>10792</td>\n",
       "      <td>Input: \"We waited an hour for our appetizers, ...</td>\n",
       "      <td>0.416744</td>\n",
       "      <td>negative</td>\n",
       "      <td>prompt_multi_term_fewshot</td>\n",
       "      <td>Example 1:\\nInput: \"The server also forgot abo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  text_id  term_id  \\\n",
       "0           0        0        0   \n",
       "1           1        0        1   \n",
       "2           2        0        2   \n",
       "3           3        0        3   \n",
       "4           4        1        4   \n",
       "\n",
       "                                                text  \\\n",
       "0  Amusing details distinguish desserts, from dul...   \n",
       "1  Amusing details distinguish desserts, from dul...   \n",
       "2  Amusing details distinguish desserts, from dul...   \n",
       "3  Amusing details distinguish desserts, from dul...   \n",
       "4  The server was so busy the night we visited th...   \n",
       "\n",
       "                          term  polarity  example1_term_id  \\\n",
       "0                     desserts  positive              9500   \n",
       "1     dulce de leche ice-cream   neutral              9500   \n",
       "2  chocolate sauce tic-tac-toe   neutral              9500   \n",
       "3            poached pineapple   neutral              9500   \n",
       "4                       server  negative              1211   \n",
       "\n",
       "                                     example1_prompt  example1_sim_score  \\\n",
       "0  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
       "1  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
       "2  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
       "3  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
       "4  Input: \"The server also forgot about our desse...            0.354028   \n",
       "\n",
       "   example2_term_id                                    example2_prompt  \\\n",
       "0              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
       "1              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
       "2              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
       "3              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
       "4              8639  Input: \"the 3rd however, the waiter forgot to ...   \n",
       "\n",
       "   example2_sim_score  example3_term_id  \\\n",
       "0            0.162247              1320   \n",
       "1            0.162247              1320   \n",
       "2            0.162247              1320   \n",
       "3            0.162247              1320   \n",
       "4            0.410810             10792   \n",
       "\n",
       "                                     example3_prompt  example3_sim_score  \\\n",
       "0  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
       "1  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
       "2  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
       "3  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
       "4  Input: \"We waited an hour for our appetizers, ...            0.416744   \n",
       "\n",
       "  polarity_pred                prompt_name  \\\n",
       "0      positive  prompt_multi_term_fewshot   \n",
       "1      positive  prompt_multi_term_fewshot   \n",
       "2      positive  prompt_multi_term_fewshot   \n",
       "3      positive  prompt_multi_term_fewshot   \n",
       "4      negative  prompt_multi_term_fewshot   \n",
       "\n",
       "                                              prompt  \n",
       "0  Example 1:\\nInput: \"Food is mediocre, except f...  \n",
       "1  Example 1:\\nInput: \"Food is mediocre, except f...  \n",
       "2  Example 1:\\nInput: \"Food is mediocre, except f...  \n",
       "3  Example 1:\\nInput: \"Food is mediocre, except f...  \n",
       "4  Example 1:\\nInput: \"The server also forgot abo...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(OUTPUT_PATH, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
