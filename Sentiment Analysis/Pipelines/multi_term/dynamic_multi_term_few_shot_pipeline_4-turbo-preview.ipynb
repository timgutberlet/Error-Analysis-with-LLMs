{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/timgutberlet/My Drive (t.gutberlet01@gmail.com)/05 - Coding/06 - Bachelor Thesis/Error-Analysis-with-LLMs/Sentiment Analysis/Pipelines/multi_term', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python312.zip', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/lib-dynload', '', '/Users/timgutberlet/Library/Python/3.12/lib/python/site-packages', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages', '../']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "print(sys.path)\n",
    "import prompts as p\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = os.environ.get(\"LANGFUSE_PUBLIC_KEY\")\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = os.environ.get(\"LANGFUSE_SECRET_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "handler = CallbackHandler()\n",
    "handler.auth_check()\n",
    "\n",
    "DATA_PATH = \"../../../Datasets/MAMS-ATSA/Downsampled/test/test_multi_row_few_shot.csv\"\n",
    "OUTPUT_PATH = \"../../../Datasets/Evaluations/Sentiment Analysis/dynamic_multi_term_few_shot_pipeline_4-turbo-preview.csv\"\n",
    "\n",
    "MODEL = \"gpt-4-turbo-preview\"\n",
    "TEMP = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  text_id  term_id  \\\n",
      "0           0        0        0   \n",
      "1           1        0        1   \n",
      "2           2        0        2   \n",
      "3           3        0        3   \n",
      "4           4        1        4   \n",
      "\n",
      "                                                text  \\\n",
      "0  Amusing details distinguish desserts, from dul...   \n",
      "1  Amusing details distinguish desserts, from dul...   \n",
      "2  Amusing details distinguish desserts, from dul...   \n",
      "3  Amusing details distinguish desserts, from dul...   \n",
      "4  The server was so busy the night we visited th...   \n",
      "\n",
      "                          term  polarity  example1_term_id  \\\n",
      "0                     desserts  positive              9500   \n",
      "1     dulce de leche ice-cream   neutral              9500   \n",
      "2  chocolate sauce tic-tac-toe   neutral              9500   \n",
      "3            poached pineapple   neutral              9500   \n",
      "4                       server  negative              1211   \n",
      "\n",
      "                                     example1_prompt  example1_sim_score  \\\n",
      "0  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
      "1  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
      "2  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
      "3  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
      "4  Input: \"The server also forgot about our desse...            0.354028   \n",
      "\n",
      "   example2_term_id                                    example2_prompt  \\\n",
      "0              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
      "1              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
      "2              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
      "3              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
      "4              8639  Input: \"the 3rd however, the waiter forgot to ...   \n",
      "\n",
      "   example2_sim_score  example3_term_id  \\\n",
      "0            0.162247              1320   \n",
      "1            0.162247              1320   \n",
      "2            0.162247              1320   \n",
      "3            0.162247              1320   \n",
      "4            0.410810             10792   \n",
      "\n",
      "                                     example3_prompt  example3_sim_score  \\\n",
      "0  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
      "1  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
      "2  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
      "3  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
      "4  Input: \"We waited an hour for our appetizers, ...            0.416744   \n",
      "\n",
      "  polarity_pred prompt_name prompt  \n",
      "0          None        None   None  \n",
      "1          None        None   None  \n",
      "2          None        None   None  \n",
      "3          None        None   None  \n",
      "4          None        None   None  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "prompt_name = \"prompt_multi_term_fewshot\"\n",
    "prompt = p.prompt_multi_term_fewshot\n",
    "\n",
    "df['polarity_pred'] = None\n",
    "df['prompt_name'] = None\n",
    "df['prompt'] = None\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_terms(df):\n",
    "    s = \"\"\n",
    "    for term in df['term']:\n",
    "        s += \"'\"+ term + \"'\" + \"\\n\"\n",
    "    return s\n",
    "\n",
    "def string_to_json(s):\n",
    "    start_index = s.find('{')\n",
    "    end_index = s.rfind('}') + 1\n",
    "    json_string = s[start_index:end_index]\n",
    "    json_data = json.loads(json_string)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/_api/beta_decorator.py:86: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Input: \"Food is mediocre, except for Mushroom Custard and Foie Gras in Fire Ice.\"\n",
      "Terms: \n",
      "'Food'\n",
      "'Mushroom Custard'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"Food\", \"negative\"], [\"Mushroom Custard\", \"positive\"]]}\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"It was the WORST Sangria ever, and their house drink has just a shot of Malibu rum, and at a price of $9 you want more than a shot of a 40% alcohol.\"\n",
      "Terms: \n",
      "'Sangria'\n",
      "'price'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"Sangria\", \"negative\"], [\"price\", \"neutral\"]]}\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"The overpriced ice cream is delicious but the service is atrocious - not only do I have to wait to be admitted into this ice cream joint, but the waiter is a snide, gruff man more suited to be a trucker than an ice cream shop server.\"\n",
      "Terms: \n",
      "'service'\n",
      "'cream joint'\n",
      "'cream shop server'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"service\", \"negative\"], [\"cream joint\", \"neutral\"], [\"cream shop server\", \"neutral\"]]}\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: Amusing details distinguish desserts, from dulce de leche ice-cream profiteroles dotting a chocolate sauce tic-tac-toe board, to coconut custard surrounded by a sea of Malibu-rum gelee and poached pineapple.\n",
      "Terms: \n",
      "'desserts'\n",
      "'dulce de leche ice-cream'\n",
      "'chocolate sauce tic-tac-toe'\n",
      "'poached pineapple'\n",
      "\n",
      "Prompt: Analyze the sentiment of specific terms mentioned in a sentence. \n",
      "You are required to evaluate whether the sentiment towards each term is 'positive', 'negative', or 'neutral'. \n",
      "Return the final result as JSON in the format {\"term_sentiments\": \"<a list of [term, sentiment] pairs>\"}.\n",
      "ONLY return the JSON.\n",
      "\n",
      "\n",
      "{\"term_sentiments\": [[\"desserts\", \"positive\"], [\"dulce de leche ice-cream\", \"positive\"], [\"chocolate sauce tic-tac-toe\", \"positive\"], [\"poached pineapple\", \"positive\"]]}\n",
      "\n",
      "\n",
      "0 of  451\n",
      "4\n",
      "Example 1:\n",
      "Input: \"The server also forgot about our dessert.\"\n",
      "Terms: \n",
      "'server'\n",
      "'dessert'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"server\", \"negative\"], [\"dessert\", \"neutral\"]]}\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"the 3rd however, the waiter forgot to put in our order for food and we ended up waiting an hour for them (b/c they were really busy).\"\n",
      "Terms: \n",
      "'waiter'\n",
      "'food'\n",
      "'waiting'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"waiter\", \"negative\"], [\"food\", \"neutral\"], [\"waiting\", \"negative\"]]}\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"We waited an hour for our appetizers, (I suspect the waitress forgot to put in our order because the restaurant was not busy) and then the entrees came at the same time!\"\n",
      "Terms: \n",
      "'appetizers'\n",
      "'waitress'\n",
      "'entrees'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"appetizers\", \"neutral\"], [\"waitress\", \"negative\"], [\"entrees\", \"neutral\"]]}\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: The server was so busy the night we visited that she forgot to put in our food order.\n",
      "Terms: \n",
      "'server'\n",
      "'food'\n",
      "\n",
      "Prompt: Analyze the sentiment of specific terms mentioned in a sentence. \n",
      "You are required to evaluate whether the sentiment towards each term is 'positive', 'negative', or 'neutral'. \n",
      "Return the final result as JSON in the format {\"term_sentiments\": \"<a list of [term, sentiment] pairs>\"}.\n",
      "ONLY return the JSON.\n",
      "\n",
      "\n",
      "{\"term_sentiments\": [[\"server\", \"negative\"], [\"food\", \"neutral\"]]}\n",
      "\n",
      "\n",
      "6\n",
      "8\n",
      "10\n",
      "13\n",
      "16\n",
      "19\n",
      "22\n",
      "25\n",
      "29\n",
      "33\n",
      "35\n",
      "38\n",
      "40\n",
      "42\n",
      "47\n",
      "49\n",
      "51\n",
      "54\n",
      "57\n",
      "59\n",
      "61\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "73\n",
      "76\n",
      "79\n",
      "81\n",
      "83\n",
      "85\n",
      "88\n",
      "90\n",
      "92\n",
      "94\n",
      "98\n",
      "100\n",
      "100 of  451\n",
      "102\n",
      "106\n",
      "109\n",
      "111\n",
      "113\n",
      "115\n",
      "117\n",
      "120\n",
      "123\n",
      "125\n",
      "127\n",
      "130\n",
      "133\n",
      "135\n",
      "137\n",
      "139\n",
      "141\n",
      "143\n",
      "146\n",
      "148\n",
      "150\n",
      "150 of  451\n",
      "153\n",
      "156\n",
      "159\n",
      "161\n",
      "163\n",
      "167\n",
      "170\n",
      "172\n",
      "175\n",
      "178\n",
      "181\n",
      "183\n",
      "186\n",
      "188\n",
      "191\n",
      "194\n",
      "196\n",
      "199\n",
      "202\n",
      "204\n",
      "209\n",
      "213\n",
      "216\n",
      "218\n",
      "221\n",
      "224\n",
      "227\n",
      "230\n",
      "233\n",
      "235\n",
      "239\n",
      "242\n",
      "244\n",
      "247\n",
      "249\n",
      "252\n",
      "255\n",
      "257\n",
      "259\n",
      "261\n",
      "264\n",
      "266\n",
      "268\n",
      "270\n",
      "272\n",
      "274\n",
      "276\n",
      "278\n",
      "281\n",
      "283\n",
      "286\n",
      "288\n",
      "291\n",
      "293\n",
      "296\n",
      "298\n",
      "300\n",
      "300 of  451\n",
      "303\n",
      "307\n",
      "310\n",
      "312\n",
      "317\n",
      "320\n",
      "322\n",
      "325\n",
      "327\n",
      "330\n",
      "332\n",
      "335\n",
      "338\n",
      "341\n",
      "343\n",
      "346\n",
      "348\n",
      "352\n",
      "354\n",
      "357\n",
      "359\n",
      "363\n",
      "365\n",
      "367\n",
      "372\n",
      "374\n",
      "376\n",
      "378\n",
      "381\n",
      "384\n",
      "386\n",
      "389\n",
      "391\n",
      "393\n",
      "395\n",
      "399\n",
      "401\n",
      "404\n",
      "406\n",
      "408\n",
      "412\n",
      "414\n",
      "418\n",
      "424\n",
      "426\n",
      "429\n",
      "431\n",
      "434\n",
      "436\n",
      "438\n",
      "440\n",
      "443\n",
      "446\n"
     ]
    }
   ],
   "source": [
    "def execute(df, prompt, prompt_name, start = 0):\n",
    "    current_text = -1\n",
    "    if(MODEL == \"gpt-3.5-turbo-instruct\"):\n",
    "        llm = OpenAI(model_name = MODEL, temperature = TEMP, timeout=20)\n",
    "    else:\n",
    "        llm = ChatOpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    for i in range(start, len(df)):\n",
    "        if df[\"text_id\"][i] == current_text:\n",
    "            continue\n",
    "        current_text = df[\"text_id\"][i]\n",
    "        if(df[\"polarity_pred\"][i] != None and df[\"polarity_pred\"][i] != \"error\"):\n",
    "            continue\n",
    "        print(i)\n",
    "        chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "        input_text = df[\"text\"][i]\n",
    "        terms_df = df[df[\"text_id\"] == current_text]\n",
    "        terms = create_terms(terms_df)\n",
    "        example_prompt_1 = df['example1_prompt'][i]\n",
    "        example_prompt_2 = df['example2_prompt'][i]\n",
    "        example_prompt_3 = df['example3_prompt'][i]\n",
    "        try: \n",
    "            result = chain.run(example_1 = example_prompt_1, example_2 = example_prompt_2, example_3 = example_prompt_3, input_text = input_text, terms = terms, callbacks=[handler])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            df.loc[i, 'polarity_pred'] =  'error'\n",
    "            df.loc[i, 'prompt_name'] = prompt_name\n",
    "            df.loc[i, 'prompt'] = chain.prompt.format_prompt(example_1 = example_prompt_1, example_2 = example_prompt_2, example_3 = example_prompt_3, input_text = input_text, terms = terms).text\n",
    "            continue\n",
    "        handler.langfuse.flush()\n",
    "        prompt_text = chain.prompt.format_prompt(example_1 = example_prompt_1, example_2 = example_prompt_2, example_3 = example_prompt_3, input_text = input_text, terms = terms).text\n",
    "        if (i < 5):\n",
    "            print(prompt_text)\n",
    "            print(\"\\n\")\n",
    "            print(result)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        if (i % 50 == 0):\n",
    "            print(str(i) + \" of  \" + str(len(df)))\n",
    "\n",
    "        data = string_to_json(result)\n",
    "        term_sentiments= data[\"term_sentiments\"]\n",
    "        x = 0\n",
    "        for j in terms_df[\"term_id\"]:\n",
    "            if df[\"term\"][j].lower() == term_sentiments[x][0].lower():\n",
    "                df.loc[j, 'polarity_pred'] =  term_sentiments[x][1]\n",
    "                df.loc[j, 'prompt_name'] = prompt_name\n",
    "                df.loc[j, 'prompt'] = prompt_text\n",
    "            else:\n",
    "                print(df[\"term\"][j].lower())\n",
    "                print(term_sentiments[x][0].lower())\n",
    "                print(prompt_text)\n",
    "                print(\"\\n\")\n",
    "                print(result)\n",
    "                print(\"\\n\")\n",
    "                df.loc[j, 'polarity_pred'] =  term_sentiments[x][1]\n",
    "                df.loc[j, 'prompt_name'] = prompt_name\n",
    "                df.loc[j, 'prompt'] = prompt_text\n",
    "            x+=1\n",
    "    return df\n",
    "\n",
    "df = execute(df, prompt, prompt_name)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, text_id, term_id, text, term, polarity, example1_term_id, example1_prompt, example1_sim_score, example2_term_id, example2_prompt, example2_sim_score, example3_term_id, example3_prompt, example3_sim_score, polarity_pred, prompt_name, prompt]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "error_rows = df[df['polarity_pred'] == 'error']\n",
    "print(error_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text_id</th>\n",
       "      <th>term_id</th>\n",
       "      <th>text</th>\n",
       "      <th>term</th>\n",
       "      <th>polarity</th>\n",
       "      <th>example1_term_id</th>\n",
       "      <th>example1_prompt</th>\n",
       "      <th>example1_sim_score</th>\n",
       "      <th>example2_term_id</th>\n",
       "      <th>example2_prompt</th>\n",
       "      <th>example2_sim_score</th>\n",
       "      <th>example3_term_id</th>\n",
       "      <th>example3_prompt</th>\n",
       "      <th>example3_sim_score</th>\n",
       "      <th>polarity_pred</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Amusing details distinguish desserts, from dul...</td>\n",
       "      <td>desserts</td>\n",
       "      <td>positive</td>\n",
       "      <td>9500</td>\n",
       "      <td>Input: \"Food is mediocre, except for Mushroom ...</td>\n",
       "      <td>0.152772</td>\n",
       "      <td>5385</td>\n",
       "      <td>Input: \"It was the WORST Sangria ever, and the...</td>\n",
       "      <td>0.162247</td>\n",
       "      <td>1320</td>\n",
       "      <td>Input: \"The overpriced ice cream is delicious ...</td>\n",
       "      <td>0.166906</td>\n",
       "      <td>positive</td>\n",
       "      <td>prompt_multi_term_fewshot</td>\n",
       "      <td>Example 1:\\nInput: \"Food is mediocre, except f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Amusing details distinguish desserts, from dul...</td>\n",
       "      <td>dulce de leche ice-cream</td>\n",
       "      <td>neutral</td>\n",
       "      <td>9500</td>\n",
       "      <td>Input: \"Food is mediocre, except for Mushroom ...</td>\n",
       "      <td>0.152772</td>\n",
       "      <td>5385</td>\n",
       "      <td>Input: \"It was the WORST Sangria ever, and the...</td>\n",
       "      <td>0.162247</td>\n",
       "      <td>1320</td>\n",
       "      <td>Input: \"The overpriced ice cream is delicious ...</td>\n",
       "      <td>0.166906</td>\n",
       "      <td>positive</td>\n",
       "      <td>prompt_multi_term_fewshot</td>\n",
       "      <td>Example 1:\\nInput: \"Food is mediocre, except f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Amusing details distinguish desserts, from dul...</td>\n",
       "      <td>chocolate sauce tic-tac-toe</td>\n",
       "      <td>neutral</td>\n",
       "      <td>9500</td>\n",
       "      <td>Input: \"Food is mediocre, except for Mushroom ...</td>\n",
       "      <td>0.152772</td>\n",
       "      <td>5385</td>\n",
       "      <td>Input: \"It was the WORST Sangria ever, and the...</td>\n",
       "      <td>0.162247</td>\n",
       "      <td>1320</td>\n",
       "      <td>Input: \"The overpriced ice cream is delicious ...</td>\n",
       "      <td>0.166906</td>\n",
       "      <td>positive</td>\n",
       "      <td>prompt_multi_term_fewshot</td>\n",
       "      <td>Example 1:\\nInput: \"Food is mediocre, except f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Amusing details distinguish desserts, from dul...</td>\n",
       "      <td>poached pineapple</td>\n",
       "      <td>neutral</td>\n",
       "      <td>9500</td>\n",
       "      <td>Input: \"Food is mediocre, except for Mushroom ...</td>\n",
       "      <td>0.152772</td>\n",
       "      <td>5385</td>\n",
       "      <td>Input: \"It was the WORST Sangria ever, and the...</td>\n",
       "      <td>0.162247</td>\n",
       "      <td>1320</td>\n",
       "      <td>Input: \"The overpriced ice cream is delicious ...</td>\n",
       "      <td>0.166906</td>\n",
       "      <td>positive</td>\n",
       "      <td>prompt_multi_term_fewshot</td>\n",
       "      <td>Example 1:\\nInput: \"Food is mediocre, except f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>The server was so busy the night we visited th...</td>\n",
       "      <td>server</td>\n",
       "      <td>negative</td>\n",
       "      <td>1211</td>\n",
       "      <td>Input: \"The server also forgot about our desse...</td>\n",
       "      <td>0.354028</td>\n",
       "      <td>8639</td>\n",
       "      <td>Input: \"the 3rd however, the waiter forgot to ...</td>\n",
       "      <td>0.410810</td>\n",
       "      <td>10792</td>\n",
       "      <td>Input: \"We waited an hour for our appetizers, ...</td>\n",
       "      <td>0.416744</td>\n",
       "      <td>negative</td>\n",
       "      <td>prompt_multi_term_fewshot</td>\n",
       "      <td>Example 1:\\nInput: \"The server also forgot abo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  text_id  term_id  \\\n",
       "0           0        0        0   \n",
       "1           1        0        1   \n",
       "2           2        0        2   \n",
       "3           3        0        3   \n",
       "4           4        1        4   \n",
       "\n",
       "                                                text  \\\n",
       "0  Amusing details distinguish desserts, from dul...   \n",
       "1  Amusing details distinguish desserts, from dul...   \n",
       "2  Amusing details distinguish desserts, from dul...   \n",
       "3  Amusing details distinguish desserts, from dul...   \n",
       "4  The server was so busy the night we visited th...   \n",
       "\n",
       "                          term  polarity  example1_term_id  \\\n",
       "0                     desserts  positive              9500   \n",
       "1     dulce de leche ice-cream   neutral              9500   \n",
       "2  chocolate sauce tic-tac-toe   neutral              9500   \n",
       "3            poached pineapple   neutral              9500   \n",
       "4                       server  negative              1211   \n",
       "\n",
       "                                     example1_prompt  example1_sim_score  \\\n",
       "0  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
       "1  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
       "2  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
       "3  Input: \"Food is mediocre, except for Mushroom ...            0.152772   \n",
       "4  Input: \"The server also forgot about our desse...            0.354028   \n",
       "\n",
       "   example2_term_id                                    example2_prompt  \\\n",
       "0              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
       "1              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
       "2              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
       "3              5385  Input: \"It was the WORST Sangria ever, and the...   \n",
       "4              8639  Input: \"the 3rd however, the waiter forgot to ...   \n",
       "\n",
       "   example2_sim_score  example3_term_id  \\\n",
       "0            0.162247              1320   \n",
       "1            0.162247              1320   \n",
       "2            0.162247              1320   \n",
       "3            0.162247              1320   \n",
       "4            0.410810             10792   \n",
       "\n",
       "                                     example3_prompt  example3_sim_score  \\\n",
       "0  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
       "1  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
       "2  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
       "3  Input: \"The overpriced ice cream is delicious ...            0.166906   \n",
       "4  Input: \"We waited an hour for our appetizers, ...            0.416744   \n",
       "\n",
       "  polarity_pred                prompt_name  \\\n",
       "0      positive  prompt_multi_term_fewshot   \n",
       "1      positive  prompt_multi_term_fewshot   \n",
       "2      positive  prompt_multi_term_fewshot   \n",
       "3      positive  prompt_multi_term_fewshot   \n",
       "4      negative  prompt_multi_term_fewshot   \n",
       "\n",
       "                                              prompt  \n",
       "0  Example 1:\\nInput: \"Food is mediocre, except f...  \n",
       "1  Example 1:\\nInput: \"Food is mediocre, except f...  \n",
       "2  Example 1:\\nInput: \"Food is mediocre, except f...  \n",
       "3  Example 1:\\nInput: \"Food is mediocre, except f...  \n",
       "4  Example 1:\\nInput: \"The server also forgot abo...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(OUTPUT_PATH, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
