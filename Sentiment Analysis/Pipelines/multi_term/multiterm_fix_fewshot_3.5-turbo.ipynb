{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/timgutberlet/My Drive (t.gutberlet01@gmail.com)/05 - Coding/06 - Bachelor Thesis/Error-Analysis-with-LLMs/Sentiment Analysis/Pipelines/multi_term', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python312.zip', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/lib-dynload', '', '/Users/timgutberlet/Library/Python/3.12/lib/python/site-packages', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages', '../']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "print(sys.path)\n",
    "import prompts as p\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = os.environ.get(\"LANGFUSE_PUBLIC_KEY\")\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = os.environ.get(\"LANGFUSE_SECRET_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "handler = CallbackHandler()\n",
    "handler.auth_check()\n",
    "\n",
    "\n",
    "DATA_PATH = \"../../../Datasets/MAMS-ATSA/Downsampled/test/test_multi_row_few_shot_fix.csv\"\n",
    "OUTPUT_PATH = \"../../../Datasets/Evaluations/Sentiment Analysis/fix_multi_term_few_shot_pipeline_3.5-turbo.csv\"\n",
    "\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "TEMP = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  text_id  term_id  \\\n",
      "0           0        0        0   \n",
      "1           1        0        1   \n",
      "2           2        0        2   \n",
      "3           3        0        3   \n",
      "4           4        1        4   \n",
      "\n",
      "                                                text  \\\n",
      "0  Amusing details distinguish desserts, from dul...   \n",
      "1  Amusing details distinguish desserts, from dul...   \n",
      "2  Amusing details distinguish desserts, from dul...   \n",
      "3  Amusing details distinguish desserts, from dul...   \n",
      "4  The server was so busy the night we visited th...   \n",
      "\n",
      "                          term  polarity  example1_term_id  \\\n",
      "0                     desserts  positive                 0   \n",
      "1     dulce de leche ice-cream   neutral                 0   \n",
      "2  chocolate sauce tic-tac-toe   neutral                 0   \n",
      "3            poached pineapple   neutral                 0   \n",
      "4                       server  negative                 0   \n",
      "\n",
      "                                     example1_prompt  example2_term_id  \\\n",
      "0  Input: \"The decor is not special at all but th...                 1   \n",
      "1  Input: \"The decor is not special at all but th...                 1   \n",
      "2  Input: \"The decor is not special at all but th...                 1   \n",
      "3  Input: \"The decor is not special at all but th...                 1   \n",
      "4  Input: \"The decor is not special at all but th...                 1   \n",
      "\n",
      "                                     example2_prompt  example3_term_id  \\\n",
      "0  Input: \"when tables opened up, the manager sat...                 2   \n",
      "1  Input: \"when tables opened up, the manager sat...                 2   \n",
      "2  Input: \"when tables opened up, the manager sat...                 2   \n",
      "3  Input: \"when tables opened up, the manager sat...                 2   \n",
      "4  Input: \"when tables opened up, the manager sat...                 2   \n",
      "\n",
      "                                     example3_prompt polarity_pred  \\\n",
      "0  Input: \"Though the menu includes some unorthod...          None   \n",
      "1  Input: \"Though the menu includes some unorthod...          None   \n",
      "2  Input: \"Though the menu includes some unorthod...          None   \n",
      "3  Input: \"Though the menu includes some unorthod...          None   \n",
      "4  Input: \"Though the menu includes some unorthod...          None   \n",
      "\n",
      "  prompt_name prompt  \n",
      "0        None   None  \n",
      "1        None   None  \n",
      "2        None   None  \n",
      "3        None   None  \n",
      "4        None   None  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "prompt_name = \"prompt_multi_term_fewshot\"\n",
    "prompt = p.prompt_multi_term_fewshot\n",
    "\n",
    "\n",
    "df['polarity_pred'] = None\n",
    "df['prompt_name'] = None\n",
    "df['prompt'] = None\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_terms(df):\n",
    "    s = \"\"\n",
    "    for term in df['term']:\n",
    "        s += \"'\"+ term + \"'\" + \"\\n\"\n",
    "    return s\n",
    "\n",
    "def string_to_json(s):\n",
    "    start_index = s.find('{')\n",
    "    end_index = s.rfind('}') + 1\n",
    "    json_string = s[start_index:end_index]\n",
    "    json_data = json.loads(json_string)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/_api/beta_decorator.py:86: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Input: \"The decor is not special at all but their food and amazing prices make up for it.\"\n",
      "Terms: \n",
      "'decor'\n",
      "'food'\n",
      "'prices'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"decor\", \"negative\"], [\"food\", \"positive\"], [\"prices\", \"positive\"]]}\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"when tables opened up, the manager sat another party before us.\"\n",
      "Terms: \n",
      "'tables'\n",
      "'manager'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"tables\", \"neutral\"], [\"manager\", \"negative\"]]}\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"Though the menu includes some unorthodox offerings (a peanut butter roll, for instance), the classics are pure and great--we've never had better sushi anywhere, including Japan.\"\n",
      "Terms: \n",
      "'menu'\n",
      "'peanut butter roll'\n",
      "'classics'\n",
      "'sushi'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"menu\", \"neutral\"], [\"peanut butter roll\", \"negative\"], [\"classics\", \"positive\"], [\"sushi\", \"positive\"]]}\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: Amusing details distinguish desserts, from dulce de leche ice-cream profiteroles dotting a chocolate sauce tic-tac-toe board, to coconut custard surrounded by a sea of Malibu-rum gelee and poached pineapple.\n",
      "Terms: \n",
      "'desserts'\n",
      "'dulce de leche ice-cream'\n",
      "'chocolate sauce tic-tac-toe'\n",
      "'poached pineapple'\n",
      "\n",
      "Prompt: Analyze the sentiment of specific terms mentioned in a sentence. \n",
      "You are required to evaluate whether the sentiment towards each term is 'positive', 'negative', or 'neutral'. \n",
      "Return the final result as JSON in the format {\"term_sentiments\": \"<a list of [term, sentiment] pairs>\"}.\n",
      "ONLY return the JSON.\n",
      "\n",
      "\n",
      "{\"term_sentiments\": [[\"desserts\", \"positive\"], [\"dulce de leche ice-cream\", \"positive\"], [\"chocolate sauce tic-tac-toe\", \"positive\"], [\"poached pineapple\", \"positive\"]]}\n",
      "\n",
      "\n",
      "0 of  451\n",
      "4\n",
      "Example 1:\n",
      "Input: \"The decor is not special at all but their food and amazing prices make up for it.\"\n",
      "Terms: \n",
      "'decor'\n",
      "'food'\n",
      "'prices'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"decor\", \"negative\"], [\"food\", \"positive\"], [\"prices\", \"positive\"]]}\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Input: \"when tables opened up, the manager sat another party before us.\"\n",
      "Terms: \n",
      "'tables'\n",
      "'manager'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"tables\", \"neutral\"], [\"manager\", \"negative\"]]}\n",
      "\n",
      "\n",
      "Example 3\n",
      "Input: \"Though the menu includes some unorthodox offerings (a peanut butter roll, for instance), the classics are pure and great--we've never had better sushi anywhere, including Japan.\"\n",
      "Terms: \n",
      "'menu'\n",
      "'peanut butter roll'\n",
      "'classics'\n",
      "'sushi'\n",
      "\n",
      "Output: {\"term_sentiments\": [[\"menu\", \"neutral\"], [\"peanut butter roll\", \"negative\"], [\"classics\", \"positive\"], [\"sushi\", \"positive\"]]}\n",
      "\n",
      "    \n",
      "Task:\n",
      "Input: The server was so busy the night we visited that she forgot to put in our food order.\n",
      "Terms: \n",
      "'server'\n",
      "'food'\n",
      "\n",
      "Prompt: Analyze the sentiment of specific terms mentioned in a sentence. \n",
      "You are required to evaluate whether the sentiment towards each term is 'positive', 'negative', or 'neutral'. \n",
      "Return the final result as JSON in the format {\"term_sentiments\": \"<a list of [term, sentiment] pairs>\"}.\n",
      "ONLY return the JSON.\n",
      "\n",
      "\n",
      "{\"term_sentiments\": [[\"server\", \"negative\"], [\"food\", \"negative\"]]}\n",
      "\n",
      "\n",
      "6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m             x\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 61\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 29\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(df, prompt, prompt_name, start)\u001b[0m\n\u001b[1;32m     27\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39mformat_prompt(example_1 \u001b[38;5;241m=\u001b[39m example_prompt_1, example_2 \u001b[38;5;241m=\u001b[39m example_prompt_2, example_3 \u001b[38;5;241m=\u001b[39m example_prompt_3, input_text \u001b[38;5;241m=\u001b[39m input_text, terms \u001b[38;5;241m=\u001b[39m terms)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlangfuse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m prompt_text \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39mformat_prompt(example_1 \u001b[38;5;241m=\u001b[39m example_prompt_1, example_2 \u001b[38;5;241m=\u001b[39m example_prompt_2, example_3 \u001b[38;5;241m=\u001b[39m example_prompt_3, input_text \u001b[38;5;241m=\u001b[39m input_text, terms \u001b[38;5;241m=\u001b[39m terms)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m5\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langfuse/client.py:778\u001b[0m, in \u001b[0;36mLangfuse.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflush\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 778\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    780\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mexception(e)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langfuse/task_manager.py:252\u001b[0m, in \u001b[0;36mTaskManager.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m queue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\n\u001b[1;32m    251\u001b[0m size \u001b[38;5;241m=\u001b[39m queue\u001b[38;5;241m.\u001b[39mqsize()\n\u001b[0;32m--> 252\u001b[0m \u001b[43mqueue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# Note that this message may not be precise, because of threading.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccessfully flushed about \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m items.\u001b[39m\u001b[38;5;124m\"\u001b[39m, size)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/queue.py:90\u001b[0m, in \u001b[0;36mQueue.join\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_tasks_done:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munfinished_tasks:\n\u001b[0;32m---> 90\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_tasks_done\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def execute(df, prompt, prompt_name, start = 0):\n",
    "    current_text = -1\n",
    "    if(MODEL == \"gpt-3.5-turbo-instruct\"):\n",
    "        llm = OpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    else:\n",
    "        llm = ChatOpenAI(model_name = MODEL, temperature = TEMP, timeout=10)\n",
    "    for i in range(start, len(df)):\n",
    "        if df[\"text_id\"][i] == current_text:\n",
    "            continue\n",
    "        current_text = df[\"text_id\"][i]\n",
    "        if(df[\"polarity_pred\"][i] != None and df[\"polarity_pred\"][i] != \"error\"):\n",
    "            continue\n",
    "        print(i)\n",
    "        chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "        input_text = df[\"text\"][i]\n",
    "        terms_df = df[df[\"text_id\"] == current_text]\n",
    "        terms = create_terms(terms_df)\n",
    "        example_prompt_1 = df['example1_prompt'][i]\n",
    "        example_prompt_2 = df['example2_prompt'][i]\n",
    "        example_prompt_3 = df['example3_prompt'][i]\n",
    "        try: \n",
    "            result = chain.run(example_1 = example_prompt_1, example_2 = example_prompt_2, example_3 = example_prompt_3, input_text = input_text, terms = terms, callbacks=[handler])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            df.loc[i, 'polarity_pred'] =  'error'\n",
    "            df.loc[i, 'prompt_name'] = prompt_name\n",
    "            df.loc[i, 'prompt'] = chain.prompt.format_prompt(example_1 = example_prompt_1, example_2 = example_prompt_2, example_3 = example_prompt_3, input_text = input_text, terms = terms).text\n",
    "            continue\n",
    "        handler.langfuse.flush()\n",
    "        prompt_text = chain.prompt.format_prompt(example_1 = example_prompt_1, example_2 = example_prompt_2, example_3 = example_prompt_3, input_text = input_text, terms = terms).text\n",
    "        if (i < 5):\n",
    "            print(prompt_text)\n",
    "            print(\"\\n\")\n",
    "            print(result)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        if (i % 50 == 0):\n",
    "            print(str(i) + \" of  \" + str(len(df)))\n",
    "\n",
    "        data = string_to_json(result)\n",
    "        term_sentiments= data[\"term_sentiments\"]\n",
    "        x = 0\n",
    "        for j in terms_df[\"term_id\"]:\n",
    "            if df[\"term\"][j].lower() == term_sentiments[x][0].lower():\n",
    "                df.loc[j, 'polarity_pred'] =  term_sentiments[x][1]\n",
    "                df.loc[j, 'prompt_name'] = prompt_name\n",
    "                df.loc[j, 'prompt'] = prompt_text\n",
    "            else:\n",
    "                print(df[\"term\"][j].lower())\n",
    "                print(term_sentiments[x][0].lower())\n",
    "                print(prompt_text)\n",
    "                print(\"\\n\")\n",
    "                print(result)\n",
    "                print(\"\\n\")\n",
    "                df.loc[j, 'polarity_pred'] =  term_sentiments[x][1]\n",
    "                df.loc[j, 'prompt_name'] = prompt_name\n",
    "                df.loc[j, 'prompt'] = prompt_text\n",
    "            x+=1\n",
    "    return df\n",
    "\n",
    "df = execute(df, prompt, prompt_name)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, text_id, term_id, text, term, polarity, example1_term_id, example1_prompt, example2_term_id, example2_prompt, example3_term_id, example3_prompt, polarity_pred, prompt_name, prompt]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "error_rows = df[df['polarity_pred'] == 'error']\n",
    "print(error_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text_id</th>\n",
       "      <th>term_id</th>\n",
       "      <th>text</th>\n",
       "      <th>term</th>\n",
       "      <th>polarity</th>\n",
       "      <th>example1_term_id</th>\n",
       "      <th>example1_prompt</th>\n",
       "      <th>example2_term_id</th>\n",
       "      <th>example2_prompt</th>\n",
       "      <th>example3_term_id</th>\n",
       "      <th>example3_prompt</th>\n",
       "      <th>polarity_pred</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Amusing details distinguish desserts, from dul...</td>\n",
       "      <td>desserts</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>Input: \"The decor is not special at all but th...</td>\n",
       "      <td>1</td>\n",
       "      <td>Input: \"when tables opened up, the manager sat...</td>\n",
       "      <td>2</td>\n",
       "      <td>Input: \"Though the menu includes some unorthod...</td>\n",
       "      <td>positive</td>\n",
       "      <td>prompt_multi_term_fewshot</td>\n",
       "      <td>Example 1:\\nInput: \"The decor is not special a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Amusing details distinguish desserts, from dul...</td>\n",
       "      <td>dulce de leche ice-cream</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Input: \"The decor is not special at all but th...</td>\n",
       "      <td>1</td>\n",
       "      <td>Input: \"when tables opened up, the manager sat...</td>\n",
       "      <td>2</td>\n",
       "      <td>Input: \"Though the menu includes some unorthod...</td>\n",
       "      <td>positive</td>\n",
       "      <td>prompt_multi_term_fewshot</td>\n",
       "      <td>Example 1:\\nInput: \"The decor is not special a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Amusing details distinguish desserts, from dul...</td>\n",
       "      <td>chocolate sauce tic-tac-toe</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Input: \"The decor is not special at all but th...</td>\n",
       "      <td>1</td>\n",
       "      <td>Input: \"when tables opened up, the manager sat...</td>\n",
       "      <td>2</td>\n",
       "      <td>Input: \"Though the menu includes some unorthod...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>prompt_multi_term_fewshot</td>\n",
       "      <td>Example 1:\\nInput: \"The decor is not special a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Amusing details distinguish desserts, from dul...</td>\n",
       "      <td>poached pineapple</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Input: \"The decor is not special at all but th...</td>\n",
       "      <td>1</td>\n",
       "      <td>Input: \"when tables opened up, the manager sat...</td>\n",
       "      <td>2</td>\n",
       "      <td>Input: \"Though the menu includes some unorthod...</td>\n",
       "      <td>positive</td>\n",
       "      <td>prompt_multi_term_fewshot</td>\n",
       "      <td>Example 1:\\nInput: \"The decor is not special a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>The server was so busy the night we visited th...</td>\n",
       "      <td>server</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>Input: \"The decor is not special at all but th...</td>\n",
       "      <td>1</td>\n",
       "      <td>Input: \"when tables opened up, the manager sat...</td>\n",
       "      <td>2</td>\n",
       "      <td>Input: \"Though the menu includes some unorthod...</td>\n",
       "      <td>negative</td>\n",
       "      <td>prompt_multi_term_fewshot</td>\n",
       "      <td>Example 1:\\nInput: \"The decor is not special a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  text_id  term_id  \\\n",
       "0           0        0        0   \n",
       "1           1        0        1   \n",
       "2           2        0        2   \n",
       "3           3        0        3   \n",
       "4           4        1        4   \n",
       "\n",
       "                                                text  \\\n",
       "0  Amusing details distinguish desserts, from dul...   \n",
       "1  Amusing details distinguish desserts, from dul...   \n",
       "2  Amusing details distinguish desserts, from dul...   \n",
       "3  Amusing details distinguish desserts, from dul...   \n",
       "4  The server was so busy the night we visited th...   \n",
       "\n",
       "                          term  polarity  example1_term_id  \\\n",
       "0                     desserts  positive                 0   \n",
       "1     dulce de leche ice-cream   neutral                 0   \n",
       "2  chocolate sauce tic-tac-toe   neutral                 0   \n",
       "3            poached pineapple   neutral                 0   \n",
       "4                       server  negative                 0   \n",
       "\n",
       "                                     example1_prompt  example2_term_id  \\\n",
       "0  Input: \"The decor is not special at all but th...                 1   \n",
       "1  Input: \"The decor is not special at all but th...                 1   \n",
       "2  Input: \"The decor is not special at all but th...                 1   \n",
       "3  Input: \"The decor is not special at all but th...                 1   \n",
       "4  Input: \"The decor is not special at all but th...                 1   \n",
       "\n",
       "                                     example2_prompt  example3_term_id  \\\n",
       "0  Input: \"when tables opened up, the manager sat...                 2   \n",
       "1  Input: \"when tables opened up, the manager sat...                 2   \n",
       "2  Input: \"when tables opened up, the manager sat...                 2   \n",
       "3  Input: \"when tables opened up, the manager sat...                 2   \n",
       "4  Input: \"when tables opened up, the manager sat...                 2   \n",
       "\n",
       "                                     example3_prompt polarity_pred  \\\n",
       "0  Input: \"Though the menu includes some unorthod...      positive   \n",
       "1  Input: \"Though the menu includes some unorthod...      positive   \n",
       "2  Input: \"Though the menu includes some unorthod...       neutral   \n",
       "3  Input: \"Though the menu includes some unorthod...      positive   \n",
       "4  Input: \"Though the menu includes some unorthod...      negative   \n",
       "\n",
       "                 prompt_name  \\\n",
       "0  prompt_multi_term_fewshot   \n",
       "1  prompt_multi_term_fewshot   \n",
       "2  prompt_multi_term_fewshot   \n",
       "3  prompt_multi_term_fewshot   \n",
       "4  prompt_multi_term_fewshot   \n",
       "\n",
       "                                              prompt  \n",
       "0  Example 1:\\nInput: \"The decor is not special a...  \n",
       "1  Example 1:\\nInput: \"The decor is not special a...  \n",
       "2  Example 1:\\nInput: \"The decor is not special a...  \n",
       "3  Example 1:\\nInput: \"The decor is not special a...  \n",
       "4  Example 1:\\nInput: \"The decor is not special a...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(OUTPUT_PATH, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
